{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "536a6ccd-e607-4f3d-b9c6-9a91d76a070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import subprocess\n",
    "import shlex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5621f4aa-a661-4b4a-ad42-6650867204a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('merged_train.csv')\n",
    "\n",
    "merged_test_df = pd.read_csv('merged_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d36930c-3f24-4319-b444-efd046fec91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_holdout_df = pd.read_csv('merged_holdout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a508378b-71a8-415c-aea2-2063a3769fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9838, 70)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>aniongap</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>bun</th>\n",
       "      <th>calcium</th>\n",
       "      <th>chloride</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>glucose</th>\n",
       "      <th>sodium</th>\n",
       "      <th>...</th>\n",
       "      <th>first_careunit_Cardiac Vascular Intensive Care Unit (CVICU)</th>\n",
       "      <th>first_careunit_Coronary Care Unit (CCU)</th>\n",
       "      <th>first_careunit_Medical Intensive Care Unit (MICU)</th>\n",
       "      <th>first_careunit_Medical/Surgical Intensive Care Unit (MICU/SICU)</th>\n",
       "      <th>first_careunit_Neuro Intermediate</th>\n",
       "      <th>first_careunit_Neuro Stepdown</th>\n",
       "      <th>first_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)</th>\n",
       "      <th>first_careunit_Surgical Intensive Care Unit (SICU)</th>\n",
       "      <th>first_careunit_Trauma SICU (TSICU)</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20017191</td>\n",
       "      <td>2032-12-04 04:56:00</td>\n",
       "      <td>31</td>\n",
       "      <td>16.0</td>\n",
       "      <td>35</td>\n",
       "      <td>9.2</td>\n",
       "      <td>99</td>\n",
       "      <td>1.6</td>\n",
       "      <td>156</td>\n",
       "      <td>140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20017191</td>\n",
       "      <td>2032-12-04 14:19:00</td>\n",
       "      <td>18</td>\n",
       "      <td>23.0</td>\n",
       "      <td>40</td>\n",
       "      <td>8.4</td>\n",
       "      <td>105</td>\n",
       "      <td>1.5</td>\n",
       "      <td>136</td>\n",
       "      <td>141.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20036035</td>\n",
       "      <td>2022-10-05 23:22:00</td>\n",
       "      <td>29</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19</td>\n",
       "      <td>9.1</td>\n",
       "      <td>102</td>\n",
       "      <td>0.8</td>\n",
       "      <td>486</td>\n",
       "      <td>143.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20036035</td>\n",
       "      <td>2022-10-06 03:36:00</td>\n",
       "      <td>31</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18</td>\n",
       "      <td>9.1</td>\n",
       "      <td>104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>386</td>\n",
       "      <td>144.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20037205</td>\n",
       "      <td>2022-03-05 21:55:00</td>\n",
       "      <td>17</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8.7</td>\n",
       "      <td>104</td>\n",
       "      <td>0.6</td>\n",
       "      <td>129</td>\n",
       "      <td>138.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id            charttime  aniongap  bicarbonate  bun  calcium  \\\n",
       "0  20017191  2032-12-04 04:56:00        31         16.0   35      9.2   \n",
       "1  20017191  2032-12-04 14:19:00        18         23.0   40      8.4   \n",
       "2  20036035  2022-10-05 23:22:00        29         16.0   19      9.1   \n",
       "3  20036035  2022-10-06 03:36:00        31         13.0   18      9.1   \n",
       "4  20037205  2022-03-05 21:55:00        17         21.0   11      8.7   \n",
       "\n",
       "   chloride  creatinine  glucose  sodium  ...  \\\n",
       "0        99         1.6      156   140.0  ...   \n",
       "1       105         1.5      136   141.0  ...   \n",
       "2       102         0.8      486   143.0  ...   \n",
       "3       104         1.0      386   144.0  ...   \n",
       "4       104         0.6      129   138.0  ...   \n",
       "\n",
       "   first_careunit_Cardiac Vascular Intensive Care Unit (CVICU)  \\\n",
       "0                                                  0             \n",
       "1                                                  0             \n",
       "2                                                  0             \n",
       "3                                                  0             \n",
       "4                                                  0             \n",
       "\n",
       "   first_careunit_Coronary Care Unit (CCU)  \\\n",
       "0                                        1   \n",
       "1                                        1   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "\n",
       "   first_careunit_Medical Intensive Care Unit (MICU)  \\\n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  1   \n",
       "\n",
       "   first_careunit_Medical/Surgical Intensive Care Unit (MICU/SICU)  \\\n",
       "0                                                  0                 \n",
       "1                                                  0                 \n",
       "2                                                  0                 \n",
       "3                                                  0                 \n",
       "4                                                  0                 \n",
       "\n",
       "   first_careunit_Neuro Intermediate  first_careunit_Neuro Stepdown  \\\n",
       "0                                  0                              0   \n",
       "1                                  0                              0   \n",
       "2                                  0                              0   \n",
       "3                                  0                              0   \n",
       "4                                  0                              0   \n",
       "\n",
       "   first_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)  \\\n",
       "0                                                  0                \n",
       "1                                                  0                \n",
       "2                                                  0                \n",
       "3                                                  0                \n",
       "4                                                  0                \n",
       "\n",
       "   first_careunit_Surgical Intensive Care Unit (SICU)  \\\n",
       "0                                                  0    \n",
       "1                                                  0    \n",
       "2                                                  0    \n",
       "3                                                  0    \n",
       "4                                                  0    \n",
       "\n",
       "   first_careunit_Trauma SICU (TSICU)       hour  \n",
       "0                                   0  11.233333  \n",
       "1                                   0  20.616667  \n",
       "2                                   1   1.433333  \n",
       "3                                   1   5.666667  \n",
       "4                                   0   2.166667  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(merged_holdout_df.shape)\n",
    "merged_holdout_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba14b943-f842-4b98-94f6-c3e777f7821b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2042"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_holdout_df.id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "730c0aa3-e726-4bbb-8263-b121b12e3eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = merged_df.groupby('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd8738a4-0c77-4f24-a1c5-fb7c06bf6b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>aniongap</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>bun</th>\n",
       "      <th>calcium</th>\n",
       "      <th>chloride</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>glucose</th>\n",
       "      <th>sodium</th>\n",
       "      <th>...</th>\n",
       "      <th>first_careunit_Cardiac Vascular Intensive Care Unit (CVICU)</th>\n",
       "      <th>first_careunit_Coronary Care Unit (CCU)</th>\n",
       "      <th>first_careunit_Medical Intensive Care Unit (MICU)</th>\n",
       "      <th>first_careunit_Medical/Surgical Intensive Care Unit (MICU/SICU)</th>\n",
       "      <th>first_careunit_Neuro Intermediate</th>\n",
       "      <th>first_careunit_Neuro Stepdown</th>\n",
       "      <th>first_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)</th>\n",
       "      <th>first_careunit_Surgical Intensive Care Unit (SICU)</th>\n",
       "      <th>first_careunit_Trauma SICU (TSICU)</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001305</td>\n",
       "      <td>1978-03-25 08:20:00</td>\n",
       "      <td>15</td>\n",
       "      <td>23.0</td>\n",
       "      <td>47</td>\n",
       "      <td>11.4</td>\n",
       "      <td>108</td>\n",
       "      <td>0.8</td>\n",
       "      <td>154</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001305</td>\n",
       "      <td>1978-03-25 13:45:00</td>\n",
       "      <td>13</td>\n",
       "      <td>25.0</td>\n",
       "      <td>48</td>\n",
       "      <td>10.8</td>\n",
       "      <td>107</td>\n",
       "      <td>0.9</td>\n",
       "      <td>149</td>\n",
       "      <td>140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001305</td>\n",
       "      <td>1978-03-25 21:55:00</td>\n",
       "      <td>13</td>\n",
       "      <td>24.0</td>\n",
       "      <td>50</td>\n",
       "      <td>10.8</td>\n",
       "      <td>108</td>\n",
       "      <td>0.9</td>\n",
       "      <td>131</td>\n",
       "      <td>141.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001361</td>\n",
       "      <td>2043-05-04 17:24:00</td>\n",
       "      <td>14</td>\n",
       "      <td>22.0</td>\n",
       "      <td>28</td>\n",
       "      <td>6.3</td>\n",
       "      <td>107</td>\n",
       "      <td>2.5</td>\n",
       "      <td>161</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001361</td>\n",
       "      <td>2043-05-04 21:07:00</td>\n",
       "      <td>15</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32</td>\n",
       "      <td>6.5</td>\n",
       "      <td>108</td>\n",
       "      <td>2.5</td>\n",
       "      <td>124</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64980</th>\n",
       "      <td>29998399</td>\n",
       "      <td>2012-05-09 17:50:00</td>\n",
       "      <td>10</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12</td>\n",
       "      <td>9.2</td>\n",
       "      <td>107</td>\n",
       "      <td>1.1</td>\n",
       "      <td>129</td>\n",
       "      <td>140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64981</th>\n",
       "      <td>29998399</td>\n",
       "      <td>2012-05-09 19:45:00</td>\n",
       "      <td>11</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12</td>\n",
       "      <td>8.2</td>\n",
       "      <td>105</td>\n",
       "      <td>1.1</td>\n",
       "      <td>122</td>\n",
       "      <td>140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64982</th>\n",
       "      <td>29999625</td>\n",
       "      <td>2057-11-07 13:33:00</td>\n",
       "      <td>17</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14</td>\n",
       "      <td>8.5</td>\n",
       "      <td>104</td>\n",
       "      <td>1.2</td>\n",
       "      <td>109</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64983</th>\n",
       "      <td>29999625</td>\n",
       "      <td>2057-11-08 01:36:00</td>\n",
       "      <td>15</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21</td>\n",
       "      <td>8.6</td>\n",
       "      <td>110</td>\n",
       "      <td>1.6</td>\n",
       "      <td>122</td>\n",
       "      <td>149.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64984</th>\n",
       "      <td>29999625</td>\n",
       "      <td>2057-11-08 11:14:00</td>\n",
       "      <td>15</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27</td>\n",
       "      <td>8.4</td>\n",
       "      <td>102</td>\n",
       "      <td>1.3</td>\n",
       "      <td>127</td>\n",
       "      <td>148.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.383333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45890 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id            charttime  aniongap  bicarbonate  bun  calcium  \\\n",
       "0      20001305  1978-03-25 08:20:00        15         23.0   47     11.4   \n",
       "1      20001305  1978-03-25 13:45:00        13         25.0   48     10.8   \n",
       "2      20001305  1978-03-25 21:55:00        13         24.0   50     10.8   \n",
       "3      20001361  2043-05-04 17:24:00        14         22.0   28      6.3   \n",
       "4      20001361  2043-05-04 21:07:00        15         20.0   32      6.5   \n",
       "...         ...                  ...       ...          ...  ...      ...   \n",
       "64980  29998399  2012-05-09 17:50:00        10         23.0   12      9.2   \n",
       "64981  29998399  2012-05-09 19:45:00        11         24.0   12      8.2   \n",
       "64982  29999625  2057-11-07 13:33:00        17         21.0   14      8.5   \n",
       "64983  29999625  2057-11-08 01:36:00        15         24.0   21      8.6   \n",
       "64984  29999625  2057-11-08 11:14:00        15         23.0   27      8.4   \n",
       "\n",
       "       chloride  creatinine  glucose  sodium  ...  \\\n",
       "0           108         0.8      154   142.0  ...   \n",
       "1           107         0.9      149   140.0  ...   \n",
       "2           108         0.9      131   141.0  ...   \n",
       "3           107         2.5      161   137.0  ...   \n",
       "4           108         2.5      124   137.0  ...   \n",
       "...         ...         ...      ...     ...  ...   \n",
       "64980       107         1.1      129   140.0  ...   \n",
       "64981       105         1.1      122   140.0  ...   \n",
       "64982       104         1.2      109   142.0  ...   \n",
       "64983       110         1.6      122   149.0  ...   \n",
       "64984       102         1.3      127   148.0  ...   \n",
       "\n",
       "       first_careunit_Cardiac Vascular Intensive Care Unit (CVICU)  \\\n",
       "0                                                      0             \n",
       "1                                                      0             \n",
       "2                                                      0             \n",
       "3                                                      0             \n",
       "4                                                      0             \n",
       "...                                                  ...             \n",
       "64980                                                  0             \n",
       "64981                                                  0             \n",
       "64982                                                  0             \n",
       "64983                                                  0             \n",
       "64984                                                  0             \n",
       "\n",
       "       first_careunit_Coronary Care Unit (CCU)  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "...                                        ...   \n",
       "64980                                        0   \n",
       "64981                                        0   \n",
       "64982                                        0   \n",
       "64983                                        0   \n",
       "64984                                        0   \n",
       "\n",
       "       first_careunit_Medical Intensive Care Unit (MICU)  \\\n",
       "0                                                      0   \n",
       "1                                                      0   \n",
       "2                                                      0   \n",
       "3                                                      0   \n",
       "4                                                      0   \n",
       "...                                                  ...   \n",
       "64980                                                  0   \n",
       "64981                                                  0   \n",
       "64982                                                  0   \n",
       "64983                                                  0   \n",
       "64984                                                  0   \n",
       "\n",
       "       first_careunit_Medical/Surgical Intensive Care Unit (MICU/SICU)  \\\n",
       "0                                                      1                 \n",
       "1                                                      1                 \n",
       "2                                                      1                 \n",
       "3                                                      1                 \n",
       "4                                                      1                 \n",
       "...                                                  ...                 \n",
       "64980                                                  0                 \n",
       "64981                                                  0                 \n",
       "64982                                                  0                 \n",
       "64983                                                  0                 \n",
       "64984                                                  0                 \n",
       "\n",
       "       first_careunit_Neuro Intermediate  first_careunit_Neuro Stepdown  \\\n",
       "0                                      0                              0   \n",
       "1                                      0                              0   \n",
       "2                                      0                              0   \n",
       "3                                      0                              0   \n",
       "4                                      0                              0   \n",
       "...                                  ...                            ...   \n",
       "64980                                  0                              0   \n",
       "64981                                  0                              0   \n",
       "64982                                  0                              0   \n",
       "64983                                  0                              0   \n",
       "64984                                  0                              0   \n",
       "\n",
       "       first_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)  \\\n",
       "0                                                      0                \n",
       "1                                                      0                \n",
       "2                                                      0                \n",
       "3                                                      0                \n",
       "4                                                      0                \n",
       "...                                                  ...                \n",
       "64980                                                  0                \n",
       "64981                                                  0                \n",
       "64982                                                  1                \n",
       "64983                                                  1                \n",
       "64984                                                  1                \n",
       "\n",
       "       first_careunit_Surgical Intensive Care Unit (SICU)  \\\n",
       "0                                                      0    \n",
       "1                                                      0    \n",
       "2                                                      0    \n",
       "3                                                      0    \n",
       "4                                                      0    \n",
       "...                                                  ...    \n",
       "64980                                                  0    \n",
       "64981                                                  0    \n",
       "64982                                                  0    \n",
       "64983                                                  0    \n",
       "64984                                                  0    \n",
       "\n",
       "       first_careunit_Trauma SICU (TSICU)       hour  \n",
       "0                                       0   5.350000  \n",
       "1                                       0  10.766667  \n",
       "2                                       0  18.933333  \n",
       "3                                       0   0.533333  \n",
       "4                                       0   4.250000  \n",
       "...                                   ...        ...  \n",
       "64980                                   1  20.416667  \n",
       "64981                                   1  22.333333  \n",
       "64982                                   0   1.700000  \n",
       "64983                                   0  13.750000  \n",
       "64984                                   0  23.383333  \n",
       "\n",
       "[45890 rows x 70 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c32536f-bed5-4991-b1fc-6fc5e1d9daaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group ID: 1\n",
      "   id  timestamp  value\n",
      "0   1 2024-01-01     10\n",
      "1   1 2024-01-02     20\n",
      "Group ID: 2\n",
      "   id  timestamp  value\n",
      "2   2 2024-01-01     30\n",
      "3   2 2024-01-02     40\n",
      "Group ID: 3\n",
      "   id  timestamp  value\n",
      "4   3 2024-01-01     50\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df' is your DataFrame with time series data and 'id' is the column you want to group by\n",
    "# Example DataFrame structure:\n",
    "df = pd.DataFrame({'id': [1, 1, 2, 2, 3], 'timestamp': [pd.Timestamp('2024-01-01'), pd.Timestamp('2024-01-02'), pd.Timestamp('2024-01-01'), pd.Timestamp('2024-01-02'), pd.Timestamp('2024-01-01')], 'value': [10, 20, 30, 40, 50]})\n",
    "\n",
    "# Group the DataFrame by 'id'\n",
    "grouped = df.groupby('id')\n",
    "\n",
    "# Now, 'grouped' is a DataFrameGroupBy object, which contains groups of dataframes for each unique value in the 'id' column.\n",
    "\n",
    "# You can iterate over the groups, or access specific groups using the get_group method, for example:\n",
    "for group_id, group_data in grouped:\n",
    "    print(f\"Group ID: {group_id}\")\n",
    "    print(group_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3315026-7c32-44e9-9a9a-4d57a56179b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  timestamp  value\n",
       "0   1 2024-01-01     10\n",
       "1   1 2024-01-02     20\n",
       "2   2 2024-01-01     30\n",
       "3   2 2024-01-02     40\n",
       "4   3 2024-01-01     50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d222a0b-0ba4-4607-9f09-423602046782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_list = merged_df.id.unique().tolist()\n",
    "\n",
    "# test_id_list = merged_test_df.id.unique().tolist()\n",
    "\n",
    "holdout_id_list = merged_holdout_df.id.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccca31d5-fde5-4dd8-bc80-d17a2490dda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2042"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(holdout_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa39137d-ed63-4ab5-83a2-b1ffc9b595cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_list.sort()\n",
    "\n",
    "# test_id_list.sort()\n",
    "\n",
    "holdout_id_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6619d99-e3f1-439c-b2fe-b93c28799052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f25c276d-24ae-4938-bead-0b06ba0daec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4146\n"
     ]
    }
   ],
   "source": [
    "# counter = 0\n",
    "# for id in id_list:\n",
    "#     id_df = merged_df[merged_df['id'] == id]\n",
    "#     if id_df.shape[0] >= 5:\n",
    "#         counter += 1\n",
    "# print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d4265f04-23dd-4f3d-b0fe-f7d0ab62c544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 70)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trial_df = merged_df[merged_df['id'] == 20001305]\n",
    "\n",
    "# trial_df.head()\n",
    "# result_df = pd.DataFrame()\n",
    "# for index, row in trial_df.iterrows():\n",
    "#     #print(row)\n",
    "#     row_dict = row.to_dict()\n",
    "#     result_df = result_df.append(row_dict, ignore_index=True)\n",
    "# result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5826b276-4a05-4947-a3e3-83bb7b15682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_step(df, id_list, steps):\n",
    "    result_df = pd.DataFrame()\n",
    "    for id in id_list:\n",
    "        id_df = df[df['id'] == id]\n",
    "        if id_df.shape[0] >= steps:\n",
    "            id_df = id_df.sort_values(by='hour', ascending=False)\n",
    "            counter = 0\n",
    "            for index, row in id_df.iterrows():\n",
    "                if counter < steps:\n",
    "                    row_dict = row.to_dict()\n",
    "                    result_df = result_df.append(row_dict, ignore_index=True)\n",
    "                    counter += 1\n",
    "        else:\n",
    "            id_df = id_df.sort_values(by='hour', ascending=False)\n",
    "            n = steps - id_df.shape[0]\n",
    "            for index, row in id_df.iterrows():\n",
    "                row_dict = row.to_dict()\n",
    "                result_df = result_df.append(row_dict, ignore_index=True)\n",
    "            for i in range(n):\n",
    "                result_df = result_df.append(row_dict, ignore_index=True)\n",
    "            \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ab0f44e-bb6e-49ea-b3b2-bc4062977e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_df = get_time_step(merged_holdout_df, holdout_id_list, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa77b4ce-70db-439d-a0dc-18b40928dc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10210, 70)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "af9053a7-a592-4c69-b192-45265b0a6a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>aniongap</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>bun</th>\n",
       "      <th>calcium</th>\n",
       "      <th>chloride</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>glucose</th>\n",
       "      <th>sodium</th>\n",
       "      <th>...</th>\n",
       "      <th>first_careunit_Cardiac Vascular Intensive Care Unit (CVICU)</th>\n",
       "      <th>first_careunit_Coronary Care Unit (CCU)</th>\n",
       "      <th>first_careunit_Medical Intensive Care Unit (MICU)</th>\n",
       "      <th>first_careunit_Medical/Surgical Intensive Care Unit (MICU/SICU)</th>\n",
       "      <th>first_careunit_Neuro Intermediate</th>\n",
       "      <th>first_careunit_Neuro Stepdown</th>\n",
       "      <th>first_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)</th>\n",
       "      <th>first_careunit_Surgical Intensive Care Unit (SICU)</th>\n",
       "      <th>first_careunit_Trauma SICU (TSICU)</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20008724.0</td>\n",
       "      <td>2024-02-27 01:53:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>112.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20008724.0</td>\n",
       "      <td>2024-02-27 01:53:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>112.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20008724.0</td>\n",
       "      <td>2024-02-27 01:53:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>112.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20008724.0</td>\n",
       "      <td>2024-02-27 01:53:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>112.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20008724.0</td>\n",
       "      <td>2024-02-27 01:53:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>112.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id            charttime  aniongap  bicarbonate   bun  calcium  \\\n",
       "35  20008724.0  2024-02-27 01:53:00      12.0         25.0  14.0      9.0   \n",
       "36  20008724.0  2024-02-27 01:53:00      12.0         25.0  14.0      9.0   \n",
       "37  20008724.0  2024-02-27 01:53:00      12.0         25.0  14.0      9.0   \n",
       "38  20008724.0  2024-02-27 01:53:00      12.0         25.0  14.0      9.0   \n",
       "39  20008724.0  2024-02-27 01:53:00      12.0         25.0  14.0      9.0   \n",
       "\n",
       "    chloride  creatinine  glucose  sodium  ...  \\\n",
       "35     103.0         0.5    112.0   137.0  ...   \n",
       "36     103.0         0.5    112.0   137.0  ...   \n",
       "37     103.0         0.5    112.0   137.0  ...   \n",
       "38     103.0         0.5    112.0   137.0  ...   \n",
       "39     103.0         0.5    112.0   137.0  ...   \n",
       "\n",
       "    first_careunit_Cardiac Vascular Intensive Care Unit (CVICU)  \\\n",
       "35                                                0.0             \n",
       "36                                                0.0             \n",
       "37                                                0.0             \n",
       "38                                                0.0             \n",
       "39                                                0.0             \n",
       "\n",
       "    first_careunit_Coronary Care Unit (CCU)  \\\n",
       "35                                      0.0   \n",
       "36                                      0.0   \n",
       "37                                      0.0   \n",
       "38                                      0.0   \n",
       "39                                      0.0   \n",
       "\n",
       "    first_careunit_Medical Intensive Care Unit (MICU)  \\\n",
       "35                                                0.0   \n",
       "36                                                0.0   \n",
       "37                                                0.0   \n",
       "38                                                0.0   \n",
       "39                                                0.0   \n",
       "\n",
       "    first_careunit_Medical/Surgical Intensive Care Unit (MICU/SICU)  \\\n",
       "35                                                0.0                 \n",
       "36                                                0.0                 \n",
       "37                                                0.0                 \n",
       "38                                                0.0                 \n",
       "39                                                0.0                 \n",
       "\n",
       "    first_careunit_Neuro Intermediate  first_careunit_Neuro Stepdown  \\\n",
       "35                                0.0                            0.0   \n",
       "36                                0.0                            0.0   \n",
       "37                                0.0                            0.0   \n",
       "38                                0.0                            0.0   \n",
       "39                                0.0                            0.0   \n",
       "\n",
       "    first_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)  \\\n",
       "35                                                0.0                \n",
       "36                                                0.0                \n",
       "37                                                0.0                \n",
       "38                                                0.0                \n",
       "39                                                0.0                \n",
       "\n",
       "    first_careunit_Surgical Intensive Care Unit (SICU)  \\\n",
       "35                                                0.0    \n",
       "36                                                0.0    \n",
       "37                                                0.0    \n",
       "38                                                0.0    \n",
       "39                                                0.0    \n",
       "\n",
       "    first_careunit_Trauma SICU (TSICU)   hour  \n",
       "35                                 1.0  11.05  \n",
       "36                                 1.0  11.05  \n",
       "37                                 1.0  11.05  \n",
       "38                                 1.0  11.05  \n",
       "39                                 1.0  11.05  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_df = result_df[result_df['id'] == 20008724]\n",
    "id_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a42b7c28-ae75-400b-864e-c676de3d3b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start here - load processed timestep5 data\n",
    "\n",
    "train_df = pd.read_excel('Timestep5_train.xlsx')\n",
    "test_df = pd.read_excel('Timestep5_test.xlsx')\n",
    "holdout_df = pd.read_excel('Timestep5_holdout.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "643a9788-2db3-4066-953b-37673857acdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71445, 70)\n",
      "(20415, 70)\n",
      "(10210, 70)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "print(holdout_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "322f5289-e845-4107-ac3d-d821e5737e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>aniongap</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>bun</th>\n",
       "      <th>calcium</th>\n",
       "      <th>chloride</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>glucose</th>\n",
       "      <th>sodium</th>\n",
       "      <th>...</th>\n",
       "      <th>first_careunit_Coronary Care Unit (CCU)</th>\n",
       "      <th>first_careunit_Medical Intensive Care Unit (MICU)</th>\n",
       "      <th>first_careunit_Medical/Surgical Intensive Care Unit (MICU/SICU)</th>\n",
       "      <th>first_careunit_Neuro Intermediate</th>\n",
       "      <th>first_careunit_Neuro Stepdown</th>\n",
       "      <th>first_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)</th>\n",
       "      <th>first_careunit_Surgical Intensive Care Unit (SICU)</th>\n",
       "      <th>first_careunit_Trauma SICU (TSICU)</th>\n",
       "      <th>hour</th>\n",
       "      <th>icu_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001305</td>\n",
       "      <td>1978-03-25 08:20:00</td>\n",
       "      <td>15</td>\n",
       "      <td>23.0</td>\n",
       "      <td>47</td>\n",
       "      <td>11.4</td>\n",
       "      <td>108</td>\n",
       "      <td>0.8</td>\n",
       "      <td>154</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.350000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001305</td>\n",
       "      <td>1978-03-25 08:20:00</td>\n",
       "      <td>15</td>\n",
       "      <td>23.0</td>\n",
       "      <td>47</td>\n",
       "      <td>11.4</td>\n",
       "      <td>108</td>\n",
       "      <td>0.8</td>\n",
       "      <td>154</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.350000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001305</td>\n",
       "      <td>1978-03-25 08:20:00</td>\n",
       "      <td>15</td>\n",
       "      <td>23.0</td>\n",
       "      <td>47</td>\n",
       "      <td>11.4</td>\n",
       "      <td>108</td>\n",
       "      <td>0.8</td>\n",
       "      <td>154</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.350000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001305</td>\n",
       "      <td>1978-03-25 13:45:00</td>\n",
       "      <td>13</td>\n",
       "      <td>25.0</td>\n",
       "      <td>48</td>\n",
       "      <td>10.8</td>\n",
       "      <td>107</td>\n",
       "      <td>0.9</td>\n",
       "      <td>149</td>\n",
       "      <td>140</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.766667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001305</td>\n",
       "      <td>1978-03-25 21:55:00</td>\n",
       "      <td>13</td>\n",
       "      <td>24.0</td>\n",
       "      <td>50</td>\n",
       "      <td>10.8</td>\n",
       "      <td>108</td>\n",
       "      <td>0.9</td>\n",
       "      <td>131</td>\n",
       "      <td>141</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.933333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20001361</td>\n",
       "      <td>2043-05-04 17:24:00</td>\n",
       "      <td>14</td>\n",
       "      <td>22.0</td>\n",
       "      <td>28</td>\n",
       "      <td>6.3</td>\n",
       "      <td>107</td>\n",
       "      <td>2.5</td>\n",
       "      <td>161</td>\n",
       "      <td>137</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20001361</td>\n",
       "      <td>2043-05-04 21:07:00</td>\n",
       "      <td>15</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32</td>\n",
       "      <td>6.5</td>\n",
       "      <td>108</td>\n",
       "      <td>2.5</td>\n",
       "      <td>124</td>\n",
       "      <td>137</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20001361</td>\n",
       "      <td>2043-05-05 04:27:00</td>\n",
       "      <td>15</td>\n",
       "      <td>23.0</td>\n",
       "      <td>36</td>\n",
       "      <td>7.2</td>\n",
       "      <td>108</td>\n",
       "      <td>2.9</td>\n",
       "      <td>98</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.583333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20001361</td>\n",
       "      <td>2043-05-05 11:50:00</td>\n",
       "      <td>15</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27</td>\n",
       "      <td>8.4</td>\n",
       "      <td>107</td>\n",
       "      <td>1.3</td>\n",
       "      <td>134</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.966667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20001361</td>\n",
       "      <td>2043-05-05 15:02:00</td>\n",
       "      <td>18</td>\n",
       "      <td>23.0</td>\n",
       "      <td>40</td>\n",
       "      <td>7.9</td>\n",
       "      <td>107</td>\n",
       "      <td>3.7</td>\n",
       "      <td>123</td>\n",
       "      <td>144</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.166667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id            charttime  aniongap  bicarbonate  bun  calcium  \\\n",
       "0  20001305  1978-03-25 08:20:00        15         23.0   47     11.4   \n",
       "1  20001305  1978-03-25 08:20:00        15         23.0   47     11.4   \n",
       "2  20001305  1978-03-25 08:20:00        15         23.0   47     11.4   \n",
       "3  20001305  1978-03-25 13:45:00        13         25.0   48     10.8   \n",
       "4  20001305  1978-03-25 21:55:00        13         24.0   50     10.8   \n",
       "5  20001361  2043-05-04 17:24:00        14         22.0   28      6.3   \n",
       "6  20001361  2043-05-04 21:07:00        15         20.0   32      6.5   \n",
       "7  20001361  2043-05-05 04:27:00        15         23.0   36      7.2   \n",
       "8  20001361  2043-05-05 11:50:00        15         23.0   27      8.4   \n",
       "9  20001361  2043-05-05 15:02:00        18         23.0   40      7.9   \n",
       "\n",
       "   chloride  creatinine  glucose  sodium  ...  \\\n",
       "0       108         0.8      154     142  ...   \n",
       "1       108         0.8      154     142  ...   \n",
       "2       108         0.8      154     142  ...   \n",
       "3       107         0.9      149     140  ...   \n",
       "4       108         0.9      131     141  ...   \n",
       "5       107         2.5      161     137  ...   \n",
       "6       108         2.5      124     137  ...   \n",
       "7       108         2.9       98     142  ...   \n",
       "8       107         1.3      134     142  ...   \n",
       "9       107         3.7      123     144  ...   \n",
       "\n",
       "   first_careunit_Coronary Care Unit (CCU)  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "5                                        0   \n",
       "6                                        0   \n",
       "7                                        0   \n",
       "8                                        0   \n",
       "9                                        0   \n",
       "\n",
       "   first_careunit_Medical Intensive Care Unit (MICU)  \\\n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "5                                                  0   \n",
       "6                                                  0   \n",
       "7                                                  0   \n",
       "8                                                  0   \n",
       "9                                                  0   \n",
       "\n",
       "   first_careunit_Medical/Surgical Intensive Care Unit (MICU/SICU)  \\\n",
       "0                                                  1                 \n",
       "1                                                  1                 \n",
       "2                                                  1                 \n",
       "3                                                  1                 \n",
       "4                                                  1                 \n",
       "5                                                  1                 \n",
       "6                                                  1                 \n",
       "7                                                  1                 \n",
       "8                                                  1                 \n",
       "9                                                  1                 \n",
       "\n",
       "   first_careunit_Neuro Intermediate  first_careunit_Neuro Stepdown  \\\n",
       "0                                  0                              0   \n",
       "1                                  0                              0   \n",
       "2                                  0                              0   \n",
       "3                                  0                              0   \n",
       "4                                  0                              0   \n",
       "5                                  0                              0   \n",
       "6                                  0                              0   \n",
       "7                                  0                              0   \n",
       "8                                  0                              0   \n",
       "9                                  0                              0   \n",
       "\n",
       "   first_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)  \\\n",
       "0                                                  0                \n",
       "1                                                  0                \n",
       "2                                                  0                \n",
       "3                                                  0                \n",
       "4                                                  0                \n",
       "5                                                  0                \n",
       "6                                                  0                \n",
       "7                                                  0                \n",
       "8                                                  0                \n",
       "9                                                  0                \n",
       "\n",
       "   first_careunit_Surgical Intensive Care Unit (SICU)  \\\n",
       "0                                                  0    \n",
       "1                                                  0    \n",
       "2                                                  0    \n",
       "3                                                  0    \n",
       "4                                                  0    \n",
       "5                                                  0    \n",
       "6                                                  0    \n",
       "7                                                  0    \n",
       "8                                                  0    \n",
       "9                                                  0    \n",
       "\n",
       "   first_careunit_Trauma SICU (TSICU)       hour  icu_cat  \n",
       "0                                   0   5.350000        1  \n",
       "1                                   0   5.350000        1  \n",
       "2                                   0   5.350000        1  \n",
       "3                                   0  10.766667        1  \n",
       "4                                   0  18.933333        1  \n",
       "5                                   0   0.533333        2  \n",
       "6                                   0   4.250000        2  \n",
       "7                                   0  11.583333        2  \n",
       "8                                   0  18.966667        2  \n",
       "9                                   0  22.166667        2  \n",
       "\n",
       "[10 rows x 70 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c2e11c-d946-426b-a617-be4ccd7e8551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Converting los_icu into 3 categorical bins\n",
    "\n",
    "# low_thres = 2.5\n",
    "# medium_thres = 5\n",
    "\n",
    "# result_df['icu_cat'] = 10\n",
    "# result_df.loc[result_df['los_icu'] < low_thres, 'icu_cat'] = 0\n",
    "# result_df.loc[((result_df['los_icu'] >= low_thres) & (result_df['los_icu'] < medium_thres)), 'icu_cat'] = 1\n",
    "# result_df.loc[result_df['los_icu'] >= medium_thres, 'icu_cat'] = 2\n",
    "\n",
    "# # test_df['icu_cat'] = 10\n",
    "# # test_df.loc[test_df['los_icu'] < low_thres, 'icu_cat'] = 0\n",
    "# # test_df.loc[((test_df['los_icu'] >= low_thres) & (test_df['los_icu'] < medium_thres)), 'icu_cat'] = 1\n",
    "# # test_df.loc[test_df['los_icu'] >= medium_thres, 'icu_cat'] = 2\n",
    "\n",
    "# holdout_df['icu_cat'] = 10\n",
    "# holdout_df.loc[holdout_df['los_icu'] < low_thres, 'icu_cat'] = 0\n",
    "# holdout_df.loc[((holdout_df['los_icu'] >= low_thres) & (holdout_df['los_icu'] < medium_thres)), 'icu_cat'] = 1\n",
    "# holdout_df.loc[holdout_df['los_icu'] >= medium_thres, 'icu_cat'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fde6823-dcb1-4e90-9179-546ea5ff7412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting los_icu into 2 categorical bins\n",
    "\n",
    "low_thres = 7\n",
    "medium_thres = None\n",
    "\n",
    "train_df['icu_cat'] = 10\n",
    "train_df.loc[train_df['los_icu'] <= low_thres, 'icu_cat'] = 0\n",
    "train_df.loc[train_df['los_icu'] > low_thres, 'icu_cat'] = 1\n",
    "\n",
    "test_df['icu_cat'] = 10\n",
    "test_df.loc[test_df['los_icu'] <= low_thres, 'icu_cat'] = 0\n",
    "test_df.loc[test_df['los_icu'] > low_thres, 'icu_cat'] = 1\n",
    "\n",
    "holdout_df['icu_cat'] = 10\n",
    "holdout_df.loc[holdout_df['los_icu'] <= low_thres, 'icu_cat'] = 0\n",
    "holdout_df.loc[holdout_df['los_icu'] > low_thres, 'icu_cat'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad002bc2-9833-403b-afd8-d9924b3a19e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71445, 70)\n",
      "(20415, 70)\n",
      "(10210, 70)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>aniongap</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>bun</th>\n",
       "      <th>calcium</th>\n",
       "      <th>chloride</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>glucose</th>\n",
       "      <th>sodium</th>\n",
       "      <th>...</th>\n",
       "      <th>first_careunit_Coronary Care Unit (CCU)</th>\n",
       "      <th>first_careunit_Medical Intensive Care Unit (MICU)</th>\n",
       "      <th>first_careunit_Medical/Surgical Intensive Care Unit (MICU/SICU)</th>\n",
       "      <th>first_careunit_Neuro Intermediate</th>\n",
       "      <th>first_careunit_Neuro Stepdown</th>\n",
       "      <th>first_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)</th>\n",
       "      <th>first_careunit_Surgical Intensive Care Unit (SICU)</th>\n",
       "      <th>first_careunit_Trauma SICU (TSICU)</th>\n",
       "      <th>hour</th>\n",
       "      <th>icu_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001305</td>\n",
       "      <td>1978-03-25 08:20:00</td>\n",
       "      <td>15</td>\n",
       "      <td>23.0</td>\n",
       "      <td>47</td>\n",
       "      <td>11.4</td>\n",
       "      <td>108</td>\n",
       "      <td>0.8</td>\n",
       "      <td>154</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.350000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001305</td>\n",
       "      <td>1978-03-25 08:20:00</td>\n",
       "      <td>15</td>\n",
       "      <td>23.0</td>\n",
       "      <td>47</td>\n",
       "      <td>11.4</td>\n",
       "      <td>108</td>\n",
       "      <td>0.8</td>\n",
       "      <td>154</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.350000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001305</td>\n",
       "      <td>1978-03-25 08:20:00</td>\n",
       "      <td>15</td>\n",
       "      <td>23.0</td>\n",
       "      <td>47</td>\n",
       "      <td>11.4</td>\n",
       "      <td>108</td>\n",
       "      <td>0.8</td>\n",
       "      <td>154</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.350000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001305</td>\n",
       "      <td>1978-03-25 13:45:00</td>\n",
       "      <td>13</td>\n",
       "      <td>25.0</td>\n",
       "      <td>48</td>\n",
       "      <td>10.8</td>\n",
       "      <td>107</td>\n",
       "      <td>0.9</td>\n",
       "      <td>149</td>\n",
       "      <td>140</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.766667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001305</td>\n",
       "      <td>1978-03-25 21:55:00</td>\n",
       "      <td>13</td>\n",
       "      <td>24.0</td>\n",
       "      <td>50</td>\n",
       "      <td>10.8</td>\n",
       "      <td>108</td>\n",
       "      <td>0.9</td>\n",
       "      <td>131</td>\n",
       "      <td>141</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.933333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20001361</td>\n",
       "      <td>2043-05-04 17:24:00</td>\n",
       "      <td>14</td>\n",
       "      <td>22.0</td>\n",
       "      <td>28</td>\n",
       "      <td>6.3</td>\n",
       "      <td>107</td>\n",
       "      <td>2.5</td>\n",
       "      <td>161</td>\n",
       "      <td>137</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20001361</td>\n",
       "      <td>2043-05-04 21:07:00</td>\n",
       "      <td>15</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32</td>\n",
       "      <td>6.5</td>\n",
       "      <td>108</td>\n",
       "      <td>2.5</td>\n",
       "      <td>124</td>\n",
       "      <td>137</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20001361</td>\n",
       "      <td>2043-05-05 04:27:00</td>\n",
       "      <td>15</td>\n",
       "      <td>23.0</td>\n",
       "      <td>36</td>\n",
       "      <td>7.2</td>\n",
       "      <td>108</td>\n",
       "      <td>2.9</td>\n",
       "      <td>98</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.583333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20001361</td>\n",
       "      <td>2043-05-05 11:50:00</td>\n",
       "      <td>15</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27</td>\n",
       "      <td>8.4</td>\n",
       "      <td>107</td>\n",
       "      <td>1.3</td>\n",
       "      <td>134</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.966667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20001361</td>\n",
       "      <td>2043-05-05 15:02:00</td>\n",
       "      <td>18</td>\n",
       "      <td>23.0</td>\n",
       "      <td>40</td>\n",
       "      <td>7.9</td>\n",
       "      <td>107</td>\n",
       "      <td>3.7</td>\n",
       "      <td>123</td>\n",
       "      <td>144</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id            charttime  aniongap  bicarbonate  bun  calcium  \\\n",
       "0  20001305  1978-03-25 08:20:00        15         23.0   47     11.4   \n",
       "1  20001305  1978-03-25 08:20:00        15         23.0   47     11.4   \n",
       "2  20001305  1978-03-25 08:20:00        15         23.0   47     11.4   \n",
       "3  20001305  1978-03-25 13:45:00        13         25.0   48     10.8   \n",
       "4  20001305  1978-03-25 21:55:00        13         24.0   50     10.8   \n",
       "5  20001361  2043-05-04 17:24:00        14         22.0   28      6.3   \n",
       "6  20001361  2043-05-04 21:07:00        15         20.0   32      6.5   \n",
       "7  20001361  2043-05-05 04:27:00        15         23.0   36      7.2   \n",
       "8  20001361  2043-05-05 11:50:00        15         23.0   27      8.4   \n",
       "9  20001361  2043-05-05 15:02:00        18         23.0   40      7.9   \n",
       "\n",
       "   chloride  creatinine  glucose  sodium  ...  \\\n",
       "0       108         0.8      154     142  ...   \n",
       "1       108         0.8      154     142  ...   \n",
       "2       108         0.8      154     142  ...   \n",
       "3       107         0.9      149     140  ...   \n",
       "4       108         0.9      131     141  ...   \n",
       "5       107         2.5      161     137  ...   \n",
       "6       108         2.5      124     137  ...   \n",
       "7       108         2.9       98     142  ...   \n",
       "8       107         1.3      134     142  ...   \n",
       "9       107         3.7      123     144  ...   \n",
       "\n",
       "   first_careunit_Coronary Care Unit (CCU)  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "5                                        0   \n",
       "6                                        0   \n",
       "7                                        0   \n",
       "8                                        0   \n",
       "9                                        0   \n",
       "\n",
       "   first_careunit_Medical Intensive Care Unit (MICU)  \\\n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "5                                                  0   \n",
       "6                                                  0   \n",
       "7                                                  0   \n",
       "8                                                  0   \n",
       "9                                                  0   \n",
       "\n",
       "   first_careunit_Medical/Surgical Intensive Care Unit (MICU/SICU)  \\\n",
       "0                                                  1                 \n",
       "1                                                  1                 \n",
       "2                                                  1                 \n",
       "3                                                  1                 \n",
       "4                                                  1                 \n",
       "5                                                  1                 \n",
       "6                                                  1                 \n",
       "7                                                  1                 \n",
       "8                                                  1                 \n",
       "9                                                  1                 \n",
       "\n",
       "   first_careunit_Neuro Intermediate  first_careunit_Neuro Stepdown  \\\n",
       "0                                  0                              0   \n",
       "1                                  0                              0   \n",
       "2                                  0                              0   \n",
       "3                                  0                              0   \n",
       "4                                  0                              0   \n",
       "5                                  0                              0   \n",
       "6                                  0                              0   \n",
       "7                                  0                              0   \n",
       "8                                  0                              0   \n",
       "9                                  0                              0   \n",
       "\n",
       "   first_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)  \\\n",
       "0                                                  0                \n",
       "1                                                  0                \n",
       "2                                                  0                \n",
       "3                                                  0                \n",
       "4                                                  0                \n",
       "5                                                  0                \n",
       "6                                                  0                \n",
       "7                                                  0                \n",
       "8                                                  0                \n",
       "9                                                  0                \n",
       "\n",
       "   first_careunit_Surgical Intensive Care Unit (SICU)  \\\n",
       "0                                                  0    \n",
       "1                                                  0    \n",
       "2                                                  0    \n",
       "3                                                  0    \n",
       "4                                                  0    \n",
       "5                                                  0    \n",
       "6                                                  0    \n",
       "7                                                  0    \n",
       "8                                                  0    \n",
       "9                                                  0    \n",
       "\n",
       "   first_careunit_Trauma SICU (TSICU)       hour  icu_cat  \n",
       "0                                   0   5.350000        0  \n",
       "1                                   0   5.350000        0  \n",
       "2                                   0   5.350000        0  \n",
       "3                                   0  10.766667        0  \n",
       "4                                   0  18.933333        0  \n",
       "5                                   0   0.533333        0  \n",
       "6                                   0   4.250000        0  \n",
       "7                                   0  11.583333        0  \n",
       "8                                   0  18.966667        0  \n",
       "9                                   0  22.166667        0  \n",
       "\n",
       "[10 rows x 70 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "print(holdout_df.shape)\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ffada-7f34-4801-ab71-ffe579c4f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# holdout_df = holdout_df.drop(columns=['icu_outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3fc32f3-5e09-42a7-aafa-b29a6b5b60a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(result_df.shape)\n",
    "# print(test_df.shape)\n",
    "# print(holdout_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fbbc2bc4-deee-4f2e-bb21-061095cc0e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>aniongap</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>bun</th>\n",
       "      <th>calcium</th>\n",
       "      <th>chloride</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>glucose</th>\n",
       "      <th>sodium</th>\n",
       "      <th>...</th>\n",
       "      <th>first_careunit_Coronary Care Unit (CCU)</th>\n",
       "      <th>first_careunit_Medical Intensive Care Unit (MICU)</th>\n",
       "      <th>first_careunit_Medical/Surgical Intensive Care Unit (MICU/SICU)</th>\n",
       "      <th>first_careunit_Neuro Intermediate</th>\n",
       "      <th>first_careunit_Neuro Stepdown</th>\n",
       "      <th>first_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)</th>\n",
       "      <th>first_careunit_Surgical Intensive Care Unit (SICU)</th>\n",
       "      <th>first_careunit_Trauma SICU (TSICU)</th>\n",
       "      <th>hour</th>\n",
       "      <th>icu_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001770</td>\n",
       "      <td>2017-01-26 03:56:00</td>\n",
       "      <td>14</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23</td>\n",
       "      <td>7.4</td>\n",
       "      <td>86</td>\n",
       "      <td>1.3</td>\n",
       "      <td>80</td>\n",
       "      <td>122.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.150000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001770</td>\n",
       "      <td>2017-01-26 03:56:00</td>\n",
       "      <td>14</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23</td>\n",
       "      <td>7.4</td>\n",
       "      <td>86</td>\n",
       "      <td>1.3</td>\n",
       "      <td>80</td>\n",
       "      <td>122.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.150000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001770</td>\n",
       "      <td>2017-01-26 03:56:00</td>\n",
       "      <td>14</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23</td>\n",
       "      <td>7.4</td>\n",
       "      <td>86</td>\n",
       "      <td>1.3</td>\n",
       "      <td>80</td>\n",
       "      <td>122.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.150000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001770</td>\n",
       "      <td>2017-01-26 03:56:00</td>\n",
       "      <td>14</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23</td>\n",
       "      <td>7.4</td>\n",
       "      <td>86</td>\n",
       "      <td>1.3</td>\n",
       "      <td>80</td>\n",
       "      <td>122.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.150000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001770</td>\n",
       "      <td>2017-01-26 03:56:00</td>\n",
       "      <td>14</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23</td>\n",
       "      <td>7.4</td>\n",
       "      <td>86</td>\n",
       "      <td>1.3</td>\n",
       "      <td>80</td>\n",
       "      <td>122.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.150000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20004357</td>\n",
       "      <td>2057-08-05 16:37:00</td>\n",
       "      <td>21</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24</td>\n",
       "      <td>9.9</td>\n",
       "      <td>101</td>\n",
       "      <td>1.1</td>\n",
       "      <td>177</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20004357</td>\n",
       "      <td>2057-08-05 16:37:00</td>\n",
       "      <td>21</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24</td>\n",
       "      <td>9.9</td>\n",
       "      <td>101</td>\n",
       "      <td>1.1</td>\n",
       "      <td>177</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20004357</td>\n",
       "      <td>2057-08-05 16:37:00</td>\n",
       "      <td>21</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24</td>\n",
       "      <td>9.9</td>\n",
       "      <td>101</td>\n",
       "      <td>1.1</td>\n",
       "      <td>177</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20004357</td>\n",
       "      <td>2057-08-05 16:37:00</td>\n",
       "      <td>21</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24</td>\n",
       "      <td>9.9</td>\n",
       "      <td>101</td>\n",
       "      <td>1.1</td>\n",
       "      <td>177</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20004357</td>\n",
       "      <td>2057-08-06 04:35:00</td>\n",
       "      <td>12</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29</td>\n",
       "      <td>9.2</td>\n",
       "      <td>105</td>\n",
       "      <td>1.1</td>\n",
       "      <td>155</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.216667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20008098</td>\n",
       "      <td>1975-02-09 01:25:00</td>\n",
       "      <td>19</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15</td>\n",
       "      <td>8.6</td>\n",
       "      <td>89</td>\n",
       "      <td>0.8</td>\n",
       "      <td>118</td>\n",
       "      <td>125.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-12.933333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20008098</td>\n",
       "      <td>1975-02-09 06:30:00</td>\n",
       "      <td>21</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14</td>\n",
       "      <td>8.8</td>\n",
       "      <td>94</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108</td>\n",
       "      <td>130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.850000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20008098</td>\n",
       "      <td>1975-02-09 12:40:00</td>\n",
       "      <td>19</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17</td>\n",
       "      <td>8.8</td>\n",
       "      <td>92</td>\n",
       "      <td>0.8</td>\n",
       "      <td>125</td>\n",
       "      <td>129.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.683333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20008098</td>\n",
       "      <td>1975-02-09 18:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20</td>\n",
       "      <td>8.6</td>\n",
       "      <td>95</td>\n",
       "      <td>0.8</td>\n",
       "      <td>115</td>\n",
       "      <td>131.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20008098</td>\n",
       "      <td>1975-02-10 02:10:00</td>\n",
       "      <td>18</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21</td>\n",
       "      <td>7.1</td>\n",
       "      <td>103</td>\n",
       "      <td>0.6</td>\n",
       "      <td>108</td>\n",
       "      <td>136.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.816667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20013839</td>\n",
       "      <td>2018-07-07 08:32:00</td>\n",
       "      <td>14</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9</td>\n",
       "      <td>8.5</td>\n",
       "      <td>98</td>\n",
       "      <td>0.8</td>\n",
       "      <td>140</td>\n",
       "      <td>135.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20013839</td>\n",
       "      <td>2018-07-07 08:32:00</td>\n",
       "      <td>14</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9</td>\n",
       "      <td>8.5</td>\n",
       "      <td>98</td>\n",
       "      <td>0.8</td>\n",
       "      <td>140</td>\n",
       "      <td>135.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20013839</td>\n",
       "      <td>2018-07-07 08:32:00</td>\n",
       "      <td>14</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9</td>\n",
       "      <td>8.5</td>\n",
       "      <td>98</td>\n",
       "      <td>0.8</td>\n",
       "      <td>140</td>\n",
       "      <td>135.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20013839</td>\n",
       "      <td>2018-07-07 08:32:00</td>\n",
       "      <td>14</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9</td>\n",
       "      <td>8.5</td>\n",
       "      <td>98</td>\n",
       "      <td>0.8</td>\n",
       "      <td>140</td>\n",
       "      <td>135.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20013839</td>\n",
       "      <td>2018-07-08 02:45:00</td>\n",
       "      <td>13</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9</td>\n",
       "      <td>8.4</td>\n",
       "      <td>105</td>\n",
       "      <td>0.7</td>\n",
       "      <td>140</td>\n",
       "      <td>143.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id            charttime  aniongap  bicarbonate  bun  calcium  \\\n",
       "0   20001770  2017-01-26 03:56:00        14         22.0   23      7.4   \n",
       "1   20001770  2017-01-26 03:56:00        14         22.0   23      7.4   \n",
       "2   20001770  2017-01-26 03:56:00        14         22.0   23      7.4   \n",
       "3   20001770  2017-01-26 03:56:00        14         22.0   23      7.4   \n",
       "4   20001770  2017-01-26 03:56:00        14         22.0   23      7.4   \n",
       "5   20004357  2057-08-05 16:37:00        21         24.0   24      9.9   \n",
       "6   20004357  2057-08-05 16:37:00        21         24.0   24      9.9   \n",
       "7   20004357  2057-08-05 16:37:00        21         24.0   24      9.9   \n",
       "8   20004357  2057-08-05 16:37:00        21         24.0   24      9.9   \n",
       "9   20004357  2057-08-06 04:35:00        12         29.0   29      9.2   \n",
       "10  20008098  1975-02-09 01:25:00        19         21.0   15      8.6   \n",
       "11  20008098  1975-02-09 06:30:00        21         20.0   14      8.8   \n",
       "12  20008098  1975-02-09 12:40:00        19         23.0   17      8.8   \n",
       "13  20008098  1975-02-09 18:00:00        19         21.0   20      8.6   \n",
       "14  20008098  1975-02-10 02:10:00        18         19.0   21      7.1   \n",
       "15  20013839  2018-07-07 08:32:00        14         27.0    9      8.5   \n",
       "16  20013839  2018-07-07 08:32:00        14         27.0    9      8.5   \n",
       "17  20013839  2018-07-07 08:32:00        14         27.0    9      8.5   \n",
       "18  20013839  2018-07-07 08:32:00        14         27.0    9      8.5   \n",
       "19  20013839  2018-07-08 02:45:00        13         28.0    9      8.4   \n",
       "\n",
       "    chloride  creatinine  glucose  sodium  ...  \\\n",
       "0         86         1.3       80   122.0  ...   \n",
       "1         86         1.3       80   122.0  ...   \n",
       "2         86         1.3       80   122.0  ...   \n",
       "3         86         1.3       80   122.0  ...   \n",
       "4         86         1.3       80   122.0  ...   \n",
       "5        101         1.1      177   142.0  ...   \n",
       "6        101         1.1      177   142.0  ...   \n",
       "7        101         1.1      177   142.0  ...   \n",
       "8        101         1.1      177   142.0  ...   \n",
       "9        105         1.1      155   142.0  ...   \n",
       "10        89         0.8      118   125.0  ...   \n",
       "11        94         0.7      108   130.0  ...   \n",
       "12        92         0.8      125   129.0  ...   \n",
       "13        95         0.8      115   131.0  ...   \n",
       "14       103         0.6      108   136.0  ...   \n",
       "15        98         0.8      140   135.0  ...   \n",
       "16        98         0.8      140   135.0  ...   \n",
       "17        98         0.8      140   135.0  ...   \n",
       "18        98         0.8      140   135.0  ...   \n",
       "19       105         0.7      140   143.0  ...   \n",
       "\n",
       "    first_careunit_Coronary Care Unit (CCU)  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "5                                         0   \n",
       "6                                         0   \n",
       "7                                         0   \n",
       "8                                         0   \n",
       "9                                         0   \n",
       "10                                        0   \n",
       "11                                        0   \n",
       "12                                        0   \n",
       "13                                        0   \n",
       "14                                        0   \n",
       "15                                        0   \n",
       "16                                        0   \n",
       "17                                        0   \n",
       "18                                        0   \n",
       "19                                        0   \n",
       "\n",
       "    first_careunit_Medical Intensive Care Unit (MICU)  \\\n",
       "0                                                   0   \n",
       "1                                                   0   \n",
       "2                                                   0   \n",
       "3                                                   0   \n",
       "4                                                   0   \n",
       "5                                                   1   \n",
       "6                                                   1   \n",
       "7                                                   1   \n",
       "8                                                   1   \n",
       "9                                                   1   \n",
       "10                                                  0   \n",
       "11                                                  0   \n",
       "12                                                  0   \n",
       "13                                                  0   \n",
       "14                                                  0   \n",
       "15                                                  0   \n",
       "16                                                  0   \n",
       "17                                                  0   \n",
       "18                                                  0   \n",
       "19                                                  0   \n",
       "\n",
       "    first_careunit_Medical/Surgical Intensive Care Unit (MICU/SICU)  \\\n",
       "0                                                   0                 \n",
       "1                                                   0                 \n",
       "2                                                   0                 \n",
       "3                                                   0                 \n",
       "4                                                   0                 \n",
       "5                                                   0                 \n",
       "6                                                   0                 \n",
       "7                                                   0                 \n",
       "8                                                   0                 \n",
       "9                                                   0                 \n",
       "10                                                  0                 \n",
       "11                                                  0                 \n",
       "12                                                  0                 \n",
       "13                                                  0                 \n",
       "14                                                  0                 \n",
       "15                                                  0                 \n",
       "16                                                  0                 \n",
       "17                                                  0                 \n",
       "18                                                  0                 \n",
       "19                                                  0                 \n",
       "\n",
       "    first_careunit_Neuro Intermediate  first_careunit_Neuro Stepdown  \\\n",
       "0                                   0                              0   \n",
       "1                                   0                              0   \n",
       "2                                   0                              0   \n",
       "3                                   0                              0   \n",
       "4                                   0                              0   \n",
       "5                                   0                              0   \n",
       "6                                   0                              0   \n",
       "7                                   0                              0   \n",
       "8                                   0                              0   \n",
       "9                                   0                              0   \n",
       "10                                  0                              0   \n",
       "11                                  0                              0   \n",
       "12                                  0                              0   \n",
       "13                                  0                              0   \n",
       "14                                  0                              0   \n",
       "15                                  0                              0   \n",
       "16                                  0                              0   \n",
       "17                                  0                              0   \n",
       "18                                  0                              0   \n",
       "19                                  0                              0   \n",
       "\n",
       "    first_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)  \\\n",
       "0                                                   0                \n",
       "1                                                   0                \n",
       "2                                                   0                \n",
       "3                                                   0                \n",
       "4                                                   0                \n",
       "5                                                   0                \n",
       "6                                                   0                \n",
       "7                                                   0                \n",
       "8                                                   0                \n",
       "9                                                   0                \n",
       "10                                                  0                \n",
       "11                                                  0                \n",
       "12                                                  0                \n",
       "13                                                  0                \n",
       "14                                                  0                \n",
       "15                                                  0                \n",
       "16                                                  0                \n",
       "17                                                  0                \n",
       "18                                                  0                \n",
       "19                                                  0                \n",
       "\n",
       "    first_careunit_Surgical Intensive Care Unit (SICU)  \\\n",
       "0                                                   1    \n",
       "1                                                   1    \n",
       "2                                                   1    \n",
       "3                                                   1    \n",
       "4                                                   1    \n",
       "5                                                   0    \n",
       "6                                                   0    \n",
       "7                                                   0    \n",
       "8                                                   0    \n",
       "9                                                   0    \n",
       "10                                                  1    \n",
       "11                                                  1    \n",
       "12                                                  1    \n",
       "13                                                  1    \n",
       "14                                                  1    \n",
       "15                                                  0    \n",
       "16                                                  0    \n",
       "17                                                  0    \n",
       "18                                                  0    \n",
       "19                                                  0    \n",
       "\n",
       "    first_careunit_Trauma SICU (TSICU)       hour  icu_cat  \n",
       "0                                    0   7.150000        1  \n",
       "1                                    0   7.150000        1  \n",
       "2                                    0   7.150000        1  \n",
       "3                                    0   7.150000        1  \n",
       "4                                    0   7.150000        1  \n",
       "5                                    0   4.250000        1  \n",
       "6                                    0   4.250000        1  \n",
       "7                                    0   4.250000        1  \n",
       "8                                    0   4.250000        1  \n",
       "9                                    0  16.216667        1  \n",
       "10                                   0 -12.933333        0  \n",
       "11                                   0  -7.850000        0  \n",
       "12                                   0  -1.683333        0  \n",
       "13                                   0   3.650000        0  \n",
       "14                                   0  11.816667        0  \n",
       "15                                   1   1.033333        0  \n",
       "16                                   1   1.033333        0  \n",
       "17                                   1   1.033333        0  \n",
       "18                                   1   1.033333        0  \n",
       "19                                   1  19.250000        0  \n",
       "\n",
       "[20 rows x 70 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # sorting hours to ascending order\n",
    "\n",
    "# train_df = train_df.sort_values(by=['id', 'hour'], ascending=[True, True])\n",
    "# test_df = test_df.sort_values(by=['id', 'hour'], ascending=[True, True])\n",
    "# holdout_df = holdout_df.sort_values(by=['id', 'hour'], ascending=[True, True])\n",
    "\n",
    "# train_df.reset_index(drop=True, inplace=True)\n",
    "# test_df.reset_index(drop=True, inplace=True)\n",
    "# holdout_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# test_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7dbfeac-7f8e-48f7-8d7b-7a2bc3600b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Can also Start here - load processed timestep5 data\n",
    "\n",
    "# train_df.to_excel('Timestep5_train.xlsx', index=False)\n",
    "# test_df.to_excel('Timestep5_test.xlsx', index=False)\n",
    "# holdout_df.to_excel('Timestep5_holdout.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f82c1b9-5556-4188-aa06-0af00d1d5314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71445, 59)\n",
      "(20415, 59)\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['id',\n",
    "                   'charttime',\n",
    "                   'hour',\n",
    "                   'icu_cat',\n",
    "                   'hosp_admittime',\n",
    "                   'hosp_dischtime',\n",
    "                   'icu_intime',\n",
    "                   'icu_outtime',\n",
    "                   'los_icu',\n",
    "                   'icu_death',\n",
    "                   'race'\n",
    "                  ]\n",
    "\n",
    "X_train_df = train_df.drop(columns=columns_to_drop)\n",
    "X_test_df = test_df.drop(columns=columns_to_drop)\n",
    "X_holdout_df = holdout_df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(X_train_df.shape)\n",
    "print(X_test_df.shape)\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0998b34d-4765-446e-821e-3e8ea6c67a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform normalization using data from X_train to transform X_test\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_cols = X_train_df.columns[X_train_df.dtypes.apply(lambda c: np.issubdtype(c, np.number))]\n",
    "# print(num_cols)\n",
    "scaler = StandardScaler()\n",
    "X_train_df[num_cols] = scaler.fit_transform(X_train_df[num_cols])\n",
    "X_test_df[num_cols] = scaler.transform(X_test_df[num_cols])\n",
    "X_holdout_df[num_cols] = scaler.transform(X_holdout_df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8307768a-6f3e-4f96-8290-5c4dd3116a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aniongap',\n",
       " 'bicarbonate',\n",
       " 'bun',\n",
       " 'calcium',\n",
       " 'chloride',\n",
       " 'creatinine',\n",
       " 'glucose',\n",
       " 'sodium',\n",
       " 'potassium',\n",
       " 'hematocrit',\n",
       " 'hemoglobin',\n",
       " 'mch',\n",
       " 'mchc',\n",
       " 'mcv',\n",
       " 'platelet',\n",
       " 'rbc',\n",
       " 'rdw',\n",
       " 'wbc',\n",
       " 'inr',\n",
       " 'pt',\n",
       " 'ptt',\n",
       " 'gender',\n",
       " 'admission_age',\n",
       " 'weight_admit',\n",
       " 'height',\n",
       " 'charlson_score',\n",
       " 'atrial_fibrillation',\n",
       " 'malignant_cancer',\n",
       " 'chf',\n",
       " 'ckd',\n",
       " 'cld',\n",
       " 'copd',\n",
       " 'diabetes',\n",
       " 'hypertension',\n",
       " 'ihd',\n",
       " 'stroke',\n",
       " 'race_encode_African',\n",
       " 'race_encode_Asian',\n",
       " 'race_encode_Caucasian',\n",
       " 'race_encode_Hispanic',\n",
       " 'race_encode_Not Specified',\n",
       " 'race_encode_South American',\n",
       " 'admission_type_DIRECT EMER.',\n",
       " 'admission_type_DIRECT OBSERVATION',\n",
       " 'admission_type_ELECTIVE',\n",
       " 'admission_type_EU OBSERVATION',\n",
       " 'admission_type_EW EMER.',\n",
       " 'admission_type_OBSERVATION ADMIT',\n",
       " 'admission_type_SURGICAL SAME DAY ADMISSION',\n",
       " 'admission_type_URGENT',\n",
       " 'first_careunit_Cardiac Vascular Intensive Care Unit (CVICU)',\n",
       " 'first_careunit_Coronary Care Unit (CCU)',\n",
       " 'first_careunit_Medical Intensive Care Unit (MICU)',\n",
       " 'first_careunit_Medical/Surgical Intensive Care Unit (MICU/SICU)',\n",
       " 'first_careunit_Neuro Intermediate',\n",
       " 'first_careunit_Neuro Stepdown',\n",
       " 'first_careunit_Neuro Surgical Intensive Care Unit (Neuro SICU)',\n",
       " 'first_careunit_Surgical Intensive Care Unit (SICU)',\n",
       " 'first_careunit_Trauma SICU (TSICU)']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_df = X_df.drop(columns=['race'])\n",
    "X_train_df.dtypes\n",
    "X_train_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b293e67-f287-4dc8-afe2-de439c483064",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# steps = 5\n",
    "\n",
    "# numpy_data = X_df.values\n",
    "\n",
    "# print(len(numpy_data))\n",
    "# time_input = []\n",
    "# labels = []\n",
    "\n",
    "# for i in range(int(len(numpy_data)/steps)):\n",
    "#     sample = X_df.iloc[i*steps:i*steps+steps]\n",
    "#     label = result_df.iloc[i*steps][-1]\n",
    "#     time_input.append(sample)\n",
    "#     labels.append(label)\n",
    "\n",
    "# time_input = np.array(time_input)\n",
    "# labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2b44490-2cc3-4ba3-b39b-f62c9ddc1adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting training, testing and holdout data into 3D numpy array\n",
    "\n",
    "steps = 5\n",
    "\n",
    "numpy_train_data = X_train_df.values\n",
    "numpy_test_data = X_test_df.values\n",
    "numpy_holdout_data = X_holdout_df.values\n",
    "\n",
    "# print(len(numpy_data))\n",
    "X_train_input = []\n",
    "y_train = []\n",
    "X_test_input = []\n",
    "y_test = []\n",
    "X_holdout_input = []\n",
    "y_holdout = []\n",
    "\n",
    "\n",
    "for i in range(int(len(numpy_train_data)/steps)):\n",
    "    sample = X_train_df.iloc[i*steps:i*steps+steps]\n",
    "    label = train_df.iloc[i*steps][-1]\n",
    "    X_train_input.append(sample)\n",
    "    y_train.append(label)\n",
    "\n",
    "for i in range(int(len(numpy_test_data)/steps)):\n",
    "    sample = X_test_df.iloc[i*steps:i*steps+steps]\n",
    "    label = test_df.iloc[i*steps][-1]\n",
    "    X_test_input.append(sample)\n",
    "    y_test.append(label)\n",
    "\n",
    "for i in range(int(len(numpy_holdout_data)/steps)):\n",
    "    sample = X_holdout_df.iloc[i*steps:i*steps+steps]\n",
    "    label = holdout_df.iloc[i*steps][-1]\n",
    "    X_holdout_input.append(sample)\n",
    "    y_holdout.append(label)\n",
    "\n",
    "X_train_input = np.array(X_train_input)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test_input = np.array(X_test_input)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "X_holdout_input = np.array(X_holdout_input)\n",
    "y_holdout = np.array(y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a04b4b6-0057-424c-b5b6-d338fb80f490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14289, 5, 59)\n",
      "(4083, 5, 59)\n",
      "(2042, 5, 59)\n",
      "(14289,)\n",
      "(4083,)\n",
      "(2042,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_input.shape)\n",
    "print(X_test_input.shape)\n",
    "print(X_holdout_input.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_holdout.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac637c-1837-4c2b-904a-7056a3a551c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "902c4496-069d-4abd-90b5-7342720fa23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.09635218 -0.01836304  0.57357206 ... -0.14891649 -0.42154144\n",
      "   -0.37139068]\n",
      "  [-0.09635218 -0.01836304  0.57357206 ... -0.14891649 -0.42154144\n",
      "   -0.37139068]\n",
      "  [-0.09635218 -0.01836304  0.57357206 ... -0.14891649 -0.42154144\n",
      "   -0.37139068]\n",
      "  [-0.54658805  0.36974698  0.61426125 ... -0.14891649 -0.42154144\n",
      "   -0.37139068]\n",
      "  [-0.54658805  0.17569197  0.69563963 ... -0.14891649 -0.42154144\n",
      "   -0.37139068]]\n",
      "\n",
      " [[-0.32147012 -0.21241805 -0.19952254 ... -0.14891649 -0.42154144\n",
      "   -0.37139068]\n",
      "  [-0.09635218 -0.60052807 -0.03676578 ... -0.14891649 -0.42154144\n",
      "   -0.37139068]\n",
      "  [-0.09635218 -0.01836304  0.12599098 ... -0.14891649 -0.42154144\n",
      "   -0.37139068]\n",
      "  [-0.09635218 -0.01836304 -0.24021173 ... -0.14891649 -0.42154144\n",
      "   -0.37139068]\n",
      "  [ 0.57900163 -0.01836304  0.28874774 ... -0.14891649 -0.42154144\n",
      "   -0.37139068]]\n",
      "\n",
      " [[ 0.12876576 -0.21241805 -0.80986039 ...  6.715173   -0.42154144\n",
      "   -0.37139068]\n",
      "  [ 0.12876576 -0.21241805 -0.80986039 ...  6.715173   -0.42154144\n",
      "   -0.37139068]\n",
      "  [ 0.12876576 -0.21241805 -0.80986039 ...  6.715173   -0.42154144\n",
      "   -0.37139068]\n",
      "  [-0.09635218 -0.01836304 -0.24021173 ...  6.715173   -0.42154144\n",
      "   -0.37139068]\n",
      "  [-0.32147012 -0.21241805 -0.97261715 ...  6.715173   -0.42154144\n",
      "   -0.37139068]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.77170599  0.36974698 -0.7691712  ... -0.14891649 -0.42154144\n",
      "    2.6925824 ]\n",
      "  [-0.77170599  0.36974698 -0.7691712  ... -0.14891649 -0.42154144\n",
      "    2.6925824 ]\n",
      "  [-0.77170599  0.36974698 -0.7691712  ... -0.14891649 -0.42154144\n",
      "    2.6925824 ]\n",
      "  [-0.77170599  0.36974698 -0.7691712  ... -0.14891649 -0.42154144\n",
      "    2.6925824 ]\n",
      "  [-0.77170599  0.36974698 -0.7691712  ... -0.14891649 -0.42154144\n",
      "    2.6925824 ]]\n",
      "\n",
      " [[-0.54658805 -0.60052807 -0.3622793  ... -0.14891649 -0.42154144\n",
      "   -0.37139068]\n",
      "  [-0.54658805 -0.60052807 -0.3622793  ... -0.14891649 -0.42154144\n",
      "   -0.37139068]\n",
      "  [ 0.3538837  -1.18269311 -0.64710363 ... -0.14891649 -0.42154144\n",
      "   -0.37139068]\n",
      "  [ 0.57900163 -1.76485814 -0.64710363 ... -0.14891649 -0.42154144\n",
      "   -0.37139068]\n",
      "  [-1.4470598  -0.01836304 -0.56572525 ... -0.14891649 -0.42154144\n",
      "   -0.37139068]]\n",
      "\n",
      " [[ 0.3538837   1.34002203  0.37012611 ... -0.14891649 -0.42154144\n",
      "   -0.37139068]\n",
      "  [ 1.02923751  1.34002203  0.65495044 ... -0.14891649 -0.42154144\n",
      "   -0.37139068]\n",
      "  [ 1.70459132  0.757857    0.37012611 ... -0.14891649 -0.42154144\n",
      "   -0.37139068]\n",
      "  [ 0.57900163  1.14596702  0.57357206 ... -0.14891649 -0.42154144\n",
      "   -0.37139068]\n",
      "  [ 1.47947338  0.56380199  1.06184234 ... -0.14891649 -0.42154144\n",
      "   -0.37139068]]]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_input[:10])\n",
    "print(y_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9082c74-1024-4c6e-a250-6751d162b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c58c67f2-3473-4263-a289-9b95e1122c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngqin\\AppData\\Local\\Temp\\ipykernel_6852\\1248966963.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train, dtype=torch.long)\n",
      "C:\\Users\\ngqin\\AppData\\Local\\Temp\\ipykernel_6852\\1248966963.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(y_test, dtype=torch.long)\n",
      "C:\\Users\\ngqin\\AppData\\Local\\Temp\\ipykernel_6852\\1248966963.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_holdout = torch.tensor(y_holdout, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 1.1150\n",
      "Epoch [2/1000], Loss: 1.1093\n",
      "Epoch [3/1000], Loss: 1.1039\n",
      "Epoch [4/1000], Loss: 1.0987\n",
      "Epoch [5/1000], Loss: 1.0935\n",
      "Epoch [6/1000], Loss: 1.0882\n",
      "Epoch [7/1000], Loss: 1.0829\n",
      "Epoch [8/1000], Loss: 1.0775\n",
      "Epoch [9/1000], Loss: 1.0720\n",
      "Epoch [10/1000], Loss: 1.0666\n",
      "Epoch [11/1000], Loss: 1.0615\n",
      "Epoch [12/1000], Loss: 1.0573\n",
      "Epoch [13/1000], Loss: 1.0545\n",
      "Epoch [14/1000], Loss: 1.0534\n",
      "Epoch [15/1000], Loss: 1.0536\n",
      "Epoch [16/1000], Loss: 1.0534\n",
      "Epoch [17/1000], Loss: 1.0519\n",
      "Epoch [18/1000], Loss: 1.0493\n",
      "Epoch [19/1000], Loss: 1.0463\n",
      "Epoch [20/1000], Loss: 1.0437\n",
      "Epoch [21/1000], Loss: 1.0417\n",
      "Epoch [22/1000], Loss: 1.0402\n",
      "Epoch [23/1000], Loss: 1.0391\n",
      "Epoch [24/1000], Loss: 1.0382\n",
      "Epoch [25/1000], Loss: 1.0371\n",
      "Epoch [26/1000], Loss: 1.0360\n",
      "Epoch [27/1000], Loss: 1.0347\n",
      "Epoch [28/1000], Loss: 1.0332\n",
      "Epoch [29/1000], Loss: 1.0316\n",
      "Epoch [30/1000], Loss: 1.0300\n",
      "Epoch [31/1000], Loss: 1.0285\n",
      "Epoch [32/1000], Loss: 1.0270\n",
      "Epoch [33/1000], Loss: 1.0256\n",
      "Epoch [34/1000], Loss: 1.0242\n",
      "Epoch [35/1000], Loss: 1.0227\n",
      "Epoch [36/1000], Loss: 1.0210\n",
      "Epoch [37/1000], Loss: 1.0191\n",
      "Epoch [38/1000], Loss: 1.0172\n",
      "Epoch [39/1000], Loss: 1.0152\n",
      "Epoch [40/1000], Loss: 1.0132\n",
      "Epoch [41/1000], Loss: 1.0112\n",
      "Epoch [42/1000], Loss: 1.0092\n",
      "Epoch [43/1000], Loss: 1.0072\n",
      "Epoch [44/1000], Loss: 1.0051\n",
      "Epoch [45/1000], Loss: 1.0028\n",
      "Epoch [46/1000], Loss: 1.0005\n",
      "Epoch [47/1000], Loss: 0.9982\n",
      "Epoch [48/1000], Loss: 0.9958\n",
      "Epoch [49/1000], Loss: 0.9935\n",
      "Epoch [50/1000], Loss: 0.9912\n",
      "Epoch [51/1000], Loss: 0.9888\n",
      "Epoch [52/1000], Loss: 0.9863\n",
      "Epoch [53/1000], Loss: 0.9838\n",
      "Epoch [54/1000], Loss: 0.9813\n",
      "Epoch [55/1000], Loss: 0.9788\n",
      "Epoch [56/1000], Loss: 0.9761\n",
      "Epoch [57/1000], Loss: 0.9734\n",
      "Epoch [58/1000], Loss: 0.9706\n",
      "Epoch [59/1000], Loss: 0.9678\n",
      "Epoch [60/1000], Loss: 0.9650\n",
      "Epoch [61/1000], Loss: 0.9621\n",
      "Epoch [62/1000], Loss: 0.9591\n",
      "Epoch [63/1000], Loss: 0.9561\n",
      "Epoch [64/1000], Loss: 0.9530\n",
      "Epoch [65/1000], Loss: 0.9498\n",
      "Epoch [66/1000], Loss: 0.9465\n",
      "Epoch [67/1000], Loss: 0.9431\n",
      "Epoch [68/1000], Loss: 0.9396\n",
      "Epoch [69/1000], Loss: 0.9360\n",
      "Epoch [70/1000], Loss: 0.9322\n",
      "Epoch [71/1000], Loss: 0.9283\n",
      "Epoch [72/1000], Loss: 0.9243\n",
      "Epoch [73/1000], Loss: 0.9202\n",
      "Epoch [74/1000], Loss: 0.9159\n",
      "Epoch [75/1000], Loss: 0.9115\n",
      "Epoch [76/1000], Loss: 0.9070\n",
      "Epoch [77/1000], Loss: 0.9024\n",
      "Epoch [78/1000], Loss: 0.8976\n",
      "Epoch [79/1000], Loss: 0.8928\n",
      "Epoch [80/1000], Loss: 0.8877\n",
      "Epoch [81/1000], Loss: 0.8825\n",
      "Epoch [82/1000], Loss: 0.8771\n",
      "Epoch [83/1000], Loss: 0.8715\n",
      "Epoch [84/1000], Loss: 0.8658\n",
      "Epoch [85/1000], Loss: 0.8598\n",
      "Epoch [86/1000], Loss: 0.8537\n",
      "Epoch [87/1000], Loss: 0.8476\n",
      "Epoch [88/1000], Loss: 0.8421\n",
      "Epoch [89/1000], Loss: 0.8367\n",
      "Epoch [90/1000], Loss: 0.8292\n",
      "Epoch [91/1000], Loss: 0.8231\n",
      "Epoch [92/1000], Loss: 0.8178\n",
      "Epoch [93/1000], Loss: 0.8104\n",
      "Epoch [94/1000], Loss: 0.8042\n",
      "Epoch [95/1000], Loss: 0.7982\n",
      "Epoch [96/1000], Loss: 0.7907\n",
      "Epoch [97/1000], Loss: 0.7840\n",
      "Epoch [98/1000], Loss: 0.7777\n",
      "Epoch [99/1000], Loss: 0.7703\n",
      "Epoch [100/1000], Loss: 0.7628\n",
      "Epoch [101/1000], Loss: 0.7559\n",
      "Epoch [102/1000], Loss: 0.7490\n",
      "Epoch [103/1000], Loss: 0.7413\n",
      "Epoch [104/1000], Loss: 0.7334\n",
      "Epoch [105/1000], Loss: 0.7256\n",
      "Epoch [106/1000], Loss: 0.7181\n",
      "Epoch [107/1000], Loss: 0.7110\n",
      "Epoch [108/1000], Loss: 0.7045\n",
      "Epoch [109/1000], Loss: 0.6986\n",
      "Epoch [110/1000], Loss: 0.6895\n",
      "Epoch [111/1000], Loss: 0.6797\n",
      "Epoch [112/1000], Loss: 0.6739\n",
      "Epoch [113/1000], Loss: 0.6680\n",
      "Epoch [114/1000], Loss: 0.6584\n",
      "Epoch [115/1000], Loss: 0.6506\n",
      "Epoch [116/1000], Loss: 0.6451\n",
      "Epoch [117/1000], Loss: 0.6372\n",
      "Epoch [118/1000], Loss: 0.6287\n",
      "Epoch [119/1000], Loss: 0.6215\n",
      "Epoch [120/1000], Loss: 0.6146\n",
      "Epoch [121/1000], Loss: 0.6075\n",
      "Epoch [122/1000], Loss: 0.5996\n",
      "Epoch [123/1000], Loss: 0.5917\n",
      "Epoch [124/1000], Loss: 0.5850\n",
      "Epoch [125/1000], Loss: 0.5786\n",
      "Epoch [126/1000], Loss: 0.5724\n",
      "Epoch [127/1000], Loss: 0.5682\n",
      "Epoch [128/1000], Loss: 0.5669\n",
      "Epoch [129/1000], Loss: 0.5589\n",
      "Epoch [130/1000], Loss: 0.5447\n",
      "Epoch [131/1000], Loss: 0.5409\n",
      "Epoch [132/1000], Loss: 0.5357\n",
      "Epoch [133/1000], Loss: 0.5274\n",
      "Epoch [134/1000], Loss: 0.5204\n",
      "Epoch [135/1000], Loss: 0.5164\n",
      "Epoch [136/1000], Loss: 0.5092\n",
      "Epoch [137/1000], Loss: 0.5017\n",
      "Epoch [138/1000], Loss: 0.4977\n",
      "Epoch [139/1000], Loss: 0.4904\n",
      "Epoch [140/1000], Loss: 0.4846\n",
      "Epoch [141/1000], Loss: 0.4782\n",
      "Epoch [142/1000], Loss: 0.4724\n",
      "Epoch [143/1000], Loss: 0.4669\n",
      "Epoch [144/1000], Loss: 0.4604\n",
      "Epoch [145/1000], Loss: 0.4556\n",
      "Epoch [146/1000], Loss: 0.4488\n",
      "Epoch [147/1000], Loss: 0.4425\n",
      "Epoch [148/1000], Loss: 0.4378\n",
      "Epoch [149/1000], Loss: 0.4315\n",
      "Epoch [150/1000], Loss: 0.4277\n",
      "Epoch [151/1000], Loss: 0.4260\n",
      "Epoch [152/1000], Loss: 0.4303\n",
      "Epoch [153/1000], Loss: 0.4280\n",
      "Epoch [154/1000], Loss: 0.4108\n",
      "Epoch [155/1000], Loss: 0.4006\n",
      "Epoch [156/1000], Loss: 0.4079\n",
      "Epoch [157/1000], Loss: 0.3942\n",
      "Epoch [158/1000], Loss: 0.3885\n",
      "Epoch [159/1000], Loss: 0.3897\n",
      "Epoch [160/1000], Loss: 0.3766\n",
      "Epoch [161/1000], Loss: 0.3765\n",
      "Epoch [162/1000], Loss: 0.3702\n",
      "Epoch [163/1000], Loss: 0.3635\n",
      "Epoch [164/1000], Loss: 0.3621\n",
      "Epoch [165/1000], Loss: 0.3539\n",
      "Epoch [166/1000], Loss: 0.3516\n",
      "Epoch [167/1000], Loss: 0.3460\n",
      "Epoch [168/1000], Loss: 0.3409\n",
      "Epoch [169/1000], Loss: 0.3383\n",
      "Epoch [170/1000], Loss: 0.3309\n",
      "Epoch [171/1000], Loss: 0.3284\n",
      "Epoch [172/1000], Loss: 0.3243\n",
      "Epoch [173/1000], Loss: 0.3180\n",
      "Epoch [174/1000], Loss: 0.3154\n",
      "Epoch [175/1000], Loss: 0.3098\n",
      "Epoch [176/1000], Loss: 0.3054\n",
      "Epoch [177/1000], Loss: 0.3025\n",
      "Epoch [178/1000], Loss: 0.2971\n",
      "Epoch [179/1000], Loss: 0.2939\n",
      "Epoch [180/1000], Loss: 0.2903\n",
      "Epoch [181/1000], Loss: 0.2871\n",
      "Epoch [182/1000], Loss: 0.2874\n",
      "Epoch [183/1000], Loss: 0.2947\n",
      "Epoch [184/1000], Loss: 0.3120\n",
      "Epoch [185/1000], Loss: 0.3271\n",
      "Epoch [186/1000], Loss: 0.2839\n",
      "Epoch [187/1000], Loss: 0.2898\n",
      "Epoch [188/1000], Loss: 0.2920\n",
      "Epoch [189/1000], Loss: 0.2706\n",
      "Epoch [190/1000], Loss: 0.2797\n",
      "Epoch [191/1000], Loss: 0.2640\n",
      "Epoch [192/1000], Loss: 0.2648\n",
      "Epoch [193/1000], Loss: 0.2617\n",
      "Epoch [194/1000], Loss: 0.2532\n",
      "Epoch [195/1000], Loss: 0.2576\n",
      "Epoch [196/1000], Loss: 0.2450\n",
      "Epoch [197/1000], Loss: 0.2508\n",
      "Epoch [198/1000], Loss: 0.2394\n",
      "Epoch [199/1000], Loss: 0.2423\n",
      "Epoch [200/1000], Loss: 0.2349\n",
      "Epoch [201/1000], Loss: 0.2344\n",
      "Epoch [202/1000], Loss: 0.2305\n",
      "Epoch [203/1000], Loss: 0.2276\n",
      "Epoch [204/1000], Loss: 0.2250\n",
      "Epoch [205/1000], Loss: 0.2221\n",
      "Epoch [206/1000], Loss: 0.2194\n",
      "Epoch [207/1000], Loss: 0.2166\n",
      "Epoch [208/1000], Loss: 0.2141\n",
      "Epoch [209/1000], Loss: 0.2112\n",
      "Epoch [210/1000], Loss: 0.2091\n",
      "Epoch [211/1000], Loss: 0.2060\n",
      "Epoch [212/1000], Loss: 0.2039\n",
      "Epoch [213/1000], Loss: 0.2014\n",
      "Epoch [214/1000], Loss: 0.1988\n",
      "Epoch [215/1000], Loss: 0.1967\n",
      "Epoch [216/1000], Loss: 0.1940\n",
      "Epoch [217/1000], Loss: 0.1918\n",
      "Epoch [218/1000], Loss: 0.1894\n",
      "Epoch [219/1000], Loss: 0.1871\n",
      "Epoch [220/1000], Loss: 0.1848\n",
      "Epoch [221/1000], Loss: 0.1825\n",
      "Epoch [222/1000], Loss: 0.1804\n",
      "Epoch [223/1000], Loss: 0.1780\n",
      "Epoch [224/1000], Loss: 0.1759\n",
      "Epoch [225/1000], Loss: 0.1737\n",
      "Epoch [226/1000], Loss: 0.1715\n",
      "Epoch [227/1000], Loss: 0.1694\n",
      "Epoch [228/1000], Loss: 0.1672\n",
      "Epoch [229/1000], Loss: 0.1652\n",
      "Epoch [230/1000], Loss: 0.1630\n",
      "Epoch [231/1000], Loss: 0.1610\n",
      "Epoch [232/1000], Loss: 0.1589\n",
      "Epoch [233/1000], Loss: 0.1569\n",
      "Epoch [234/1000], Loss: 0.1549\n",
      "Epoch [235/1000], Loss: 0.1529\n",
      "Epoch [236/1000], Loss: 0.1509\n",
      "Epoch [237/1000], Loss: 0.1490\n",
      "Epoch [238/1000], Loss: 0.1470\n",
      "Epoch [239/1000], Loss: 0.1451\n",
      "Epoch [240/1000], Loss: 0.1432\n",
      "Epoch [241/1000], Loss: 0.1413\n",
      "Epoch [242/1000], Loss: 0.1395\n",
      "Epoch [243/1000], Loss: 0.1376\n",
      "Epoch [244/1000], Loss: 0.1358\n",
      "Epoch [245/1000], Loss: 0.1340\n",
      "Epoch [246/1000], Loss: 0.1322\n",
      "Epoch [247/1000], Loss: 0.1304\n",
      "Epoch [248/1000], Loss: 0.1287\n",
      "Epoch [249/1000], Loss: 0.1270\n",
      "Epoch [250/1000], Loss: 0.1252\n",
      "Epoch [251/1000], Loss: 0.1235\n",
      "Epoch [252/1000], Loss: 0.1218\n",
      "Epoch [253/1000], Loss: 0.1202\n",
      "Epoch [254/1000], Loss: 0.1185\n",
      "Epoch [255/1000], Loss: 0.1169\n",
      "Epoch [256/1000], Loss: 0.1153\n",
      "Epoch [257/1000], Loss: 0.1138\n",
      "Epoch [258/1000], Loss: 0.1123\n",
      "Epoch [259/1000], Loss: 0.1109\n",
      "Epoch [260/1000], Loss: 0.1095\n",
      "Epoch [261/1000], Loss: 0.1086\n",
      "Epoch [262/1000], Loss: 0.1085\n",
      "Epoch [263/1000], Loss: 0.1131\n",
      "Epoch [264/1000], Loss: 0.1577\n",
      "Epoch [265/1000], Loss: 0.7043\n",
      "Epoch [266/1000], Loss: 0.5979\n",
      "Epoch [267/1000], Loss: 0.3513\n",
      "Epoch [268/1000], Loss: 0.4669\n",
      "Epoch [269/1000], Loss: 0.3022\n",
      "Epoch [270/1000], Loss: 0.2612\n",
      "Epoch [271/1000], Loss: 0.3252\n",
      "Epoch [272/1000], Loss: 0.2357\n",
      "Epoch [273/1000], Loss: 0.2340\n",
      "Epoch [274/1000], Loss: 0.2408\n",
      "Epoch [275/1000], Loss: 0.2222\n",
      "Epoch [276/1000], Loss: 0.2037\n",
      "Epoch [277/1000], Loss: 0.1966\n",
      "Epoch [278/1000], Loss: 0.1857\n",
      "Epoch [279/1000], Loss: 0.1760\n",
      "Epoch [280/1000], Loss: 0.1656\n",
      "Epoch [281/1000], Loss: 0.1674\n",
      "Epoch [282/1000], Loss: 0.1631\n",
      "Epoch [283/1000], Loss: 0.1478\n",
      "Epoch [284/1000], Loss: 0.1415\n",
      "Epoch [285/1000], Loss: 0.1440\n",
      "Epoch [286/1000], Loss: 0.1414\n",
      "Epoch [287/1000], Loss: 0.1333\n",
      "Epoch [288/1000], Loss: 0.1292\n",
      "Epoch [289/1000], Loss: 0.1268\n",
      "Epoch [290/1000], Loss: 0.1257\n",
      "Epoch [291/1000], Loss: 0.1253\n",
      "Epoch [292/1000], Loss: 0.1220\n",
      "Epoch [293/1000], Loss: 0.1188\n",
      "Epoch [294/1000], Loss: 0.1168\n",
      "Epoch [295/1000], Loss: 0.1150\n",
      "Epoch [296/1000], Loss: 0.1142\n",
      "Epoch [297/1000], Loss: 0.1132\n",
      "Epoch [298/1000], Loss: 0.1109\n",
      "Epoch [299/1000], Loss: 0.1094\n",
      "Epoch [300/1000], Loss: 0.1084\n",
      "Epoch [301/1000], Loss: 0.1067\n",
      "Epoch [302/1000], Loss: 0.1052\n",
      "Epoch [303/1000], Loss: 0.1046\n",
      "Epoch [304/1000], Loss: 0.1038\n",
      "Epoch [305/1000], Loss: 0.1027\n",
      "Epoch [306/1000], Loss: 0.1016\n",
      "Epoch [307/1000], Loss: 0.1003\n",
      "Epoch [308/1000], Loss: 0.0992\n",
      "Epoch [309/1000], Loss: 0.0985\n",
      "Epoch [310/1000], Loss: 0.0980\n",
      "Epoch [311/1000], Loss: 0.0972\n",
      "Epoch [312/1000], Loss: 0.0964\n",
      "Epoch [313/1000], Loss: 0.0955\n",
      "Epoch [314/1000], Loss: 0.0945\n",
      "Epoch [315/1000], Loss: 0.0937\n",
      "Epoch [316/1000], Loss: 0.0931\n",
      "Epoch [317/1000], Loss: 0.0925\n",
      "Epoch [318/1000], Loss: 0.0918\n",
      "Epoch [319/1000], Loss: 0.0911\n",
      "Epoch [320/1000], Loss: 0.0903\n",
      "Epoch [321/1000], Loss: 0.0897\n",
      "Epoch [322/1000], Loss: 0.0891\n",
      "Epoch [323/1000], Loss: 0.0885\n",
      "Epoch [324/1000], Loss: 0.0878\n",
      "Epoch [325/1000], Loss: 0.0872\n",
      "Epoch [326/1000], Loss: 0.0866\n",
      "Epoch [327/1000], Loss: 0.0861\n",
      "Epoch [328/1000], Loss: 0.0855\n",
      "Epoch [329/1000], Loss: 0.0850\n",
      "Epoch [330/1000], Loss: 0.0844\n",
      "Epoch [331/1000], Loss: 0.0838\n",
      "Epoch [332/1000], Loss: 0.0833\n",
      "Epoch [333/1000], Loss: 0.0828\n",
      "Epoch [334/1000], Loss: 0.0823\n",
      "Epoch [335/1000], Loss: 0.0818\n",
      "Epoch [336/1000], Loss: 0.0813\n",
      "Epoch [337/1000], Loss: 0.0808\n",
      "Epoch [338/1000], Loss: 0.0803\n",
      "Epoch [339/1000], Loss: 0.0799\n",
      "Epoch [340/1000], Loss: 0.0794\n",
      "Epoch [341/1000], Loss: 0.0789\n",
      "Epoch [342/1000], Loss: 0.0785\n",
      "Epoch [343/1000], Loss: 0.0780\n",
      "Epoch [344/1000], Loss: 0.0776\n",
      "Epoch [345/1000], Loss: 0.0771\n",
      "Epoch [346/1000], Loss: 0.0767\n",
      "Epoch [347/1000], Loss: 0.0763\n",
      "Epoch [348/1000], Loss: 0.0758\n",
      "Epoch [349/1000], Loss: 0.0754\n",
      "Epoch [350/1000], Loss: 0.0750\n",
      "Epoch [351/1000], Loss: 0.0745\n",
      "Epoch [352/1000], Loss: 0.0741\n",
      "Epoch [353/1000], Loss: 0.0737\n",
      "Epoch [354/1000], Loss: 0.0733\n",
      "Epoch [355/1000], Loss: 0.0729\n",
      "Epoch [356/1000], Loss: 0.0725\n",
      "Epoch [357/1000], Loss: 0.0721\n",
      "Epoch [358/1000], Loss: 0.0717\n",
      "Epoch [359/1000], Loss: 0.0713\n",
      "Epoch [360/1000], Loss: 0.0709\n",
      "Epoch [361/1000], Loss: 0.0705\n",
      "Epoch [362/1000], Loss: 0.0701\n",
      "Epoch [363/1000], Loss: 0.0697\n",
      "Epoch [364/1000], Loss: 0.0693\n",
      "Epoch [365/1000], Loss: 0.0690\n",
      "Epoch [366/1000], Loss: 0.0686\n",
      "Epoch [367/1000], Loss: 0.0682\n",
      "Epoch [368/1000], Loss: 0.0678\n",
      "Epoch [369/1000], Loss: 0.0675\n",
      "Epoch [370/1000], Loss: 0.0671\n",
      "Epoch [371/1000], Loss: 0.0667\n",
      "Epoch [372/1000], Loss: 0.0663\n",
      "Epoch [373/1000], Loss: 0.0660\n",
      "Epoch [374/1000], Loss: 0.0656\n",
      "Epoch [375/1000], Loss: 0.0652\n",
      "Epoch [376/1000], Loss: 0.0649\n",
      "Epoch [377/1000], Loss: 0.0645\n",
      "Epoch [378/1000], Loss: 0.0641\n",
      "Epoch [379/1000], Loss: 0.0638\n",
      "Epoch [380/1000], Loss: 0.0634\n",
      "Epoch [381/1000], Loss: 0.0631\n",
      "Epoch [382/1000], Loss: 0.0627\n",
      "Epoch [383/1000], Loss: 0.0623\n",
      "Epoch [384/1000], Loss: 0.0620\n",
      "Epoch [385/1000], Loss: 0.0616\n",
      "Epoch [386/1000], Loss: 0.0613\n",
      "Epoch [387/1000], Loss: 0.0609\n",
      "Epoch [388/1000], Loss: 0.0606\n",
      "Epoch [389/1000], Loss: 0.0602\n",
      "Epoch [390/1000], Loss: 0.0599\n",
      "Epoch [391/1000], Loss: 0.0595\n",
      "Epoch [392/1000], Loss: 0.0592\n",
      "Epoch [393/1000], Loss: 0.0588\n",
      "Epoch [394/1000], Loss: 0.0585\n",
      "Epoch [395/1000], Loss: 0.0582\n",
      "Epoch [396/1000], Loss: 0.0578\n",
      "Epoch [397/1000], Loss: 0.0575\n",
      "Epoch [398/1000], Loss: 0.0572\n",
      "Epoch [399/1000], Loss: 0.0569\n",
      "Epoch [400/1000], Loss: 0.0566\n",
      "Epoch [401/1000], Loss: 0.0562\n",
      "Epoch [402/1000], Loss: 0.0559\n",
      "Epoch [403/1000], Loss: 0.0556\n",
      "Epoch [404/1000], Loss: 0.0553\n",
      "Epoch [405/1000], Loss: 0.0550\n",
      "Epoch [406/1000], Loss: 0.0547\n",
      "Epoch [407/1000], Loss: 0.0544\n",
      "Epoch [408/1000], Loss: 0.0541\n",
      "Epoch [409/1000], Loss: 0.0538\n",
      "Epoch [410/1000], Loss: 0.0535\n",
      "Epoch [411/1000], Loss: 0.0532\n",
      "Epoch [412/1000], Loss: 0.0530\n",
      "Epoch [413/1000], Loss: 0.0527\n",
      "Epoch [414/1000], Loss: 0.0524\n",
      "Epoch [415/1000], Loss: 0.0521\n",
      "Epoch [416/1000], Loss: 0.0518\n",
      "Epoch [417/1000], Loss: 0.0515\n",
      "Epoch [418/1000], Loss: 0.0513\n",
      "Epoch [419/1000], Loss: 0.0510\n",
      "Epoch [420/1000], Loss: 0.0507\n",
      "Epoch [421/1000], Loss: 0.0504\n",
      "Epoch [422/1000], Loss: 0.0501\n",
      "Epoch [423/1000], Loss: 0.0499\n",
      "Epoch [424/1000], Loss: 0.0496\n",
      "Epoch [425/1000], Loss: 0.0493\n",
      "Epoch [426/1000], Loss: 0.0491\n",
      "Epoch [427/1000], Loss: 0.0488\n",
      "Epoch [428/1000], Loss: 0.0485\n",
      "Epoch [429/1000], Loss: 0.0483\n",
      "Epoch [430/1000], Loss: 0.0480\n",
      "Epoch [431/1000], Loss: 0.0477\n",
      "Epoch [432/1000], Loss: 0.0475\n",
      "Epoch [433/1000], Loss: 0.0472\n",
      "Epoch [434/1000], Loss: 0.0470\n",
      "Epoch [435/1000], Loss: 0.0467\n",
      "Epoch [436/1000], Loss: 0.0465\n",
      "Epoch [437/1000], Loss: 0.0462\n",
      "Epoch [438/1000], Loss: 0.0460\n",
      "Epoch [439/1000], Loss: 0.0457\n",
      "Epoch [440/1000], Loss: 0.0455\n",
      "Epoch [441/1000], Loss: 0.0452\n",
      "Epoch [442/1000], Loss: 0.0450\n",
      "Epoch [443/1000], Loss: 0.0447\n",
      "Epoch [444/1000], Loss: 0.0445\n",
      "Epoch [445/1000], Loss: 0.0442\n",
      "Epoch [446/1000], Loss: 0.0440\n",
      "Epoch [447/1000], Loss: 0.0437\n",
      "Epoch [448/1000], Loss: 0.0435\n",
      "Epoch [449/1000], Loss: 0.0433\n",
      "Epoch [450/1000], Loss: 0.0430\n",
      "Epoch [451/1000], Loss: 0.0428\n",
      "Epoch [452/1000], Loss: 0.0426\n",
      "Epoch [453/1000], Loss: 0.0423\n",
      "Epoch [454/1000], Loss: 0.0421\n",
      "Epoch [455/1000], Loss: 0.0419\n",
      "Epoch [456/1000], Loss: 0.0416\n",
      "Epoch [457/1000], Loss: 0.0414\n",
      "Epoch [458/1000], Loss: 0.0412\n",
      "Epoch [459/1000], Loss: 0.0410\n",
      "Epoch [460/1000], Loss: 0.0407\n",
      "Epoch [461/1000], Loss: 0.0405\n",
      "Epoch [462/1000], Loss: 0.0403\n",
      "Epoch [463/1000], Loss: 0.0401\n",
      "Epoch [464/1000], Loss: 0.0399\n",
      "Epoch [465/1000], Loss: 0.0396\n",
      "Epoch [466/1000], Loss: 0.0394\n",
      "Epoch [467/1000], Loss: 0.0392\n",
      "Epoch [468/1000], Loss: 0.0390\n",
      "Epoch [469/1000], Loss: 0.0388\n",
      "Epoch [470/1000], Loss: 0.0386\n",
      "Epoch [471/1000], Loss: 0.0384\n",
      "Epoch [472/1000], Loss: 0.0382\n",
      "Epoch [473/1000], Loss: 0.0380\n",
      "Epoch [474/1000], Loss: 0.0378\n",
      "Epoch [475/1000], Loss: 0.0375\n",
      "Epoch [476/1000], Loss: 0.0373\n",
      "Epoch [477/1000], Loss: 0.0371\n",
      "Epoch [478/1000], Loss: 0.0369\n",
      "Epoch [479/1000], Loss: 0.0367\n",
      "Epoch [480/1000], Loss: 0.0365\n",
      "Epoch [481/1000], Loss: 0.0363\n",
      "Epoch [482/1000], Loss: 0.0361\n",
      "Epoch [483/1000], Loss: 0.0359\n",
      "Epoch [484/1000], Loss: 0.0358\n",
      "Epoch [485/1000], Loss: 0.0356\n",
      "Epoch [486/1000], Loss: 0.0354\n",
      "Epoch [487/1000], Loss: 0.0352\n",
      "Epoch [488/1000], Loss: 0.0350\n",
      "Epoch [489/1000], Loss: 0.0348\n",
      "Epoch [490/1000], Loss: 0.0346\n",
      "Epoch [491/1000], Loss: 0.0344\n",
      "Epoch [492/1000], Loss: 0.0342\n",
      "Epoch [493/1000], Loss: 0.0340\n",
      "Epoch [494/1000], Loss: 0.0339\n",
      "Epoch [495/1000], Loss: 0.0337\n",
      "Epoch [496/1000], Loss: 0.0335\n",
      "Epoch [497/1000], Loss: 0.0333\n",
      "Epoch [498/1000], Loss: 0.0331\n",
      "Epoch [499/1000], Loss: 0.0330\n",
      "Epoch [500/1000], Loss: 0.0328\n",
      "Epoch [501/1000], Loss: 0.0326\n",
      "Epoch [502/1000], Loss: 0.0324\n",
      "Epoch [503/1000], Loss: 0.0323\n",
      "Epoch [504/1000], Loss: 0.0321\n",
      "Epoch [505/1000], Loss: 0.0319\n",
      "Epoch [506/1000], Loss: 0.0317\n",
      "Epoch [507/1000], Loss: 0.0316\n",
      "Epoch [508/1000], Loss: 0.0314\n",
      "Epoch [509/1000], Loss: 0.0312\n",
      "Epoch [510/1000], Loss: 0.0310\n",
      "Epoch [511/1000], Loss: 0.0309\n",
      "Epoch [512/1000], Loss: 0.0307\n",
      "Epoch [513/1000], Loss: 0.0305\n",
      "Epoch [514/1000], Loss: 0.0304\n",
      "Epoch [515/1000], Loss: 0.0302\n",
      "Epoch [516/1000], Loss: 0.0300\n",
      "Epoch [517/1000], Loss: 0.0299\n",
      "Epoch [518/1000], Loss: 0.0297\n",
      "Epoch [519/1000], Loss: 0.0296\n",
      "Epoch [520/1000], Loss: 0.0294\n",
      "Epoch [521/1000], Loss: 0.0292\n",
      "Epoch [522/1000], Loss: 0.0291\n",
      "Epoch [523/1000], Loss: 0.0289\n",
      "Epoch [524/1000], Loss: 0.0288\n",
      "Epoch [525/1000], Loss: 0.0286\n",
      "Epoch [526/1000], Loss: 0.0284\n",
      "Epoch [527/1000], Loss: 0.0283\n",
      "Epoch [528/1000], Loss: 0.0281\n",
      "Epoch [529/1000], Loss: 0.0280\n",
      "Epoch [530/1000], Loss: 0.0278\n",
      "Epoch [531/1000], Loss: 0.0277\n",
      "Epoch [532/1000], Loss: 0.0275\n",
      "Epoch [533/1000], Loss: 0.0274\n",
      "Epoch [534/1000], Loss: 0.0272\n",
      "Epoch [535/1000], Loss: 0.0271\n",
      "Epoch [536/1000], Loss: 0.0269\n",
      "Epoch [537/1000], Loss: 0.0268\n",
      "Epoch [538/1000], Loss: 0.0266\n",
      "Epoch [539/1000], Loss: 0.0265\n",
      "Epoch [540/1000], Loss: 0.0263\n",
      "Epoch [541/1000], Loss: 0.0262\n",
      "Epoch [542/1000], Loss: 0.0260\n",
      "Epoch [543/1000], Loss: 0.0259\n",
      "Epoch [544/1000], Loss: 0.0258\n",
      "Epoch [545/1000], Loss: 0.0256\n",
      "Epoch [546/1000], Loss: 0.0255\n",
      "Epoch [547/1000], Loss: 0.0253\n",
      "Epoch [548/1000], Loss: 0.0252\n",
      "Epoch [549/1000], Loss: 0.0250\n",
      "Epoch [550/1000], Loss: 0.0249\n",
      "Epoch [551/1000], Loss: 0.0248\n",
      "Epoch [552/1000], Loss: 0.0246\n",
      "Epoch [553/1000], Loss: 0.0245\n",
      "Epoch [554/1000], Loss: 0.0244\n",
      "Epoch [555/1000], Loss: 0.0242\n",
      "Epoch [556/1000], Loss: 0.0241\n",
      "Epoch [557/1000], Loss: 0.0239\n",
      "Epoch [558/1000], Loss: 0.0238\n",
      "Epoch [559/1000], Loss: 0.0237\n",
      "Epoch [560/1000], Loss: 0.0235\n",
      "Epoch [561/1000], Loss: 0.0234\n",
      "Epoch [562/1000], Loss: 0.0233\n",
      "Epoch [563/1000], Loss: 0.0231\n",
      "Epoch [564/1000], Loss: 0.0230\n",
      "Epoch [565/1000], Loss: 0.0229\n",
      "Epoch [566/1000], Loss: 0.0227\n",
      "Epoch [567/1000], Loss: 0.0226\n",
      "Epoch [568/1000], Loss: 0.0225\n",
      "Epoch [569/1000], Loss: 0.0224\n",
      "Epoch [570/1000], Loss: 0.0222\n",
      "Epoch [571/1000], Loss: 0.0221\n",
      "Epoch [572/1000], Loss: 0.0220\n",
      "Epoch [573/1000], Loss: 0.0218\n",
      "Epoch [574/1000], Loss: 0.0217\n",
      "Epoch [575/1000], Loss: 0.0216\n",
      "Epoch [576/1000], Loss: 0.0215\n",
      "Epoch [577/1000], Loss: 0.0213\n",
      "Epoch [578/1000], Loss: 0.0212\n",
      "Epoch [579/1000], Loss: 0.0211\n",
      "Epoch [580/1000], Loss: 0.0210\n",
      "Epoch [581/1000], Loss: 0.0208\n",
      "Epoch [582/1000], Loss: 0.0207\n",
      "Epoch [583/1000], Loss: 0.0206\n",
      "Epoch [584/1000], Loss: 0.0205\n",
      "Epoch [585/1000], Loss: 0.0204\n",
      "Epoch [586/1000], Loss: 0.0202\n",
      "Epoch [587/1000], Loss: 0.0201\n",
      "Epoch [588/1000], Loss: 0.0200\n",
      "Epoch [589/1000], Loss: 0.0199\n",
      "Epoch [590/1000], Loss: 0.0198\n",
      "Epoch [591/1000], Loss: 0.0196\n",
      "Epoch [592/1000], Loss: 0.0195\n",
      "Epoch [593/1000], Loss: 0.0194\n",
      "Epoch [594/1000], Loss: 0.0193\n",
      "Epoch [595/1000], Loss: 0.0192\n",
      "Epoch [596/1000], Loss: 0.0191\n",
      "Epoch [597/1000], Loss: 0.0190\n",
      "Epoch [598/1000], Loss: 0.0189\n",
      "Epoch [599/1000], Loss: 0.0187\n",
      "Epoch [600/1000], Loss: 0.0186\n",
      "Epoch [601/1000], Loss: 0.0185\n",
      "Epoch [602/1000], Loss: 0.0184\n",
      "Epoch [603/1000], Loss: 0.0183\n",
      "Epoch [604/1000], Loss: 0.0182\n",
      "Epoch [605/1000], Loss: 0.0181\n",
      "Epoch [606/1000], Loss: 0.0180\n",
      "Epoch [607/1000], Loss: 0.0179\n",
      "Epoch [608/1000], Loss: 0.0178\n",
      "Epoch [609/1000], Loss: 0.0177\n",
      "Epoch [610/1000], Loss: 0.0176\n",
      "Epoch [611/1000], Loss: 0.0175\n",
      "Epoch [612/1000], Loss: 0.0174\n",
      "Epoch [613/1000], Loss: 0.0173\n",
      "Epoch [614/1000], Loss: 0.0172\n",
      "Epoch [615/1000], Loss: 0.0171\n",
      "Epoch [616/1000], Loss: 0.0170\n",
      "Epoch [617/1000], Loss: 0.0169\n",
      "Epoch [618/1000], Loss: 0.0168\n",
      "Epoch [619/1000], Loss: 0.0167\n",
      "Epoch [620/1000], Loss: 0.0166\n",
      "Epoch [621/1000], Loss: 0.0165\n",
      "Epoch [622/1000], Loss: 0.0164\n",
      "Epoch [623/1000], Loss: 0.0163\n",
      "Epoch [624/1000], Loss: 0.0162\n",
      "Epoch [625/1000], Loss: 0.0161\n",
      "Epoch [626/1000], Loss: 0.0160\n",
      "Epoch [627/1000], Loss: 0.0159\n",
      "Epoch [628/1000], Loss: 0.0158\n",
      "Epoch [629/1000], Loss: 0.0158\n",
      "Epoch [630/1000], Loss: 0.0157\n",
      "Epoch [631/1000], Loss: 0.0156\n",
      "Epoch [632/1000], Loss: 0.0155\n",
      "Epoch [633/1000], Loss: 0.0154\n",
      "Epoch [634/1000], Loss: 0.0153\n",
      "Epoch [635/1000], Loss: 0.0152\n",
      "Epoch [636/1000], Loss: 0.0151\n",
      "Epoch [637/1000], Loss: 0.0151\n",
      "Epoch [638/1000], Loss: 0.0150\n",
      "Epoch [639/1000], Loss: 0.0149\n",
      "Epoch [640/1000], Loss: 0.0148\n",
      "Epoch [641/1000], Loss: 0.0147\n",
      "Epoch [642/1000], Loss: 0.0146\n",
      "Epoch [643/1000], Loss: 0.0145\n",
      "Epoch [644/1000], Loss: 0.0145\n",
      "Epoch [645/1000], Loss: 0.0144\n",
      "Epoch [646/1000], Loss: 0.0143\n",
      "Epoch [647/1000], Loss: 0.0142\n",
      "Epoch [648/1000], Loss: 0.0141\n",
      "Epoch [649/1000], Loss: 0.0141\n",
      "Epoch [650/1000], Loss: 0.0140\n",
      "Epoch [651/1000], Loss: 0.0139\n",
      "Epoch [652/1000], Loss: 0.0138\n",
      "Epoch [653/1000], Loss: 0.0137\n",
      "Epoch [654/1000], Loss: 0.0137\n",
      "Epoch [655/1000], Loss: 0.0136\n",
      "Epoch [656/1000], Loss: 0.0135\n",
      "Epoch [657/1000], Loss: 0.0134\n",
      "Epoch [658/1000], Loss: 0.0134\n",
      "Epoch [659/1000], Loss: 0.0133\n",
      "Epoch [660/1000], Loss: 0.0132\n",
      "Epoch [661/1000], Loss: 0.0131\n",
      "Epoch [662/1000], Loss: 0.0131\n",
      "Epoch [663/1000], Loss: 0.0130\n",
      "Epoch [664/1000], Loss: 0.0129\n",
      "Epoch [665/1000], Loss: 0.0128\n",
      "Epoch [666/1000], Loss: 0.0128\n",
      "Epoch [667/1000], Loss: 0.0127\n",
      "Epoch [668/1000], Loss: 0.0126\n",
      "Epoch [669/1000], Loss: 0.0125\n",
      "Epoch [670/1000], Loss: 0.0125\n",
      "Epoch [671/1000], Loss: 0.0124\n",
      "Epoch [672/1000], Loss: 0.0123\n",
      "Epoch [673/1000], Loss: 0.0123\n",
      "Epoch [674/1000], Loss: 0.0122\n",
      "Epoch [675/1000], Loss: 0.0121\n",
      "Epoch [676/1000], Loss: 0.0120\n",
      "Epoch [677/1000], Loss: 0.0120\n",
      "Epoch [678/1000], Loss: 0.0119\n",
      "Epoch [679/1000], Loss: 0.0118\n",
      "Epoch [680/1000], Loss: 0.0118\n",
      "Epoch [681/1000], Loss: 0.0117\n",
      "Epoch [682/1000], Loss: 0.0116\n",
      "Epoch [683/1000], Loss: 0.0116\n",
      "Epoch [684/1000], Loss: 0.0115\n",
      "Epoch [685/1000], Loss: 0.0114\n",
      "Epoch [686/1000], Loss: 0.0114\n",
      "Epoch [687/1000], Loss: 0.0113\n",
      "Epoch [688/1000], Loss: 0.0112\n",
      "Epoch [689/1000], Loss: 0.0112\n",
      "Epoch [690/1000], Loss: 0.0111\n",
      "Epoch [691/1000], Loss: 0.0110\n",
      "Epoch [692/1000], Loss: 0.0110\n",
      "Epoch [693/1000], Loss: 0.0109\n",
      "Epoch [694/1000], Loss: 0.0109\n",
      "Epoch [695/1000], Loss: 0.0108\n",
      "Epoch [696/1000], Loss: 0.0107\n",
      "Epoch [697/1000], Loss: 0.0107\n",
      "Epoch [698/1000], Loss: 0.0106\n",
      "Epoch [699/1000], Loss: 0.0105\n",
      "Epoch [700/1000], Loss: 0.0105\n",
      "Epoch [701/1000], Loss: 0.0104\n",
      "Epoch [702/1000], Loss: 0.0103\n",
      "Epoch [703/1000], Loss: 0.0103\n",
      "Epoch [704/1000], Loss: 0.0102\n",
      "Epoch [705/1000], Loss: 0.0102\n",
      "Epoch [706/1000], Loss: 0.0101\n",
      "Epoch [707/1000], Loss: 0.0100\n",
      "Epoch [708/1000], Loss: 0.0100\n",
      "Epoch [709/1000], Loss: 0.0099\n",
      "Epoch [710/1000], Loss: 0.0099\n",
      "Epoch [711/1000], Loss: 0.0098\n",
      "Epoch [712/1000], Loss: 0.0098\n",
      "Epoch [713/1000], Loss: 0.0097\n",
      "Epoch [714/1000], Loss: 0.0097\n",
      "Epoch [715/1000], Loss: 0.0096\n",
      "Epoch [716/1000], Loss: 0.0096\n",
      "Epoch [717/1000], Loss: 0.0095\n",
      "Epoch [718/1000], Loss: 0.0094\n",
      "Epoch [719/1000], Loss: 0.0094\n",
      "Epoch [720/1000], Loss: 0.0093\n",
      "Epoch [721/1000], Loss: 0.0093\n",
      "Epoch [722/1000], Loss: 0.0092\n",
      "Epoch [723/1000], Loss: 0.0092\n",
      "Epoch [724/1000], Loss: 0.0091\n",
      "Epoch [725/1000], Loss: 0.0091\n",
      "Epoch [726/1000], Loss: 0.0090\n",
      "Epoch [727/1000], Loss: 0.0090\n",
      "Epoch [728/1000], Loss: 0.0089\n",
      "Epoch [729/1000], Loss: 0.0089\n",
      "Epoch [730/1000], Loss: 0.0088\n",
      "Epoch [731/1000], Loss: 0.0088\n",
      "Epoch [732/1000], Loss: 0.0087\n",
      "Epoch [733/1000], Loss: 0.0087\n",
      "Epoch [734/1000], Loss: 0.0087\n",
      "Epoch [735/1000], Loss: 0.0086\n",
      "Epoch [736/1000], Loss: 0.0086\n",
      "Epoch [737/1000], Loss: 0.0085\n",
      "Epoch [738/1000], Loss: 0.0085\n",
      "Epoch [739/1000], Loss: 0.0084\n",
      "Epoch [740/1000], Loss: 0.0084\n",
      "Epoch [741/1000], Loss: 0.0083\n",
      "Epoch [742/1000], Loss: 0.0083\n",
      "Epoch [743/1000], Loss: 0.0082\n",
      "Epoch [744/1000], Loss: 0.0082\n",
      "Epoch [745/1000], Loss: 0.0082\n",
      "Epoch [746/1000], Loss: 0.0081\n",
      "Epoch [747/1000], Loss: 0.0081\n",
      "Epoch [748/1000], Loss: 0.0080\n",
      "Epoch [749/1000], Loss: 0.0080\n",
      "Epoch [750/1000], Loss: 0.0079\n",
      "Epoch [751/1000], Loss: 0.0079\n",
      "Epoch [752/1000], Loss: 0.0078\n",
      "Epoch [753/1000], Loss: 0.0078\n",
      "Epoch [754/1000], Loss: 0.0078\n",
      "Epoch [755/1000], Loss: 0.0077\n",
      "Epoch [756/1000], Loss: 0.0077\n",
      "Epoch [757/1000], Loss: 0.0076\n",
      "Epoch [758/1000], Loss: 0.0076\n",
      "Epoch [759/1000], Loss: 0.0076\n",
      "Epoch [760/1000], Loss: 0.0075\n",
      "Epoch [761/1000], Loss: 0.0075\n",
      "Epoch [762/1000], Loss: 0.0074\n",
      "Epoch [763/1000], Loss: 0.0074\n",
      "Epoch [764/1000], Loss: 0.0073\n",
      "Epoch [765/1000], Loss: 0.0073\n",
      "Epoch [766/1000], Loss: 0.0073\n",
      "Epoch [767/1000], Loss: 0.0072\n",
      "Epoch [768/1000], Loss: 0.0072\n",
      "Epoch [769/1000], Loss: 0.0071\n",
      "Epoch [770/1000], Loss: 0.0071\n",
      "Epoch [771/1000], Loss: 0.0071\n",
      "Epoch [772/1000], Loss: 0.0070\n",
      "Epoch [773/1000], Loss: 0.0070\n",
      "Epoch [774/1000], Loss: 0.0069\n",
      "Epoch [775/1000], Loss: 0.0069\n",
      "Epoch [776/1000], Loss: 0.0069\n",
      "Epoch [777/1000], Loss: 0.0068\n",
      "Epoch [778/1000], Loss: 0.0068\n",
      "Epoch [779/1000], Loss: 0.0067\n",
      "Epoch [780/1000], Loss: 0.0067\n",
      "Epoch [781/1000], Loss: 0.0067\n",
      "Epoch [782/1000], Loss: 0.0066\n",
      "Epoch [783/1000], Loss: 0.0066\n",
      "Epoch [784/1000], Loss: 0.0066\n",
      "Epoch [785/1000], Loss: 0.0065\n",
      "Epoch [786/1000], Loss: 0.0065\n",
      "Epoch [787/1000], Loss: 0.0064\n",
      "Epoch [788/1000], Loss: 0.0064\n",
      "Epoch [789/1000], Loss: 0.0064\n",
      "Epoch [790/1000], Loss: 0.0063\n",
      "Epoch [791/1000], Loss: 0.0063\n",
      "Epoch [792/1000], Loss: 0.0063\n",
      "Epoch [793/1000], Loss: 0.0062\n",
      "Epoch [794/1000], Loss: 0.0062\n",
      "Epoch [795/1000], Loss: 0.0062\n",
      "Epoch [796/1000], Loss: 0.0061\n",
      "Epoch [797/1000], Loss: 0.0061\n",
      "Epoch [798/1000], Loss: 0.0061\n",
      "Epoch [799/1000], Loss: 0.0060\n",
      "Epoch [800/1000], Loss: 0.0060\n",
      "Epoch [801/1000], Loss: 0.0060\n",
      "Epoch [802/1000], Loss: 0.0059\n",
      "Epoch [803/1000], Loss: 0.0059\n",
      "Epoch [804/1000], Loss: 0.0059\n",
      "Epoch [805/1000], Loss: 0.0058\n",
      "Epoch [806/1000], Loss: 0.0058\n",
      "Epoch [807/1000], Loss: 0.0058\n",
      "Epoch [808/1000], Loss: 0.0057\n",
      "Epoch [809/1000], Loss: 0.0057\n",
      "Epoch [810/1000], Loss: 0.0057\n",
      "Epoch [811/1000], Loss: 0.0056\n",
      "Epoch [812/1000], Loss: 0.0056\n",
      "Epoch [813/1000], Loss: 0.0056\n",
      "Epoch [814/1000], Loss: 0.0055\n",
      "Epoch [815/1000], Loss: 0.0055\n",
      "Epoch [816/1000], Loss: 0.0055\n",
      "Epoch [817/1000], Loss: 0.0055\n",
      "Epoch [818/1000], Loss: 0.0054\n",
      "Epoch [819/1000], Loss: 0.0054\n",
      "Epoch [820/1000], Loss: 0.0054\n",
      "Epoch [821/1000], Loss: 0.0053\n",
      "Epoch [822/1000], Loss: 0.0053\n",
      "Epoch [823/1000], Loss: 0.0053\n",
      "Epoch [824/1000], Loss: 0.0053\n",
      "Epoch [825/1000], Loss: 0.0052\n",
      "Epoch [826/1000], Loss: 0.0052\n",
      "Epoch [827/1000], Loss: 0.0052\n",
      "Epoch [828/1000], Loss: 0.0052\n",
      "Epoch [829/1000], Loss: 0.0051\n",
      "Epoch [830/1000], Loss: 0.0051\n",
      "Epoch [831/1000], Loss: 0.0051\n",
      "Epoch [832/1000], Loss: 0.0050\n",
      "Epoch [833/1000], Loss: 0.0050\n",
      "Epoch [834/1000], Loss: 0.0050\n",
      "Epoch [835/1000], Loss: 0.0050\n",
      "Epoch [836/1000], Loss: 0.0049\n",
      "Epoch [837/1000], Loss: 0.0049\n",
      "Epoch [838/1000], Loss: 0.0049\n",
      "Epoch [839/1000], Loss: 0.0049\n",
      "Epoch [840/1000], Loss: 0.0048\n",
      "Epoch [841/1000], Loss: 0.0048\n",
      "Epoch [842/1000], Loss: 0.0048\n",
      "Epoch [843/1000], Loss: 0.0048\n",
      "Epoch [844/1000], Loss: 0.0047\n",
      "Epoch [845/1000], Loss: 0.0047\n",
      "Epoch [846/1000], Loss: 0.0047\n",
      "Epoch [847/1000], Loss: 0.0047\n",
      "Epoch [848/1000], Loss: 0.0047\n",
      "Epoch [849/1000], Loss: 0.0046\n",
      "Epoch [850/1000], Loss: 0.0046\n",
      "Epoch [851/1000], Loss: 0.0046\n",
      "Epoch [852/1000], Loss: 0.0046\n",
      "Epoch [853/1000], Loss: 0.0045\n",
      "Epoch [854/1000], Loss: 0.0045\n",
      "Epoch [855/1000], Loss: 0.0045\n",
      "Epoch [856/1000], Loss: 0.0045\n",
      "Epoch [857/1000], Loss: 0.0045\n",
      "Epoch [858/1000], Loss: 0.0044\n",
      "Epoch [859/1000], Loss: 0.0044\n",
      "Epoch [860/1000], Loss: 0.0044\n",
      "Epoch [861/1000], Loss: 0.0044\n",
      "Epoch [862/1000], Loss: 0.0043\n",
      "Epoch [863/1000], Loss: 0.0043\n",
      "Epoch [864/1000], Loss: 0.0043\n",
      "Epoch [865/1000], Loss: 0.0043\n",
      "Epoch [866/1000], Loss: 0.0043\n",
      "Epoch [867/1000], Loss: 0.0042\n",
      "Epoch [868/1000], Loss: 0.0042\n",
      "Epoch [869/1000], Loss: 0.0042\n",
      "Epoch [870/1000], Loss: 0.0042\n",
      "Epoch [871/1000], Loss: 0.0042\n",
      "Epoch [872/1000], Loss: 0.0041\n",
      "Epoch [873/1000], Loss: 0.0041\n",
      "Epoch [874/1000], Loss: 0.0041\n",
      "Epoch [875/1000], Loss: 0.0041\n",
      "Epoch [876/1000], Loss: 0.0041\n",
      "Epoch [877/1000], Loss: 0.0041\n",
      "Epoch [878/1000], Loss: 0.0040\n",
      "Epoch [879/1000], Loss: 0.0040\n",
      "Epoch [880/1000], Loss: 0.0040\n",
      "Epoch [881/1000], Loss: 0.0040\n",
      "Epoch [882/1000], Loss: 0.0040\n",
      "Epoch [883/1000], Loss: 0.0039\n",
      "Epoch [884/1000], Loss: 0.0039\n",
      "Epoch [885/1000], Loss: 0.0039\n",
      "Epoch [886/1000], Loss: 0.0039\n",
      "Epoch [887/1000], Loss: 0.0039\n",
      "Epoch [888/1000], Loss: 0.0039\n",
      "Epoch [889/1000], Loss: 0.0038\n",
      "Epoch [890/1000], Loss: 0.0038\n",
      "Epoch [891/1000], Loss: 0.0038\n",
      "Epoch [892/1000], Loss: 0.0038\n",
      "Epoch [893/1000], Loss: 0.0038\n",
      "Epoch [894/1000], Loss: 0.0038\n",
      "Epoch [895/1000], Loss: 0.0037\n",
      "Epoch [896/1000], Loss: 0.0037\n",
      "Epoch [897/1000], Loss: 0.0037\n",
      "Epoch [898/1000], Loss: 0.0037\n",
      "Epoch [899/1000], Loss: 0.0037\n",
      "Epoch [900/1000], Loss: 0.0037\n",
      "Epoch [901/1000], Loss: 0.0036\n",
      "Epoch [902/1000], Loss: 0.0036\n",
      "Epoch [903/1000], Loss: 0.0036\n",
      "Epoch [904/1000], Loss: 0.0036\n",
      "Epoch [905/1000], Loss: 0.0036\n",
      "Epoch [906/1000], Loss: 0.0036\n",
      "Epoch [907/1000], Loss: 0.0036\n",
      "Epoch [908/1000], Loss: 0.0035\n",
      "Epoch [909/1000], Loss: 0.0035\n",
      "Epoch [910/1000], Loss: 0.0035\n",
      "Epoch [911/1000], Loss: 0.0035\n",
      "Epoch [912/1000], Loss: 0.0035\n",
      "Epoch [913/1000], Loss: 0.0035\n",
      "Epoch [914/1000], Loss: 0.0035\n",
      "Epoch [915/1000], Loss: 0.0034\n",
      "Epoch [916/1000], Loss: 0.0034\n",
      "Epoch [917/1000], Loss: 0.0034\n",
      "Epoch [918/1000], Loss: 0.0034\n",
      "Epoch [919/1000], Loss: 0.0034\n",
      "Epoch [920/1000], Loss: 0.0034\n",
      "Epoch [921/1000], Loss: 0.0034\n",
      "Epoch [922/1000], Loss: 0.0033\n",
      "Epoch [923/1000], Loss: 0.0033\n",
      "Epoch [924/1000], Loss: 0.0033\n",
      "Epoch [925/1000], Loss: 0.0033\n",
      "Epoch [926/1000], Loss: 0.0033\n",
      "Epoch [927/1000], Loss: 0.0033\n",
      "Epoch [928/1000], Loss: 0.0033\n",
      "Epoch [929/1000], Loss: 0.0033\n",
      "Epoch [930/1000], Loss: 0.0032\n",
      "Epoch [931/1000], Loss: 0.0032\n",
      "Epoch [932/1000], Loss: 0.0032\n",
      "Epoch [933/1000], Loss: 0.0032\n",
      "Epoch [934/1000], Loss: 0.0032\n",
      "Epoch [935/1000], Loss: 0.0032\n",
      "Epoch [936/1000], Loss: 0.0032\n",
      "Epoch [937/1000], Loss: 0.0031\n",
      "Epoch [938/1000], Loss: 0.0031\n",
      "Epoch [939/1000], Loss: 0.0031\n",
      "Epoch [940/1000], Loss: 0.0031\n",
      "Epoch [941/1000], Loss: 0.0031\n",
      "Epoch [942/1000], Loss: 0.0031\n",
      "Epoch [943/1000], Loss: 0.0031\n",
      "Epoch [944/1000], Loss: 0.0031\n",
      "Epoch [945/1000], Loss: 0.0030\n",
      "Epoch [946/1000], Loss: 0.0030\n",
      "Epoch [947/1000], Loss: 0.0030\n",
      "Epoch [948/1000], Loss: 0.0030\n",
      "Epoch [949/1000], Loss: 0.0030\n",
      "Epoch [950/1000], Loss: 0.0030\n",
      "Epoch [951/1000], Loss: 0.0030\n",
      "Epoch [952/1000], Loss: 0.0030\n",
      "Epoch [953/1000], Loss: 0.0029\n",
      "Epoch [954/1000], Loss: 0.0029\n",
      "Epoch [955/1000], Loss: 0.0029\n",
      "Epoch [956/1000], Loss: 0.0029\n",
      "Epoch [957/1000], Loss: 0.0029\n",
      "Epoch [958/1000], Loss: 0.0029\n",
      "Epoch [959/1000], Loss: 0.0029\n",
      "Epoch [960/1000], Loss: 0.0029\n",
      "Epoch [961/1000], Loss: 0.0029\n",
      "Epoch [962/1000], Loss: 0.0028\n",
      "Epoch [963/1000], Loss: 0.0028\n",
      "Epoch [964/1000], Loss: 0.0028\n",
      "Epoch [965/1000], Loss: 0.0028\n",
      "Epoch [966/1000], Loss: 0.0028\n",
      "Epoch [967/1000], Loss: 0.0028\n",
      "Epoch [968/1000], Loss: 0.0028\n",
      "Epoch [969/1000], Loss: 0.0028\n",
      "Epoch [970/1000], Loss: 0.0028\n",
      "Epoch [971/1000], Loss: 0.0027\n",
      "Epoch [972/1000], Loss: 0.0027\n",
      "Epoch [973/1000], Loss: 0.0027\n",
      "Epoch [974/1000], Loss: 0.0027\n",
      "Epoch [975/1000], Loss: 0.0027\n",
      "Epoch [976/1000], Loss: 0.0027\n",
      "Epoch [977/1000], Loss: 0.0027\n",
      "Epoch [978/1000], Loss: 0.0027\n",
      "Epoch [979/1000], Loss: 0.0027\n",
      "Epoch [980/1000], Loss: 0.0027\n",
      "Epoch [981/1000], Loss: 0.0026\n",
      "Epoch [982/1000], Loss: 0.0026\n",
      "Epoch [983/1000], Loss: 0.0026\n",
      "Epoch [984/1000], Loss: 0.0026\n",
      "Epoch [985/1000], Loss: 0.0026\n",
      "Epoch [986/1000], Loss: 0.0026\n",
      "Epoch [987/1000], Loss: 0.0026\n",
      "Epoch [988/1000], Loss: 0.0026\n",
      "Epoch [989/1000], Loss: 0.0026\n",
      "Epoch [990/1000], Loss: 0.0026\n",
      "Epoch [991/1000], Loss: 0.0025\n",
      "Epoch [992/1000], Loss: 0.0025\n",
      "Epoch [993/1000], Loss: 0.0025\n",
      "Epoch [994/1000], Loss: 0.0025\n",
      "Epoch [995/1000], Loss: 0.0025\n",
      "Epoch [996/1000], Loss: 0.0025\n",
      "Epoch [997/1000], Loss: 0.0025\n",
      "Epoch [998/1000], Loss: 0.0025\n",
      "Epoch [999/1000], Loss: 0.0025\n",
      "Epoch [1000/1000], Loss: 0.0025\n"
     ]
    }
   ],
   "source": [
    "# # Example sequential measurement data\n",
    "# # Assuming each sequence has 5 time steps and 59 features\n",
    "# # X = np.random.randn(14289, 5, 59)\n",
    "# X_train = torch.tensor(X_train_input, dtype=torch.float32)\n",
    "# X_test = torch.tensor(X_test_input, dtype=torch.float32)\n",
    "# X_holdout = torch.tensor(X_holdout_input, dtype=torch.float32)\n",
    "\n",
    "# # Example classification labels\n",
    "# # y = np.random.randint(0, 3, 14289)  # Assuming three classes\n",
    "# y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "# y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "# y_holdout = torch.tensor(y_holdout, dtype=torch.long)\n",
    "\n",
    "# # Define LSTM model for classification\n",
    "# class LSTMClassifier(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "#         super(LSTMClassifier, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "#         c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "#         out, _ = self.lstm(x, (h0, c0))\n",
    "#         out = self.fc(out[:, -1, :])\n",
    "#         return out\n",
    "\n",
    "# # Instantiate the classification model\n",
    "# input_size = 59  # Number of features in each time step\n",
    "# hidden_size = 100  # Number of LSTM units\n",
    "# num_layers = 2  # Number of LSTM layers\n",
    "# num_classes = 3  # Number of output classes\n",
    "# classification_model = LSTMClassifier(input_size, hidden_size, num_layers, num_classes)\n",
    "\n",
    "# # Define loss function and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(classification_model.parameters(), lr=0.001)\n",
    "\n",
    "# # Train the classification model\n",
    "# num_epochs = 1000\n",
    "# for epoch in range(num_epochs):\n",
    "#     classification_model.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     outputs = classification_model(X_train)\n",
    "#     loss = criterion(outputs, y_train)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a885de0-f6f1-4d93-90b7-65726e8c35e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 0.6892\n",
      "Epoch [2/300], Loss: 0.6817\n",
      "Epoch [3/300], Loss: 0.6745\n",
      "Epoch [4/300], Loss: 0.6670\n",
      "Epoch [5/300], Loss: 0.6592\n",
      "Epoch [6/300], Loss: 0.6508\n",
      "Epoch [7/300], Loss: 0.6413\n",
      "Epoch [8/300], Loss: 0.6304\n",
      "Epoch [9/300], Loss: 0.6180\n",
      "Epoch [10/300], Loss: 0.6036\n",
      "Epoch [11/300], Loss: 0.5869\n",
      "Epoch [12/300], Loss: 0.5683\n",
      "Epoch [13/300], Loss: 0.5484\n",
      "Epoch [14/300], Loss: 0.5298\n",
      "Epoch [15/300], Loss: 0.5142\n",
      "Epoch [16/300], Loss: 0.5031\n",
      "Epoch [17/300], Loss: 0.4960\n",
      "Epoch [18/300], Loss: 0.4926\n",
      "Epoch [19/300], Loss: 0.4909\n",
      "Epoch [20/300], Loss: 0.4902\n",
      "Epoch [21/300], Loss: 0.4898\n",
      "Epoch [22/300], Loss: 0.4896\n",
      "Epoch [23/300], Loss: 0.4893\n",
      "Epoch [24/300], Loss: 0.4891\n",
      "Epoch [25/300], Loss: 0.4888\n",
      "Epoch [26/300], Loss: 0.4885\n",
      "Epoch [27/300], Loss: 0.4883\n",
      "Epoch [28/300], Loss: 0.4879\n",
      "Epoch [29/300], Loss: 0.4876\n",
      "Epoch [30/300], Loss: 0.4874\n",
      "Epoch [31/300], Loss: 0.4872\n",
      "Epoch [32/300], Loss: 0.4871\n",
      "Epoch [33/300], Loss: 0.4870\n",
      "Epoch [34/300], Loss: 0.4868\n",
      "Epoch [35/300], Loss: 0.4865\n",
      "Epoch [36/300], Loss: 0.4861\n",
      "Epoch [37/300], Loss: 0.4857\n",
      "Epoch [38/300], Loss: 0.4854\n",
      "Epoch [39/300], Loss: 0.4852\n",
      "Epoch [40/300], Loss: 0.4850\n",
      "Epoch [41/300], Loss: 0.4847\n",
      "Epoch [42/300], Loss: 0.4845\n",
      "Epoch [43/300], Loss: 0.4842\n",
      "Epoch [44/300], Loss: 0.4840\n",
      "Epoch [45/300], Loss: 0.4837\n",
      "Epoch [46/300], Loss: 0.4834\n",
      "Epoch [47/300], Loss: 0.4832\n",
      "Epoch [48/300], Loss: 0.4829\n",
      "Epoch [49/300], Loss: 0.4826\n",
      "Epoch [50/300], Loss: 0.4824\n",
      "Epoch [51/300], Loss: 0.4821\n",
      "Epoch [52/300], Loss: 0.4819\n",
      "Epoch [53/300], Loss: 0.4816\n",
      "Epoch [54/300], Loss: 0.4814\n",
      "Epoch [55/300], Loss: 0.4810\n",
      "Epoch [56/300], Loss: 0.4808\n",
      "Epoch [57/300], Loss: 0.4806\n",
      "Epoch [58/300], Loss: 0.4803\n",
      "Epoch [59/300], Loss: 0.4799\n",
      "Epoch [60/300], Loss: 0.4797\n",
      "Epoch [61/300], Loss: 0.4794\n",
      "Epoch [62/300], Loss: 0.4791\n",
      "Epoch [63/300], Loss: 0.4788\n",
      "Epoch [64/300], Loss: 0.4785\n",
      "Epoch [65/300], Loss: 0.4782\n",
      "Epoch [66/300], Loss: 0.4779\n",
      "Epoch [67/300], Loss: 0.4776\n",
      "Epoch [68/300], Loss: 0.4773\n",
      "Epoch [69/300], Loss: 0.4770\n",
      "Epoch [70/300], Loss: 0.4767\n",
      "Epoch [71/300], Loss: 0.4764\n",
      "Epoch [72/300], Loss: 0.4761\n",
      "Epoch [73/300], Loss: 0.4759\n",
      "Epoch [74/300], Loss: 0.4756\n",
      "Epoch [75/300], Loss: 0.4752\n",
      "Epoch [76/300], Loss: 0.4750\n",
      "Epoch [77/300], Loss: 0.4746\n",
      "Epoch [78/300], Loss: 0.4744\n",
      "Epoch [79/300], Loss: 0.4742\n",
      "Epoch [80/300], Loss: 0.4739\n",
      "Epoch [81/300], Loss: 0.4736\n",
      "Epoch [82/300], Loss: 0.4733\n",
      "Epoch [83/300], Loss: 0.4730\n",
      "Epoch [84/300], Loss: 0.4726\n",
      "Epoch [85/300], Loss: 0.4723\n",
      "Epoch [86/300], Loss: 0.4720\n",
      "Epoch [87/300], Loss: 0.4717\n",
      "Epoch [88/300], Loss: 0.4715\n",
      "Epoch [89/300], Loss: 0.4712\n",
      "Epoch [90/300], Loss: 0.4708\n",
      "Epoch [91/300], Loss: 0.4705\n",
      "Epoch [92/300], Loss: 0.4702\n",
      "Epoch [93/300], Loss: 0.4699\n",
      "Epoch [94/300], Loss: 0.4697\n",
      "Epoch [95/300], Loss: 0.4694\n",
      "Epoch [96/300], Loss: 0.4692\n",
      "Epoch [97/300], Loss: 0.4689\n",
      "Epoch [98/300], Loss: 0.4687\n",
      "Epoch [99/300], Loss: 0.4685\n",
      "Epoch [100/300], Loss: 0.4683\n",
      "Epoch [101/300], Loss: 0.4680\n",
      "Epoch [102/300], Loss: 0.4678\n",
      "Epoch [103/300], Loss: 0.4677\n",
      "Epoch [104/300], Loss: 0.4675\n",
      "Epoch [105/300], Loss: 0.4673\n",
      "Epoch [106/300], Loss: 0.4672\n",
      "Epoch [107/300], Loss: 0.4671\n",
      "Epoch [108/300], Loss: 0.4670\n",
      "Epoch [109/300], Loss: 0.4669\n",
      "Epoch [110/300], Loss: 0.4668\n",
      "Epoch [111/300], Loss: 0.4667\n",
      "Epoch [112/300], Loss: 0.4666\n",
      "Epoch [113/300], Loss: 0.4666\n",
      "Epoch [114/300], Loss: 0.4665\n",
      "Epoch [115/300], Loss: 0.4665\n",
      "Epoch [116/300], Loss: 0.4664\n",
      "Epoch [117/300], Loss: 0.4663\n",
      "Epoch [118/300], Loss: 0.4662\n",
      "Epoch [119/300], Loss: 0.4661\n",
      "Epoch [120/300], Loss: 0.4662\n",
      "Epoch [121/300], Loss: 0.4661\n",
      "Epoch [122/300], Loss: 0.4660\n",
      "Epoch [123/300], Loss: 0.4659\n",
      "Epoch [124/300], Loss: 0.4659\n",
      "Epoch [125/300], Loss: 0.4659\n",
      "Epoch [126/300], Loss: 0.4659\n",
      "Epoch [127/300], Loss: 0.4659\n",
      "Epoch [128/300], Loss: 0.4660\n",
      "Epoch [129/300], Loss: 0.4656\n",
      "Epoch [130/300], Loss: 0.4662\n",
      "Epoch [131/300], Loss: 0.4661\n",
      "Epoch [132/300], Loss: 0.4671\n",
      "Epoch [133/300], Loss: 0.4664\n",
      "Epoch [134/300], Loss: 0.4660\n",
      "Epoch [135/300], Loss: 0.4659\n",
      "Epoch [136/300], Loss: 0.4661\n",
      "Epoch [137/300], Loss: 0.4659\n",
      "Epoch [138/300], Loss: 0.4657\n",
      "Epoch [139/300], Loss: 0.4659\n",
      "Epoch [140/300], Loss: 0.4657\n",
      "Epoch [141/300], Loss: 0.4656\n",
      "Epoch [142/300], Loss: 0.4657\n",
      "Epoch [143/300], Loss: 0.4655\n",
      "Epoch [144/300], Loss: 0.4654\n",
      "Epoch [145/300], Loss: 0.4655\n",
      "Epoch [146/300], Loss: 0.4655\n",
      "Epoch [147/300], Loss: 0.4654\n",
      "Epoch [148/300], Loss: 0.4655\n",
      "Epoch [149/300], Loss: 0.4654\n",
      "Epoch [150/300], Loss: 0.4654\n",
      "Epoch [151/300], Loss: 0.4654\n",
      "Epoch [152/300], Loss: 0.4654\n",
      "Epoch [153/300], Loss: 0.4653\n",
      "Epoch [154/300], Loss: 0.4653\n",
      "Epoch [155/300], Loss: 0.4654\n",
      "Epoch [156/300], Loss: 0.4653\n",
      "Epoch [157/300], Loss: 0.4653\n",
      "Epoch [158/300], Loss: 0.4653\n",
      "Epoch [159/300], Loss: 0.4653\n",
      "Epoch [160/300], Loss: 0.4653\n",
      "Epoch [161/300], Loss: 0.4653\n",
      "Epoch [162/300], Loss: 0.4653\n",
      "Epoch [163/300], Loss: 0.4653\n",
      "Epoch [164/300], Loss: 0.4653\n",
      "Epoch [165/300], Loss: 0.4653\n",
      "Epoch [166/300], Loss: 0.4653\n",
      "Epoch [167/300], Loss: 0.4653\n",
      "Epoch [168/300], Loss: 0.4653\n",
      "Epoch [169/300], Loss: 0.4653\n",
      "Epoch [170/300], Loss: 0.4653\n",
      "Epoch [171/300], Loss: 0.4653\n",
      "Epoch [172/300], Loss: 0.4652\n",
      "Epoch [173/300], Loss: 0.4652\n",
      "Epoch [174/300], Loss: 0.4652\n",
      "Epoch [175/300], Loss: 0.4652\n",
      "Epoch [176/300], Loss: 0.4652\n",
      "Epoch [177/300], Loss: 0.4652\n",
      "Epoch [178/300], Loss: 0.4652\n",
      "Epoch [179/300], Loss: 0.4652\n",
      "Epoch [180/300], Loss: 0.4652\n",
      "Epoch [181/300], Loss: 0.4652\n",
      "Epoch [182/300], Loss: 0.4652\n",
      "Epoch [183/300], Loss: 0.4652\n",
      "Epoch [184/300], Loss: 0.4652\n",
      "Epoch [185/300], Loss: 0.4652\n",
      "Epoch [186/300], Loss: 0.4652\n",
      "Epoch [187/300], Loss: 0.4652\n",
      "Epoch [188/300], Loss: 0.4652\n",
      "Epoch [189/300], Loss: 0.4652\n",
      "Epoch [190/300], Loss: 0.4652\n",
      "Epoch [191/300], Loss: 0.4652\n",
      "Epoch [192/300], Loss: 0.4652\n",
      "Epoch [193/300], Loss: 0.4652\n",
      "Epoch [194/300], Loss: 0.4652\n",
      "Epoch [195/300], Loss: 0.4652\n",
      "Epoch [196/300], Loss: 0.4652\n",
      "Epoch [197/300], Loss: 0.4652\n",
      "Epoch [198/300], Loss: 0.4652\n",
      "Epoch [199/300], Loss: 0.4652\n",
      "Epoch [200/300], Loss: 0.4652\n",
      "Epoch [201/300], Loss: 0.4652\n",
      "Epoch [202/300], Loss: 0.4652\n",
      "Epoch [203/300], Loss: 0.4652\n",
      "Epoch [204/300], Loss: 0.4652\n",
      "Epoch [205/300], Loss: 0.4652\n",
      "Epoch [206/300], Loss: 0.4652\n",
      "Epoch [207/300], Loss: 0.4652\n",
      "Epoch [208/300], Loss: 0.4652\n",
      "Epoch [209/300], Loss: 0.4652\n",
      "Epoch [210/300], Loss: 0.4652\n",
      "Epoch [211/300], Loss: 0.4652\n",
      "Epoch [212/300], Loss: 0.4652\n",
      "Epoch [213/300], Loss: 0.4652\n",
      "Epoch [214/300], Loss: 0.4652\n",
      "Epoch [215/300], Loss: 0.4652\n",
      "Epoch [216/300], Loss: 0.4652\n",
      "Epoch [217/300], Loss: 0.4652\n",
      "Epoch [218/300], Loss: 0.4652\n",
      "Epoch [219/300], Loss: 0.4652\n",
      "Epoch [220/300], Loss: 0.4652\n",
      "Epoch [221/300], Loss: 0.4652\n",
      "Epoch [222/300], Loss: 0.4652\n",
      "Epoch [223/300], Loss: 0.4651\n",
      "Epoch [224/300], Loss: 0.4651\n",
      "Epoch [225/300], Loss: 0.4651\n",
      "Epoch [226/300], Loss: 0.4651\n",
      "Epoch [227/300], Loss: 0.4652\n",
      "Epoch [228/300], Loss: 0.4650\n",
      "Epoch [229/300], Loss: 0.4651\n",
      "Epoch [230/300], Loss: 0.4652\n",
      "Epoch [231/300], Loss: 0.4650\n",
      "Epoch [232/300], Loss: 0.4649\n",
      "Epoch [233/300], Loss: 0.4650\n",
      "Epoch [234/300], Loss: 0.4650\n",
      "Epoch [235/300], Loss: 0.4650\n",
      "Epoch [236/300], Loss: 0.4650\n",
      "Epoch [237/300], Loss: 0.4650\n",
      "Epoch [238/300], Loss: 0.4649\n",
      "Epoch [239/300], Loss: 0.4648\n",
      "Epoch [240/300], Loss: 0.4648\n",
      "Epoch [241/300], Loss: 0.4648\n",
      "Epoch [242/300], Loss: 0.4648\n",
      "Epoch [243/300], Loss: 0.4648\n",
      "Epoch [244/300], Loss: 0.4648\n",
      "Epoch [245/300], Loss: 0.4648\n",
      "Epoch [246/300], Loss: 0.4648\n",
      "Epoch [247/300], Loss: 0.4648\n",
      "Epoch [248/300], Loss: 0.4648\n",
      "Epoch [249/300], Loss: 0.4648\n",
      "Epoch [250/300], Loss: 0.4648\n",
      "Epoch [251/300], Loss: 0.4648\n",
      "Epoch [252/300], Loss: 0.4648\n",
      "Epoch [253/300], Loss: 0.4648\n",
      "Epoch [254/300], Loss: 0.4648\n",
      "Epoch [255/300], Loss: 0.4648\n",
      "Epoch [256/300], Loss: 0.4648\n",
      "Epoch [257/300], Loss: 0.4648\n",
      "Epoch [258/300], Loss: 0.4648\n",
      "Epoch [259/300], Loss: 0.4648\n",
      "Epoch [260/300], Loss: 0.4648\n",
      "Epoch [261/300], Loss: 0.4648\n",
      "Epoch [262/300], Loss: 0.4648\n",
      "Epoch [263/300], Loss: 0.4648\n",
      "Epoch [264/300], Loss: 0.4648\n",
      "Epoch [265/300], Loss: 0.4648\n",
      "Epoch [266/300], Loss: 0.4648\n",
      "Epoch [267/300], Loss: 0.4647\n",
      "Epoch [268/300], Loss: 0.4649\n",
      "Epoch [269/300], Loss: 0.4650\n",
      "Epoch [270/300], Loss: 0.4659\n",
      "Epoch [271/300], Loss: 0.4650\n",
      "Epoch [272/300], Loss: 0.4661\n",
      "Epoch [273/300], Loss: 0.4667\n",
      "Epoch [274/300], Loss: 0.4651\n",
      "Epoch [275/300], Loss: 0.4653\n",
      "Epoch [276/300], Loss: 0.4667\n",
      "Epoch [277/300], Loss: 0.4662\n",
      "Epoch [278/300], Loss: 0.4661\n",
      "Epoch [279/300], Loss: 0.4664\n",
      "Epoch [280/300], Loss: 0.4652\n",
      "Epoch [281/300], Loss: 0.4654\n",
      "Epoch [282/300], Loss: 0.4656\n",
      "Epoch [283/300], Loss: 0.4651\n",
      "Epoch [284/300], Loss: 0.4650\n",
      "Epoch [285/300], Loss: 0.4650\n",
      "Epoch [286/300], Loss: 0.4650\n",
      "Epoch [287/300], Loss: 0.4649\n",
      "Epoch [288/300], Loss: 0.4647\n",
      "Epoch [289/300], Loss: 0.4646\n",
      "Epoch [290/300], Loss: 0.4648\n",
      "Epoch [291/300], Loss: 0.4647\n",
      "Epoch [292/300], Loss: 0.4646\n",
      "Epoch [293/300], Loss: 0.4646\n",
      "Epoch [294/300], Loss: 0.4646\n",
      "Epoch [295/300], Loss: 0.4645\n",
      "Epoch [296/300], Loss: 0.4644\n",
      "Epoch [297/300], Loss: 0.4644\n",
      "Epoch [298/300], Loss: 0.4644\n",
      "Epoch [299/300], Loss: 0.4644\n",
      "Epoch [300/300], Loss: 0.4644\n"
     ]
    }
   ],
   "source": [
    "# Example sequential measurement data\n",
    "# Assuming each sequence has 5 time steps and 59 features\n",
    "# X = np.random.randn(14289, 5, 59)\n",
    "X_train = torch.tensor(X_train_input, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test_input, dtype=torch.float32)\n",
    "X_holdout = torch.tensor(X_holdout_input, dtype=torch.float32)\n",
    "\n",
    "# Example classification labels\n",
    "# y = np.random.randint(0, 3, 14289)  # Assuming three classes\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "y_holdout = torch.tensor(y_holdout, dtype=torch.long)\n",
    "\n",
    "# Define LSTM model for classification\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_rate=0.0):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Defining dropout layer with specified dropout rate\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Applying dropout\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.softmax(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Instantiate the classification model\n",
    "input_size = 59  # Number of features in each time step\n",
    "hidden_size = 118  # Number of LSTM units\n",
    "num_layers = 3  # Number of LSTM layers\n",
    "num_classes = 2  # Number of output classes\n",
    "dropout_rate = 0.3  # Example dropout rate\n",
    "classification_model = LSTMClassifier(input_size, hidden_size, num_layers, num_classes, dropout_rate)\n",
    "# classification_model = LSTMClassifier(input_size, hidden_size, num_layers, num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classification_model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the classification model\n",
    "num_epochs = 300\n",
    "for epoch in range(num_epochs):\n",
    "    # classification_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = classification_model.forward(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "593843c7-a909-4409-811d-5d94a5a18db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngqin\\AppData\\Local\\Temp\\ipykernel_12092\\4032854741.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train, dtype=torch.long)\n",
      "C:\\Users\\ngqin\\AppData\\Local\\Temp\\ipykernel_12092\\4032854741.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(y_test, dtype=torch.long)\n",
      "C:\\Users\\ngqin\\AppData\\Local\\Temp\\ipykernel_12092\\4032854741.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_holdout = torch.tensor(y_holdout, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 0.6897\n",
      "Epoch [2/300], Loss: 0.6777\n",
      "Epoch [3/300], Loss: 0.6656\n",
      "Epoch [4/300], Loss: 0.6531\n",
      "Epoch [5/300], Loss: 0.6396\n",
      "Epoch [6/300], Loss: 0.6246\n",
      "Epoch [7/300], Loss: 0.6073\n",
      "Epoch [8/300], Loss: 0.5879\n",
      "Epoch [9/300], Loss: 0.5654\n",
      "Epoch [10/300], Loss: 0.5396\n",
      "Epoch [11/300], Loss: 0.5122\n",
      "Epoch [12/300], Loss: 0.4845\n",
      "Epoch [13/300], Loss: 0.4629\n",
      "Epoch [14/300], Loss: 0.4536\n",
      "Epoch [15/300], Loss: 0.4608\n",
      "Epoch [16/300], Loss: 0.4737\n",
      "Epoch [17/300], Loss: 0.4787\n",
      "Epoch [18/300], Loss: 0.4762\n",
      "Epoch [19/300], Loss: 0.4682\n",
      "Epoch [20/300], Loss: 0.4604\n",
      "Epoch [21/300], Loss: 0.4520\n",
      "Epoch [22/300], Loss: 0.4476\n",
      "Epoch [23/300], Loss: 0.4461\n",
      "Epoch [24/300], Loss: 0.4459\n",
      "Epoch [25/300], Loss: 0.4470\n",
      "Epoch [26/300], Loss: 0.4499\n",
      "Epoch [27/300], Loss: 0.4513\n",
      "Epoch [28/300], Loss: 0.4505\n",
      "Epoch [29/300], Loss: 0.4503\n",
      "Epoch [30/300], Loss: 0.4492\n",
      "Epoch [31/300], Loss: 0.4478\n",
      "Epoch [32/300], Loss: 0.4457\n",
      "Epoch [33/300], Loss: 0.4438\n",
      "Epoch [34/300], Loss: 0.4417\n",
      "Epoch [35/300], Loss: 0.4417\n",
      "Epoch [36/300], Loss: 0.4404\n",
      "Epoch [37/300], Loss: 0.4404\n",
      "Epoch [38/300], Loss: 0.4406\n",
      "Epoch [39/300], Loss: 0.4411\n",
      "Epoch [40/300], Loss: 0.4402\n",
      "Epoch [41/300], Loss: 0.4393\n",
      "Epoch [42/300], Loss: 0.4389\n",
      "Epoch [43/300], Loss: 0.4384\n",
      "Epoch [44/300], Loss: 0.4367\n",
      "Epoch [45/300], Loss: 0.4358\n",
      "Epoch [46/300], Loss: 0.4349\n",
      "Epoch [47/300], Loss: 0.4334\n",
      "Epoch [48/300], Loss: 0.4328\n",
      "Epoch [49/300], Loss: 0.4326\n",
      "Epoch [50/300], Loss: 0.4316\n",
      "Epoch [51/300], Loss: 0.4309\n",
      "Epoch [52/300], Loss: 0.4301\n",
      "Epoch [53/300], Loss: 0.4293\n",
      "Epoch [54/300], Loss: 0.4279\n",
      "Epoch [55/300], Loss: 0.4265\n",
      "Epoch [56/300], Loss: 0.4248\n",
      "Epoch [57/300], Loss: 0.4229\n",
      "Epoch [58/300], Loss: 0.4218\n",
      "Epoch [59/300], Loss: 0.4196\n",
      "Epoch [60/300], Loss: 0.4189\n",
      "Epoch [61/300], Loss: 0.4169\n",
      "Epoch [62/300], Loss: 0.4154\n",
      "Epoch [63/300], Loss: 0.4134\n",
      "Epoch [64/300], Loss: 0.4120\n",
      "Epoch [65/300], Loss: 0.4103\n",
      "Epoch [66/300], Loss: 0.4084\n",
      "Epoch [67/300], Loss: 0.4065\n",
      "Epoch [68/300], Loss: 0.4056\n",
      "Epoch [69/300], Loss: 0.4036\n",
      "Epoch [70/300], Loss: 0.4019\n",
      "Epoch [71/300], Loss: 0.4005\n",
      "Epoch [72/300], Loss: 0.3987\n",
      "Epoch [73/300], Loss: 0.3981\n",
      "Epoch [74/300], Loss: 0.3949\n",
      "Epoch [75/300], Loss: 0.3934\n",
      "Epoch [76/300], Loss: 0.3914\n",
      "Epoch [77/300], Loss: 0.3889\n",
      "Epoch [78/300], Loss: 0.3879\n",
      "Epoch [79/300], Loss: 0.3853\n",
      "Epoch [80/300], Loss: 0.3845\n",
      "Epoch [81/300], Loss: 0.3816\n",
      "Epoch [82/300], Loss: 0.3786\n",
      "Epoch [83/300], Loss: 0.3777\n",
      "Epoch [84/300], Loss: 0.3748\n",
      "Epoch [85/300], Loss: 0.3727\n",
      "Epoch [86/300], Loss: 0.3700\n",
      "Epoch [87/300], Loss: 0.3674\n",
      "Epoch [88/300], Loss: 0.3657\n",
      "Epoch [89/300], Loss: 0.3626\n",
      "Epoch [90/300], Loss: 0.3601\n",
      "Epoch [91/300], Loss: 0.3577\n",
      "Epoch [92/300], Loss: 0.3538\n",
      "Epoch [93/300], Loss: 0.3517\n",
      "Epoch [94/300], Loss: 0.3481\n",
      "Epoch [95/300], Loss: 0.3452\n",
      "Epoch [96/300], Loss: 0.3421\n",
      "Epoch [97/300], Loss: 0.3383\n",
      "Epoch [98/300], Loss: 0.3342\n",
      "Epoch [99/300], Loss: 0.3315\n",
      "Epoch [100/300], Loss: 0.3275\n",
      "Epoch [101/300], Loss: 0.3228\n",
      "Epoch [102/300], Loss: 0.3198\n",
      "Epoch [103/300], Loss: 0.3155\n",
      "Epoch [104/300], Loss: 0.3108\n",
      "Epoch [105/300], Loss: 0.3061\n",
      "Epoch [106/300], Loss: 0.3029\n",
      "Epoch [107/300], Loss: 0.3006\n",
      "Epoch [108/300], Loss: 0.2950\n",
      "Epoch [109/300], Loss: 0.2897\n",
      "Epoch [110/300], Loss: 0.2872\n",
      "Epoch [111/300], Loss: 0.2821\n",
      "Epoch [112/300], Loss: 0.2774\n",
      "Epoch [113/300], Loss: 0.2754\n",
      "Epoch [114/300], Loss: 0.2690\n",
      "Epoch [115/300], Loss: 0.2669\n",
      "Epoch [116/300], Loss: 0.2630\n",
      "Epoch [117/300], Loss: 0.2580\n",
      "Epoch [118/300], Loss: 0.2561\n",
      "Epoch [119/300], Loss: 0.2486\n",
      "Epoch [120/300], Loss: 0.2449\n",
      "Epoch [121/300], Loss: 0.2412\n",
      "Epoch [122/300], Loss: 0.2377\n",
      "Epoch [123/300], Loss: 0.2370\n",
      "Epoch [124/300], Loss: 0.2328\n",
      "Epoch [125/300], Loss: 0.2322\n",
      "Epoch [126/300], Loss: 0.2252\n",
      "Epoch [127/300], Loss: 0.2194\n",
      "Epoch [128/300], Loss: 0.2192\n",
      "Epoch [129/300], Loss: 0.2133\n",
      "Epoch [130/300], Loss: 0.2093\n",
      "Epoch [131/300], Loss: 0.2069\n",
      "Epoch [132/300], Loss: 0.2038\n",
      "Epoch [133/300], Loss: 0.2004\n",
      "Epoch [134/300], Loss: 0.1965\n",
      "Epoch [135/300], Loss: 0.1934\n",
      "Epoch [136/300], Loss: 0.1905\n",
      "Epoch [137/300], Loss: 0.1854\n",
      "Epoch [138/300], Loss: 0.1832\n",
      "Epoch [139/300], Loss: 0.1799\n",
      "Epoch [140/300], Loss: 0.1783\n",
      "Epoch [141/300], Loss: 0.1867\n",
      "Epoch [142/300], Loss: 0.2073\n",
      "Epoch [143/300], Loss: 0.1946\n",
      "Epoch [144/300], Loss: 0.1744\n",
      "Epoch [145/300], Loss: 0.1829\n",
      "Epoch [146/300], Loss: 0.1693\n",
      "Epoch [147/300], Loss: 0.1755\n",
      "Epoch [148/300], Loss: 0.1663\n",
      "Epoch [149/300], Loss: 0.1663\n",
      "Epoch [150/300], Loss: 0.1629\n",
      "Epoch [151/300], Loss: 0.1606\n",
      "Epoch [152/300], Loss: 0.1599\n",
      "Epoch [153/300], Loss: 0.1559\n",
      "Epoch [154/300], Loss: 0.1563\n",
      "Epoch [155/300], Loss: 0.1515\n",
      "Epoch [156/300], Loss: 0.1508\n",
      "Epoch [157/300], Loss: 0.1480\n",
      "Epoch [158/300], Loss: 0.1466\n",
      "Epoch [159/300], Loss: 0.1440\n",
      "Epoch [160/300], Loss: 0.1422\n",
      "Epoch [161/300], Loss: 0.1401\n",
      "Epoch [162/300], Loss: 0.1378\n",
      "Epoch [163/300], Loss: 0.1369\n",
      "Epoch [164/300], Loss: 0.1340\n",
      "Epoch [165/300], Loss: 0.1320\n",
      "Epoch [166/300], Loss: 0.1301\n",
      "Epoch [167/300], Loss: 0.1280\n",
      "Epoch [168/300], Loss: 0.1262\n",
      "Epoch [169/300], Loss: 0.1244\n",
      "Epoch [170/300], Loss: 0.1228\n",
      "Epoch [171/300], Loss: 0.1205\n",
      "Epoch [172/300], Loss: 0.1192\n",
      "Epoch [173/300], Loss: 0.1163\n",
      "Epoch [174/300], Loss: 0.1141\n",
      "Epoch [175/300], Loss: 0.1127\n",
      "Epoch [176/300], Loss: 0.1109\n",
      "Epoch [177/300], Loss: 0.1092\n",
      "Epoch [178/300], Loss: 0.1072\n",
      "Epoch [179/300], Loss: 0.1056\n",
      "Epoch [180/300], Loss: 0.1040\n",
      "Epoch [181/300], Loss: 0.1029\n",
      "Epoch [182/300], Loss: 0.1010\n",
      "Epoch [183/300], Loss: 0.0998\n",
      "Epoch [184/300], Loss: 0.0976\n",
      "Epoch [185/300], Loss: 0.0967\n",
      "Epoch [186/300], Loss: 0.0952\n",
      "Epoch [187/300], Loss: 0.0941\n",
      "Epoch [188/300], Loss: 0.0931\n",
      "Epoch [189/300], Loss: 0.0925\n",
      "Epoch [190/300], Loss: 0.0977\n",
      "Epoch [191/300], Loss: 0.1791\n",
      "Epoch [192/300], Loss: 0.3116\n",
      "Epoch [193/300], Loss: 0.2623\n",
      "Epoch [194/300], Loss: 0.2259\n",
      "Epoch [195/300], Loss: 0.2202\n",
      "Epoch [196/300], Loss: 0.1729\n",
      "Epoch [197/300], Loss: 0.1956\n",
      "Epoch [198/300], Loss: 0.1727\n",
      "Epoch [199/300], Loss: 0.1417\n",
      "Epoch [200/300], Loss: 0.1660\n",
      "Epoch [201/300], Loss: 0.1539\n",
      "Epoch [202/300], Loss: 0.1389\n",
      "Epoch [203/300], Loss: 0.1458\n",
      "Epoch [204/300], Loss: 0.1464\n",
      "Epoch [205/300], Loss: 0.1332\n",
      "Epoch [206/300], Loss: 0.1243\n",
      "Epoch [207/300], Loss: 0.1262\n",
      "Epoch [208/300], Loss: 0.1269\n",
      "Epoch [209/300], Loss: 0.1197\n",
      "Epoch [210/300], Loss: 0.1143\n",
      "Epoch [211/300], Loss: 0.1138\n",
      "Epoch [212/300], Loss: 0.1107\n",
      "Epoch [213/300], Loss: 0.1047\n",
      "Epoch [214/300], Loss: 0.1031\n",
      "Epoch [215/300], Loss: 0.1038\n",
      "Epoch [216/300], Loss: 0.1008\n",
      "Epoch [217/300], Loss: 0.0974\n",
      "Epoch [218/300], Loss: 0.0968\n",
      "Epoch [219/300], Loss: 0.0961\n",
      "Epoch [220/300], Loss: 0.0937\n",
      "Epoch [221/300], Loss: 0.0927\n",
      "Epoch [222/300], Loss: 0.0921\n",
      "Epoch [223/300], Loss: 0.0906\n",
      "Epoch [224/300], Loss: 0.0899\n",
      "Epoch [225/300], Loss: 0.0884\n",
      "Epoch [226/300], Loss: 0.0877\n",
      "Epoch [227/300], Loss: 0.0872\n",
      "Epoch [228/300], Loss: 0.0859\n",
      "Epoch [229/300], Loss: 0.0847\n",
      "Epoch [230/300], Loss: 0.0842\n",
      "Epoch [231/300], Loss: 0.0840\n",
      "Epoch [232/300], Loss: 0.0829\n",
      "Epoch [233/300], Loss: 0.0822\n",
      "Epoch [234/300], Loss: 0.0816\n",
      "Epoch [235/300], Loss: 0.0803\n",
      "Epoch [236/300], Loss: 0.0800\n",
      "Epoch [237/300], Loss: 0.0790\n",
      "Epoch [238/300], Loss: 0.0782\n",
      "Epoch [239/300], Loss: 0.0775\n",
      "Epoch [240/300], Loss: 0.0771\n",
      "Epoch [241/300], Loss: 0.0763\n",
      "Epoch [242/300], Loss: 0.0758\n",
      "Epoch [243/300], Loss: 0.0755\n",
      "Epoch [244/300], Loss: 0.0746\n",
      "Epoch [245/300], Loss: 0.0740\n",
      "Epoch [246/300], Loss: 0.0735\n",
      "Epoch [247/300], Loss: 0.0726\n",
      "Epoch [248/300], Loss: 0.0722\n",
      "Epoch [249/300], Loss: 0.0718\n",
      "Epoch [250/300], Loss: 0.0716\n",
      "Epoch [251/300], Loss: 0.0708\n",
      "Epoch [252/300], Loss: 0.0700\n",
      "Epoch [253/300], Loss: 0.0698\n",
      "Epoch [254/300], Loss: 0.0691\n",
      "Epoch [255/300], Loss: 0.0693\n",
      "Epoch [256/300], Loss: 0.0685\n",
      "Epoch [257/300], Loss: 0.0677\n",
      "Epoch [258/300], Loss: 0.0677\n",
      "Epoch [259/300], Loss: 0.0666\n",
      "Epoch [260/300], Loss: 0.0670\n",
      "Epoch [261/300], Loss: 0.0662\n",
      "Epoch [262/300], Loss: 0.0656\n",
      "Epoch [263/300], Loss: 0.0657\n",
      "Epoch [264/300], Loss: 0.0646\n",
      "Epoch [265/300], Loss: 0.0646\n",
      "Epoch [266/300], Loss: 0.0638\n",
      "Epoch [267/300], Loss: 0.0633\n",
      "Epoch [268/300], Loss: 0.0631\n",
      "Epoch [269/300], Loss: 0.0621\n",
      "Epoch [270/300], Loss: 0.0617\n",
      "Epoch [271/300], Loss: 0.0616\n",
      "Epoch [272/300], Loss: 0.0612\n",
      "Epoch [273/300], Loss: 0.0606\n",
      "Epoch [274/300], Loss: 0.0605\n",
      "Epoch [275/300], Loss: 0.0598\n",
      "Epoch [276/300], Loss: 0.0596\n",
      "Epoch [277/300], Loss: 0.0589\n",
      "Epoch [278/300], Loss: 0.0585\n",
      "Epoch [279/300], Loss: 0.0584\n",
      "Epoch [280/300], Loss: 0.0583\n",
      "Epoch [281/300], Loss: 0.0576\n",
      "Epoch [282/300], Loss: 0.0577\n",
      "Epoch [283/300], Loss: 0.0574\n",
      "Epoch [284/300], Loss: 0.0568\n",
      "Epoch [285/300], Loss: 0.0568\n",
      "Epoch [286/300], Loss: 0.0561\n",
      "Epoch [287/300], Loss: 0.0557\n",
      "Epoch [288/300], Loss: 0.0554\n",
      "Epoch [289/300], Loss: 0.0547\n",
      "Epoch [290/300], Loss: 0.0551\n",
      "Epoch [291/300], Loss: 0.0544\n",
      "Epoch [292/300], Loss: 0.0543\n",
      "Epoch [293/300], Loss: 0.0541\n",
      "Epoch [294/300], Loss: 0.0534\n",
      "Epoch [295/300], Loss: 0.0535\n",
      "Epoch [296/300], Loss: 0.0529\n",
      "Epoch [297/300], Loss: 0.0525\n",
      "Epoch [298/300], Loss: 0.0527\n",
      "Epoch [299/300], Loss: 0.0519\n",
      "Epoch [300/300], Loss: 0.0523\n"
     ]
    }
   ],
   "source": [
    "# Binary classification with BCEloss\n",
    "# Assuming each sequence has 5 time steps and 59 features\n",
    "\n",
    "X_train = torch.tensor(X_train_input, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test_input, dtype=torch.float32)\n",
    "X_holdout = torch.tensor(X_holdout_input, dtype=torch.float32)\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "y_holdout = torch.tensor(y_holdout, dtype=torch.long)\n",
    "\n",
    "# Define LSTM model for classification\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_rate=0.0):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Defining dropout layer with specified dropout rate\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        #self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Applying dropout\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Instantiate the classification model\n",
    "input_size = 59  # Number of features in each time step\n",
    "hidden_size = 118  # Number of LSTM units\n",
    "num_layers = 3  # Number of LSTM layers\n",
    "num_classes = 1  # Number of output classes\n",
    "dropout_rate = 0.3  # Example dropout rate\n",
    "classification_model = LSTMClassifier(input_size, hidden_size, num_layers, num_classes, dropout_rate)\n",
    "# classification_model = LSTMClassifier(input_size, hidden_size, num_layers, num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(classification_model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the classification model\n",
    "num_epochs = 300\n",
    "for epoch in range(num_epochs):\n",
    "    # classification_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = classification_model.forward(X_train).squeeze(dim=1)\n",
    "    y_train = y_train.float()\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbe45195-b1cc-4566-832b-46c7633b9f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90      3321\n",
      "           1       0.00      0.00      0.00       762\n",
      "\n",
      "    accuracy                           0.81      4083\n",
      "   macro avg       0.41      0.50      0.45      4083\n",
      "weighted avg       0.66      0.81      0.73      4083\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngqin\\anaconda3\\envs\\python3.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ngqin\\anaconda3\\envs\\python3.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ngqin\\anaconda3\\envs\\python3.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the classification model\n",
    "classification_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = classification_model(X_test)\n",
    "    # _, predicted = torch.max(outputs, 1)\n",
    "    predicted = torch.argmax(outputs, dim=1)\n",
    "\n",
    "# Convert predicted tensor to numpy array\n",
    "predicted = predicted.numpy()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test.numpy(), predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e300b789-0343-49bc-a758-33b0c85537a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90      1684\n",
      "           1       0.00      0.00      0.00       358\n",
      "\n",
      "    accuracy                           0.82      2042\n",
      "   macro avg       0.41      0.50      0.45      2042\n",
      "weighted avg       0.68      0.82      0.75      2042\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngqin\\anaconda3\\envs\\python3.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ngqin\\anaconda3\\envs\\python3.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ngqin\\anaconda3\\envs\\python3.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the classification model\n",
    "classification_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = classification_model(X_holdout)\n",
    "    # _, predicted = torch.max(outputs, 1)\n",
    "    predicted = torch.argmax(outputs, dim=1)\n",
    "\n",
    "# Convert predicted tensor to numpy array\n",
    "predicted = predicted.numpy()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_holdout.numpy(), predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc142982-bf5b-495e-ba65-6923a4611604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[3321    0]\n",
      " [ 762    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Evaluate the classification model\n",
    "classification_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = classification_model(X_test)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Convert predicted tensor to numpy array\n",
    "predicted = predicted.numpy()\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test.numpy(), predicted)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad4b42bc-faa9-403e-b537-e8fcc5d3213d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92     11753\n",
      "           1       0.88      0.17      0.29      2536\n",
      "\n",
      "    accuracy                           0.85     14289\n",
      "   macro avg       0.86      0.58      0.60     14289\n",
      "weighted avg       0.85      0.85      0.80     14289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classification model\n",
    "classification_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = classification_model(X_train)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Convert predicted tensor to numpy array\n",
    "predicted = predicted.numpy()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_train.numpy(), predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "636ccb24-5ec5-4b69-9e69-64a8971935d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[4664  674  910]\n",
      " [ 770 2176 1252]\n",
      " [  76  319 3448]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Evaluate the classification model\n",
    "classification_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = classification_model(X_train)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Convert predicted tensor to numpy array\n",
    "predicted = predicted.numpy()\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_train.numpy(), predicted)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66c61b12-1b01-4cda-8d11-7c1a8e81d38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Loss: 0.6933\n",
      "Epoch [2/300], Loss: 0.6580\n",
      "Epoch [3/300], Loss: 0.6255\n",
      "Epoch [4/300], Loss: 0.5947\n",
      "Epoch [5/300], Loss: 0.5659\n",
      "Epoch [6/300], Loss: 0.5407\n",
      "Epoch [7/300], Loss: 0.5200\n",
      "Epoch [8/300], Loss: 0.5061\n",
      "Epoch [9/300], Loss: 0.4979\n",
      "Epoch [10/300], Loss: 0.4938\n",
      "Epoch [11/300], Loss: 0.4919\n",
      "Epoch [12/300], Loss: 0.4910\n",
      "Epoch [13/300], Loss: 0.4905\n",
      "Epoch [14/300], Loss: 0.4901\n",
      "Epoch [15/300], Loss: 0.4897\n",
      "Epoch [16/300], Loss: 0.4896\n",
      "Epoch [17/300], Loss: 0.4897\n",
      "Epoch [18/300], Loss: 0.4894\n",
      "Epoch [19/300], Loss: 0.4889\n",
      "Epoch [20/300], Loss: 0.4886\n",
      "Epoch [21/300], Loss: 0.4883\n",
      "Epoch [22/300], Loss: 0.4881\n",
      "Epoch [23/300], Loss: 0.4877\n",
      "Epoch [24/300], Loss: 0.4877\n",
      "Epoch [25/300], Loss: 0.4876\n",
      "Epoch [26/300], Loss: 0.4873\n",
      "Epoch [27/300], Loss: 0.4872\n",
      "Epoch [28/300], Loss: 0.4869\n",
      "Epoch [29/300], Loss: 0.4866\n",
      "Epoch [30/300], Loss: 0.4866\n",
      "Epoch [31/300], Loss: 0.4862\n",
      "Epoch [32/300], Loss: 0.4863\n",
      "Epoch [33/300], Loss: 0.4860\n",
      "Epoch [34/300], Loss: 0.4858\n",
      "Epoch [35/300], Loss: 0.4854\n",
      "Epoch [36/300], Loss: 0.4853\n",
      "Epoch [37/300], Loss: 0.4853\n",
      "Epoch [38/300], Loss: 0.4850\n",
      "Epoch [39/300], Loss: 0.4849\n",
      "Epoch [40/300], Loss: 0.4849\n",
      "Epoch [41/300], Loss: 0.4848\n",
      "Epoch [42/300], Loss: 0.4845\n",
      "Epoch [43/300], Loss: 0.4844\n",
      "Epoch [44/300], Loss: 0.4843\n",
      "Epoch [45/300], Loss: 0.4841\n",
      "Epoch [46/300], Loss: 0.4841\n",
      "Epoch [47/300], Loss: 0.4839\n",
      "Epoch [48/300], Loss: 0.4838\n",
      "Epoch [49/300], Loss: 0.4837\n",
      "Epoch [50/300], Loss: 0.4836\n",
      "Epoch [51/300], Loss: 0.4834\n",
      "Epoch [52/300], Loss: 0.4834\n",
      "Epoch [53/300], Loss: 0.4835\n",
      "Epoch [54/300], Loss: 0.4834\n",
      "Epoch [55/300], Loss: 0.4831\n",
      "Epoch [56/300], Loss: 0.4832\n",
      "Epoch [57/300], Loss: 0.4830\n",
      "Epoch [58/300], Loss: 0.4828\n",
      "Epoch [59/300], Loss: 0.4828\n",
      "Epoch [60/300], Loss: 0.4828\n",
      "Epoch [61/300], Loss: 0.4826\n",
      "Epoch [62/300], Loss: 0.4827\n",
      "Epoch [63/300], Loss: 0.4824\n",
      "Epoch [64/300], Loss: 0.4824\n",
      "Epoch [65/300], Loss: 0.4823\n",
      "Epoch [66/300], Loss: 0.4824\n",
      "Epoch [67/300], Loss: 0.4822\n",
      "Epoch [68/300], Loss: 0.4823\n",
      "Epoch [69/300], Loss: 0.4822\n",
      "Epoch [70/300], Loss: 0.4821\n",
      "Epoch [71/300], Loss: 0.4820\n",
      "Epoch [72/300], Loss: 0.4820\n",
      "Epoch [73/300], Loss: 0.4819\n",
      "Epoch [74/300], Loss: 0.4819\n",
      "Epoch [75/300], Loss: 0.4818\n",
      "Epoch [76/300], Loss: 0.4818\n",
      "Epoch [77/300], Loss: 0.4818\n",
      "Epoch [78/300], Loss: 0.4817\n",
      "Epoch [79/300], Loss: 0.4817\n",
      "Epoch [80/300], Loss: 0.4817\n",
      "Epoch [81/300], Loss: 0.4817\n",
      "Epoch [82/300], Loss: 0.4816\n",
      "Epoch [83/300], Loss: 0.4816\n",
      "Epoch [84/300], Loss: 0.4816\n",
      "Epoch [85/300], Loss: 0.4816\n",
      "Epoch [86/300], Loss: 0.4815\n",
      "Epoch [87/300], Loss: 0.4815\n",
      "Epoch [88/300], Loss: 0.4815\n",
      "Epoch [89/300], Loss: 0.4815\n",
      "Epoch [90/300], Loss: 0.4815\n",
      "Epoch [91/300], Loss: 0.4814\n",
      "Epoch [92/300], Loss: 0.4813\n",
      "Epoch [93/300], Loss: 0.4813\n",
      "Epoch [94/300], Loss: 0.4813\n",
      "Epoch [95/300], Loss: 0.4813\n",
      "Epoch [96/300], Loss: 0.4813\n",
      "Epoch [97/300], Loss: 0.4812\n",
      "Epoch [98/300], Loss: 0.4812\n",
      "Epoch [99/300], Loss: 0.4812\n",
      "Epoch [100/300], Loss: 0.4811\n",
      "Epoch [101/300], Loss: 0.4812\n",
      "Epoch [102/300], Loss: 0.4812\n",
      "Epoch [103/300], Loss: 0.4812\n",
      "Epoch [104/300], Loss: 0.4811\n",
      "Epoch [105/300], Loss: 0.4810\n",
      "Epoch [106/300], Loss: 0.4811\n",
      "Epoch [107/300], Loss: 0.4811\n",
      "Epoch [108/300], Loss: 0.4810\n",
      "Epoch [109/300], Loss: 0.4810\n",
      "Epoch [110/300], Loss: 0.4809\n",
      "Epoch [111/300], Loss: 0.4810\n",
      "Epoch [112/300], Loss: 0.4809\n",
      "Epoch [113/300], Loss: 0.4809\n",
      "Epoch [114/300], Loss: 0.4809\n",
      "Epoch [115/300], Loss: 0.4809\n",
      "Epoch [116/300], Loss: 0.4809\n",
      "Epoch [117/300], Loss: 0.4808\n",
      "Epoch [118/300], Loss: 0.4808\n",
      "Epoch [119/300], Loss: 0.4808\n",
      "Epoch [120/300], Loss: 0.4808\n",
      "Epoch [121/300], Loss: 0.4808\n",
      "Epoch [122/300], Loss: 0.4808\n",
      "Epoch [123/300], Loss: 0.4807\n",
      "Epoch [124/300], Loss: 0.4807\n",
      "Epoch [125/300], Loss: 0.4807\n",
      "Epoch [126/300], Loss: 0.4807\n",
      "Epoch [127/300], Loss: 0.4807\n",
      "Epoch [128/300], Loss: 0.4806\n",
      "Epoch [129/300], Loss: 0.4806\n",
      "Epoch [130/300], Loss: 0.4806\n",
      "Epoch [131/300], Loss: 0.4806\n",
      "Epoch [132/300], Loss: 0.4805\n",
      "Epoch [133/300], Loss: 0.4805\n",
      "Epoch [134/300], Loss: 0.4806\n",
      "Epoch [135/300], Loss: 0.4809\n",
      "Epoch [136/300], Loss: 0.4810\n",
      "Epoch [137/300], Loss: 0.4816\n",
      "Epoch [138/300], Loss: 0.4810\n",
      "Epoch [139/300], Loss: 0.4808\n",
      "Epoch [140/300], Loss: 0.4811\n",
      "Epoch [141/300], Loss: 0.4808\n",
      "Epoch [142/300], Loss: 0.4806\n",
      "Epoch [143/300], Loss: 0.4809\n",
      "Epoch [144/300], Loss: 0.4807\n",
      "Epoch [145/300], Loss: 0.4806\n",
      "Epoch [146/300], Loss: 0.4805\n",
      "Epoch [147/300], Loss: 0.4807\n",
      "Epoch [148/300], Loss: 0.4806\n",
      "Epoch [149/300], Loss: 0.4804\n",
      "Epoch [150/300], Loss: 0.4806\n",
      "Epoch [151/300], Loss: 0.4804\n",
      "Epoch [152/300], Loss: 0.4804\n",
      "Epoch [153/300], Loss: 0.4805\n",
      "Epoch [154/300], Loss: 0.4805\n",
      "Epoch [155/300], Loss: 0.4803\n",
      "Epoch [156/300], Loss: 0.4805\n",
      "Epoch [157/300], Loss: 0.4803\n",
      "Epoch [158/300], Loss: 0.4804\n",
      "Epoch [159/300], Loss: 0.4803\n",
      "Epoch [160/300], Loss: 0.4803\n",
      "Epoch [161/300], Loss: 0.4802\n",
      "Epoch [162/300], Loss: 0.4803\n",
      "Epoch [163/300], Loss: 0.4802\n",
      "Epoch [164/300], Loss: 0.4802\n",
      "Epoch [165/300], Loss: 0.4801\n",
      "Epoch [166/300], Loss: 0.4801\n",
      "Epoch [167/300], Loss: 0.4801\n",
      "Epoch [168/300], Loss: 0.4801\n",
      "Epoch [169/300], Loss: 0.4800\n",
      "Epoch [170/300], Loss: 0.4800\n",
      "Epoch [171/300], Loss: 0.4800\n",
      "Epoch [172/300], Loss: 0.4800\n",
      "Epoch [173/300], Loss: 0.4800\n",
      "Epoch [174/300], Loss: 0.4800\n",
      "Epoch [175/300], Loss: 0.4800\n",
      "Epoch [176/300], Loss: 0.4800\n",
      "Epoch [177/300], Loss: 0.4800\n",
      "Epoch [178/300], Loss: 0.4800\n",
      "Epoch [179/300], Loss: 0.4800\n",
      "Epoch [180/300], Loss: 0.4800\n",
      "Epoch [181/300], Loss: 0.4799\n",
      "Epoch [182/300], Loss: 0.4799\n",
      "Epoch [183/300], Loss: 0.4799\n",
      "Epoch [184/300], Loss: 0.4799\n",
      "Epoch [185/300], Loss: 0.4799\n",
      "Epoch [186/300], Loss: 0.4799\n",
      "Epoch [187/300], Loss: 0.4799\n",
      "Epoch [188/300], Loss: 0.4798\n",
      "Epoch [189/300], Loss: 0.4798\n",
      "Epoch [190/300], Loss: 0.4798\n",
      "Epoch [191/300], Loss: 0.4798\n",
      "Epoch [192/300], Loss: 0.4798\n",
      "Epoch [193/300], Loss: 0.4798\n",
      "Epoch [194/300], Loss: 0.4798\n",
      "Epoch [195/300], Loss: 0.4798\n",
      "Epoch [196/300], Loss: 0.4798\n",
      "Epoch [197/300], Loss: 0.4798\n",
      "Epoch [198/300], Loss: 0.4798\n",
      "Epoch [199/300], Loss: 0.4798\n",
      "Epoch [200/300], Loss: 0.4798\n",
      "Epoch [201/300], Loss: 0.4798\n",
      "Epoch [202/300], Loss: 0.4798\n",
      "Epoch [203/300], Loss: 0.4798\n",
      "Epoch [204/300], Loss: 0.4798\n",
      "Epoch [205/300], Loss: 0.4798\n",
      "Epoch [206/300], Loss: 0.4798\n",
      "Epoch [207/300], Loss: 0.4798\n",
      "Epoch [208/300], Loss: 0.4798\n",
      "Epoch [209/300], Loss: 0.4798\n",
      "Epoch [210/300], Loss: 0.4798\n",
      "Epoch [211/300], Loss: 0.4798\n",
      "Epoch [212/300], Loss: 0.4798\n",
      "Epoch [213/300], Loss: 0.4798\n",
      "Epoch [214/300], Loss: 0.4798\n",
      "Epoch [215/300], Loss: 0.4798\n",
      "Epoch [216/300], Loss: 0.4798\n",
      "Epoch [217/300], Loss: 0.4798\n",
      "Epoch [218/300], Loss: 0.4798\n",
      "Epoch [219/300], Loss: 0.4798\n",
      "Epoch [220/300], Loss: 0.4798\n",
      "Epoch [221/300], Loss: 0.4798\n",
      "Epoch [222/300], Loss: 0.4798\n",
      "Epoch [223/300], Loss: 0.4798\n",
      "Epoch [224/300], Loss: 0.4798\n",
      "Epoch [225/300], Loss: 0.4798\n",
      "Epoch [226/300], Loss: 0.4798\n",
      "Epoch [227/300], Loss: 0.4798\n",
      "Epoch [228/300], Loss: 0.4798\n",
      "Epoch [229/300], Loss: 0.4798\n",
      "Epoch [230/300], Loss: 0.4797\n",
      "Epoch [231/300], Loss: 0.4797\n",
      "Epoch [232/300], Loss: 0.4797\n",
      "Epoch [233/300], Loss: 0.4797\n",
      "Epoch [234/300], Loss: 0.4797\n",
      "Epoch [235/300], Loss: 0.4796\n",
      "Epoch [236/300], Loss: 0.4796\n",
      "Epoch [237/300], Loss: 0.4796\n",
      "Epoch [238/300], Loss: 0.4796\n",
      "Epoch [239/300], Loss: 0.4796\n",
      "Epoch [240/300], Loss: 0.4796\n",
      "Epoch [241/300], Loss: 0.4796\n",
      "Epoch [242/300], Loss: 0.4796\n",
      "Epoch [243/300], Loss: 0.4796\n",
      "Epoch [244/300], Loss: 0.4795\n",
      "Epoch [245/300], Loss: 0.4795\n",
      "Epoch [246/300], Loss: 0.4795\n",
      "Epoch [247/300], Loss: 0.4795\n",
      "Epoch [248/300], Loss: 0.4795\n",
      "Epoch [249/300], Loss: 0.4795\n",
      "Epoch [250/300], Loss: 0.4795\n",
      "Epoch [251/300], Loss: 0.4795\n",
      "Epoch [252/300], Loss: 0.4795\n",
      "Epoch [253/300], Loss: 0.4794\n",
      "Epoch [254/300], Loss: 0.4794\n",
      "Epoch [255/300], Loss: 0.4794\n",
      "Epoch [256/300], Loss: 0.4794\n",
      "Epoch [257/300], Loss: 0.4794\n",
      "Epoch [258/300], Loss: 0.4794\n",
      "Epoch [259/300], Loss: 0.4793\n",
      "Epoch [260/300], Loss: 0.4793\n",
      "Epoch [261/300], Loss: 0.4793\n",
      "Epoch [262/300], Loss: 0.4793\n",
      "Epoch [263/300], Loss: 0.4793\n",
      "Epoch [264/300], Loss: 0.4793\n",
      "Epoch [265/300], Loss: 0.4793\n",
      "Epoch [266/300], Loss: 0.4793\n",
      "Epoch [267/300], Loss: 0.4793\n",
      "Epoch [268/300], Loss: 0.4792\n",
      "Epoch [269/300], Loss: 0.4792\n",
      "Epoch [270/300], Loss: 0.4792\n",
      "Epoch [271/300], Loss: 0.4792\n",
      "Epoch [272/300], Loss: 0.4792\n",
      "Epoch [273/300], Loss: 0.4792\n",
      "Epoch [274/300], Loss: 0.4792\n",
      "Epoch [275/300], Loss: 0.4792\n",
      "Epoch [276/300], Loss: 0.4792\n",
      "Epoch [277/300], Loss: 0.4792\n",
      "Epoch [278/300], Loss: 0.4791\n",
      "Epoch [279/300], Loss: 0.4791\n",
      "Epoch [280/300], Loss: 0.4791\n",
      "Epoch [281/300], Loss: 0.4792\n",
      "Epoch [282/300], Loss: 0.4792\n",
      "Epoch [283/300], Loss: 0.4791\n",
      "Epoch [284/300], Loss: 0.4794\n",
      "Epoch [285/300], Loss: 0.4794\n",
      "Epoch [286/300], Loss: 0.4791\n",
      "Epoch [287/300], Loss: 0.4794\n",
      "Epoch [288/300], Loss: 0.4792\n",
      "Epoch [289/300], Loss: 0.4795\n",
      "Epoch [290/300], Loss: 0.4803\n",
      "Epoch [291/300], Loss: 0.4798\n",
      "Epoch [292/300], Loss: 0.4806\n",
      "Epoch [293/300], Loss: 0.4802\n",
      "Epoch [294/300], Loss: 0.4794\n",
      "Epoch [295/300], Loss: 0.4795\n",
      "Epoch [296/300], Loss: 0.4815\n",
      "Epoch [297/300], Loss: 0.4800\n",
      "Epoch [298/300], Loss: 0.4817\n",
      "Epoch [299/300], Loss: 0.4802\n",
      "Epoch [300/300], Loss: 0.4810\n"
     ]
    }
   ],
   "source": [
    "# Define RNN model for classification\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_rate=0.0):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Defining dropout layer with specified dropout rate\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        \n",
    "        # Applying dropout\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "# Instantiate the classification model\n",
    "input_size = 59  # Number of features in each time step\n",
    "hidden_size = 118  # Number of RNN units\n",
    "num_layers = 2  # Number of RNN layers\n",
    "num_classes = 2  # Number of output classes\n",
    "dropout_rate = 0.4  # Example dropout rate\n",
    "classification_model = RNNClassifier(input_size, hidden_size, num_layers, num_classes, dropout_rate)\n",
    "# classification_model = RNNClassifier(input_size, hidden_size, num_layers, num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classification_model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the classification model\n",
    "num_epochs = 300\n",
    "for epoch in range(num_epochs):\n",
    "    # classification_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = classification_model.forward(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2304899-26d7-4a52-807b-8e776704b094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.89      3321\n",
      "           1       0.41      0.03      0.06       762\n",
      "\n",
      "    accuracy                           0.81      4083\n",
      "   macro avg       0.61      0.51      0.48      4083\n",
      "weighted avg       0.74      0.81      0.74      4083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the classification model\n",
    "classification_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = classification_model(X_test)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Convert predicted tensor to numpy array\n",
    "predicted = predicted.numpy()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test.numpy(), predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bad87d4c-ceba-43d8-a194-f714aad00642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90      1684\n",
      "           1       0.40      0.03      0.06       358\n",
      "\n",
      "    accuracy                           0.82      2042\n",
      "   macro avg       0.61      0.51      0.48      2042\n",
      "weighted avg       0.75      0.82      0.75      2042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the classification model\n",
    "classification_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = classification_model(X_holdout)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Convert predicted tensor to numpy array\n",
    "predicted = predicted.numpy()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_holdout.numpy(), predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc9930e7-d4d1-4ca6-a6e1-4b765969cea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[3286   35]\n",
      " [ 738   24]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Evaluate the classification model\n",
    "classification_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = classification_model(X_test)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Convert predicted tensor to numpy array\n",
    "predicted = predicted.numpy()\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test.numpy(), predicted)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2b6e6f44-1861-46f3-a0a8-b17c35415811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.2430170774459839\n",
      "Epoch [2/10], Loss: 1.2445777654647827\n",
      "Epoch [3/10], Loss: 1.2082958221435547\n",
      "Epoch [4/10], Loss: 1.2565702199935913\n",
      "Epoch [5/10], Loss: 1.2094172239303589\n",
      "Epoch [6/10], Loss: 1.1871225833892822\n",
      "Epoch [7/10], Loss: 1.215932846069336\n",
      "Epoch [8/10], Loss: 1.208574891090393\n",
      "Epoch [9/10], Loss: 1.1900966167449951\n",
      "Epoch [10/10], Loss: 1.2072184085845947\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[133], line 58\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Test the model\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 58\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mX_test\u001b[49m))\n\u001b[0;32m     59\u001b[0m     _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     60\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m (predicted \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(y_test, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39m y_test\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define LSTM model\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 59\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "num_classes = 3\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = LSTMClassifier(input_size, hidden_size, num_layers, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Convert data to torch tensors\n",
    "X_train_tensor = torch.tensor(time_input, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(X_train_tensor), batch_size):\n",
    "        inputs = X_train_tensor[i:i+batch_size]\n",
    "        targets = y_train_tensor[i:i+batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(torch.tensor(X_test))\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    accuracy = (predicted == torch.argmax(y_test, dim=1)).sum().item() / y_test.size(0)\n",
    "    print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f0f619-94db-4e4d-8cd3-eca024db5592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be623a2e-9cf4-44af-8607-88359e6c6c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c418752-2c74-422d-9825-fec41b2f96b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a95be201-c00f-499a-aefc-9d0d3d7b67be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 0.6948\n",
      "Epoch [2/1000], Loss: 0.6923\n",
      "Epoch [3/1000], Loss: 0.6898\n",
      "Epoch [4/1000], Loss: 0.6856\n",
      "Epoch [5/1000], Loss: 0.6798\n",
      "Epoch [6/1000], Loss: 0.6717\n",
      "Epoch [7/1000], Loss: 0.6626\n",
      "Epoch [8/1000], Loss: 0.6523\n",
      "Epoch [9/1000], Loss: 0.6410\n",
      "Epoch [10/1000], Loss: 0.6292\n",
      "Epoch [11/1000], Loss: 0.6176\n",
      "Epoch [12/1000], Loss: 0.6043\n",
      "Epoch [13/1000], Loss: 0.5914\n",
      "Epoch [14/1000], Loss: 0.5783\n",
      "Epoch [15/1000], Loss: 0.5662\n",
      "Epoch [16/1000], Loss: 0.5540\n",
      "Epoch [17/1000], Loss: 0.5414\n",
      "Epoch [18/1000], Loss: 0.5312\n",
      "Epoch [19/1000], Loss: 0.5224\n",
      "Epoch [20/1000], Loss: 0.5151\n",
      "Epoch [21/1000], Loss: 0.5090\n",
      "Epoch [22/1000], Loss: 0.5037\n",
      "Epoch [23/1000], Loss: 0.5001\n",
      "Epoch [24/1000], Loss: 0.4974\n",
      "Epoch [25/1000], Loss: 0.4953\n",
      "Epoch [26/1000], Loss: 0.4938\n",
      "Epoch [27/1000], Loss: 0.4927\n",
      "Epoch [28/1000], Loss: 0.4922\n",
      "Epoch [29/1000], Loss: 0.4916\n",
      "Epoch [30/1000], Loss: 0.4913\n",
      "Epoch [31/1000], Loss: 0.4909\n",
      "Epoch [32/1000], Loss: 0.4910\n",
      "Epoch [33/1000], Loss: 0.4908\n",
      "Epoch [34/1000], Loss: 0.4906\n",
      "Epoch [35/1000], Loss: 0.4907\n",
      "Epoch [36/1000], Loss: 0.4907\n",
      "Epoch [37/1000], Loss: 0.4905\n",
      "Epoch [38/1000], Loss: 0.4906\n",
      "Epoch [39/1000], Loss: 0.4904\n",
      "Epoch [40/1000], Loss: 0.4905\n",
      "Epoch [41/1000], Loss: 0.4905\n",
      "Epoch [42/1000], Loss: 0.4905\n",
      "Epoch [43/1000], Loss: 0.4905\n",
      "Epoch [44/1000], Loss: 0.4905\n",
      "Epoch [45/1000], Loss: 0.4904\n",
      "Epoch [46/1000], Loss: 0.4904\n",
      "Epoch [47/1000], Loss: 0.4903\n",
      "Epoch [48/1000], Loss: 0.4903\n",
      "Epoch [49/1000], Loss: 0.4904\n",
      "Epoch [50/1000], Loss: 0.4903\n",
      "Epoch [51/1000], Loss: 0.4903\n",
      "Epoch [52/1000], Loss: 0.4903\n",
      "Epoch [53/1000], Loss: 0.4902\n",
      "Epoch [54/1000], Loss: 0.4902\n",
      "Epoch [55/1000], Loss: 0.4902\n",
      "Epoch [56/1000], Loss: 0.4902\n",
      "Epoch [57/1000], Loss: 0.4902\n",
      "Epoch [58/1000], Loss: 0.4902\n",
      "Epoch [59/1000], Loss: 0.4900\n",
      "Epoch [60/1000], Loss: 0.4901\n",
      "Epoch [61/1000], Loss: 0.4901\n",
      "Epoch [62/1000], Loss: 0.4899\n",
      "Epoch [63/1000], Loss: 0.4900\n",
      "Epoch [64/1000], Loss: 0.4900\n",
      "Epoch [65/1000], Loss: 0.4900\n",
      "Epoch [66/1000], Loss: 0.4898\n",
      "Epoch [67/1000], Loss: 0.4898\n",
      "Epoch [68/1000], Loss: 0.4897\n",
      "Epoch [69/1000], Loss: 0.4898\n",
      "Epoch [70/1000], Loss: 0.4897\n",
      "Epoch [71/1000], Loss: 0.4897\n",
      "Epoch [72/1000], Loss: 0.4896\n",
      "Epoch [73/1000], Loss: 0.4895\n",
      "Epoch [74/1000], Loss: 0.4896\n",
      "Epoch [75/1000], Loss: 0.4893\n",
      "Epoch [76/1000], Loss: 0.4894\n",
      "Epoch [77/1000], Loss: 0.4894\n",
      "Epoch [78/1000], Loss: 0.4892\n",
      "Epoch [79/1000], Loss: 0.4891\n",
      "Epoch [80/1000], Loss: 0.4891\n",
      "Epoch [81/1000], Loss: 0.4890\n",
      "Epoch [82/1000], Loss: 0.4890\n",
      "Epoch [83/1000], Loss: 0.4889\n",
      "Epoch [84/1000], Loss: 0.4889\n",
      "Epoch [85/1000], Loss: 0.4888\n",
      "Epoch [86/1000], Loss: 0.4887\n",
      "Epoch [87/1000], Loss: 0.4886\n",
      "Epoch [88/1000], Loss: 0.4885\n",
      "Epoch [89/1000], Loss: 0.4885\n",
      "Epoch [90/1000], Loss: 0.4885\n",
      "Epoch [91/1000], Loss: 0.4884\n",
      "Epoch [92/1000], Loss: 0.4882\n",
      "Epoch [93/1000], Loss: 0.4881\n",
      "Epoch [94/1000], Loss: 0.4879\n",
      "Epoch [95/1000], Loss: 0.4880\n",
      "Epoch [96/1000], Loss: 0.4880\n",
      "Epoch [97/1000], Loss: 0.4877\n",
      "Epoch [98/1000], Loss: 0.4877\n",
      "Epoch [99/1000], Loss: 0.4876\n",
      "Epoch [100/1000], Loss: 0.4877\n",
      "Epoch [101/1000], Loss: 0.4876\n",
      "Epoch [102/1000], Loss: 0.4875\n",
      "Epoch [103/1000], Loss: 0.4874\n",
      "Epoch [104/1000], Loss: 0.4872\n",
      "Epoch [105/1000], Loss: 0.4872\n",
      "Epoch [106/1000], Loss: 0.4871\n",
      "Epoch [107/1000], Loss: 0.4870\n",
      "Epoch [108/1000], Loss: 0.4870\n",
      "Epoch [109/1000], Loss: 0.4869\n",
      "Epoch [110/1000], Loss: 0.4867\n",
      "Epoch [111/1000], Loss: 0.4868\n",
      "Epoch [112/1000], Loss: 0.4867\n",
      "Epoch [113/1000], Loss: 0.4865\n",
      "Epoch [114/1000], Loss: 0.4865\n",
      "Epoch [115/1000], Loss: 0.4864\n",
      "Epoch [116/1000], Loss: 0.4862\n",
      "Epoch [117/1000], Loss: 0.4861\n",
      "Epoch [118/1000], Loss: 0.4862\n",
      "Epoch [119/1000], Loss: 0.4859\n",
      "Epoch [120/1000], Loss: 0.4859\n",
      "Epoch [121/1000], Loss: 0.4859\n",
      "Epoch [122/1000], Loss: 0.4857\n",
      "Epoch [123/1000], Loss: 0.4858\n",
      "Epoch [124/1000], Loss: 0.4856\n",
      "Epoch [125/1000], Loss: 0.4857\n",
      "Epoch [126/1000], Loss: 0.4856\n",
      "Epoch [127/1000], Loss: 0.4855\n",
      "Epoch [128/1000], Loss: 0.4852\n",
      "Epoch [129/1000], Loss: 0.4852\n",
      "Epoch [130/1000], Loss: 0.4853\n",
      "Epoch [131/1000], Loss: 0.4851\n",
      "Epoch [132/1000], Loss: 0.4850\n",
      "Epoch [133/1000], Loss: 0.4848\n",
      "Epoch [134/1000], Loss: 0.4850\n",
      "Epoch [135/1000], Loss: 0.4847\n",
      "Epoch [136/1000], Loss: 0.4848\n",
      "Epoch [137/1000], Loss: 0.4846\n",
      "Epoch [138/1000], Loss: 0.4845\n",
      "Epoch [139/1000], Loss: 0.4844\n",
      "Epoch [140/1000], Loss: 0.4842\n",
      "Epoch [141/1000], Loss: 0.4843\n",
      "Epoch [142/1000], Loss: 0.4841\n",
      "Epoch [143/1000], Loss: 0.4843\n",
      "Epoch [144/1000], Loss: 0.4840\n",
      "Epoch [145/1000], Loss: 0.4838\n",
      "Epoch [146/1000], Loss: 0.4838\n",
      "Epoch [147/1000], Loss: 0.4838\n",
      "Epoch [148/1000], Loss: 0.4835\n",
      "Epoch [149/1000], Loss: 0.4834\n",
      "Epoch [150/1000], Loss: 0.4835\n",
      "Epoch [151/1000], Loss: 0.4833\n",
      "Epoch [152/1000], Loss: 0.4834\n",
      "Epoch [153/1000], Loss: 0.4832\n",
      "Epoch [154/1000], Loss: 0.4831\n",
      "Epoch [155/1000], Loss: 0.4829\n",
      "Epoch [156/1000], Loss: 0.4827\n",
      "Epoch [157/1000], Loss: 0.4828\n",
      "Epoch [158/1000], Loss: 0.4828\n",
      "Epoch [159/1000], Loss: 0.4825\n",
      "Epoch [160/1000], Loss: 0.4827\n",
      "Epoch [161/1000], Loss: 0.4825\n",
      "Epoch [162/1000], Loss: 0.4822\n",
      "Epoch [163/1000], Loss: 0.4821\n",
      "Epoch [164/1000], Loss: 0.4822\n",
      "Epoch [165/1000], Loss: 0.4823\n",
      "Epoch [166/1000], Loss: 0.4820\n",
      "Epoch [167/1000], Loss: 0.4818\n",
      "Epoch [168/1000], Loss: 0.4819\n",
      "Epoch [169/1000], Loss: 0.4816\n",
      "Epoch [170/1000], Loss: 0.4816\n",
      "Epoch [171/1000], Loss: 0.4813\n",
      "Epoch [172/1000], Loss: 0.4814\n",
      "Epoch [173/1000], Loss: 0.4814\n",
      "Epoch [174/1000], Loss: 0.4812\n",
      "Epoch [175/1000], Loss: 0.4811\n",
      "Epoch [176/1000], Loss: 0.4810\n",
      "Epoch [177/1000], Loss: 0.4810\n",
      "Epoch [178/1000], Loss: 0.4808\n",
      "Epoch [179/1000], Loss: 0.4808\n",
      "Epoch [180/1000], Loss: 0.4806\n",
      "Epoch [181/1000], Loss: 0.4807\n",
      "Epoch [182/1000], Loss: 0.4805\n",
      "Epoch [183/1000], Loss: 0.4803\n",
      "Epoch [184/1000], Loss: 0.4802\n",
      "Epoch [185/1000], Loss: 0.4801\n",
      "Epoch [186/1000], Loss: 0.4801\n",
      "Epoch [187/1000], Loss: 0.4800\n",
      "Epoch [188/1000], Loss: 0.4798\n",
      "Epoch [189/1000], Loss: 0.4797\n",
      "Epoch [190/1000], Loss: 0.4794\n",
      "Epoch [191/1000], Loss: 0.4795\n",
      "Epoch [192/1000], Loss: 0.4794\n",
      "Epoch [193/1000], Loss: 0.4792\n",
      "Epoch [194/1000], Loss: 0.4792\n",
      "Epoch [195/1000], Loss: 0.4789\n",
      "Epoch [196/1000], Loss: 0.4789\n",
      "Epoch [197/1000], Loss: 0.4788\n",
      "Epoch [198/1000], Loss: 0.4788\n",
      "Epoch [199/1000], Loss: 0.4785\n",
      "Epoch [200/1000], Loss: 0.4784\n",
      "Epoch [201/1000], Loss: 0.4784\n",
      "Epoch [202/1000], Loss: 0.4783\n",
      "Epoch [203/1000], Loss: 0.4782\n",
      "Epoch [204/1000], Loss: 0.4780\n",
      "Epoch [205/1000], Loss: 0.4781\n",
      "Epoch [206/1000], Loss: 0.4777\n",
      "Epoch [207/1000], Loss: 0.4778\n",
      "Epoch [208/1000], Loss: 0.4776\n",
      "Epoch [209/1000], Loss: 0.4775\n",
      "Epoch [210/1000], Loss: 0.4774\n",
      "Epoch [211/1000], Loss: 0.4773\n",
      "Epoch [212/1000], Loss: 0.4771\n",
      "Epoch [213/1000], Loss: 0.4770\n",
      "Epoch [214/1000], Loss: 0.4768\n",
      "Epoch [215/1000], Loss: 0.4767\n",
      "Epoch [216/1000], Loss: 0.4766\n",
      "Epoch [217/1000], Loss: 0.4765\n",
      "Epoch [218/1000], Loss: 0.4764\n",
      "Epoch [219/1000], Loss: 0.4764\n",
      "Epoch [220/1000], Loss: 0.4762\n",
      "Epoch [221/1000], Loss: 0.4760\n",
      "Epoch [222/1000], Loss: 0.4760\n",
      "Epoch [223/1000], Loss: 0.4759\n",
      "Epoch [224/1000], Loss: 0.4758\n",
      "Epoch [225/1000], Loss: 0.4756\n",
      "Epoch [226/1000], Loss: 0.4754\n",
      "Epoch [227/1000], Loss: 0.4753\n",
      "Epoch [228/1000], Loss: 0.4752\n",
      "Epoch [229/1000], Loss: 0.4750\n",
      "Epoch [230/1000], Loss: 0.4750\n",
      "Epoch [231/1000], Loss: 0.4749\n",
      "Epoch [232/1000], Loss: 0.4746\n",
      "Epoch [233/1000], Loss: 0.4746\n",
      "Epoch [234/1000], Loss: 0.4745\n",
      "Epoch [235/1000], Loss: 0.4743\n",
      "Epoch [236/1000], Loss: 0.4743\n",
      "Epoch [237/1000], Loss: 0.4741\n",
      "Epoch [238/1000], Loss: 0.4741\n",
      "Epoch [239/1000], Loss: 0.4741\n",
      "Epoch [240/1000], Loss: 0.4738\n",
      "Epoch [241/1000], Loss: 0.4737\n",
      "Epoch [242/1000], Loss: 0.4736\n",
      "Epoch [243/1000], Loss: 0.4735\n",
      "Epoch [244/1000], Loss: 0.4734\n",
      "Epoch [245/1000], Loss: 0.4732\n",
      "Epoch [246/1000], Loss: 0.4731\n",
      "Epoch [247/1000], Loss: 0.4730\n",
      "Epoch [248/1000], Loss: 0.4729\n",
      "Epoch [249/1000], Loss: 0.4728\n",
      "Epoch [250/1000], Loss: 0.4727\n",
      "Epoch [251/1000], Loss: 0.4726\n",
      "Epoch [252/1000], Loss: 0.4726\n",
      "Epoch [253/1000], Loss: 0.4725\n",
      "Epoch [254/1000], Loss: 0.4723\n",
      "Epoch [255/1000], Loss: 0.4722\n",
      "Epoch [256/1000], Loss: 0.4721\n",
      "Epoch [257/1000], Loss: 0.4719\n",
      "Epoch [258/1000], Loss: 0.4721\n",
      "Epoch [259/1000], Loss: 0.4719\n",
      "Epoch [260/1000], Loss: 0.4719\n",
      "Epoch [261/1000], Loss: 0.4716\n",
      "Epoch [262/1000], Loss: 0.4717\n",
      "Epoch [263/1000], Loss: 0.4717\n",
      "Epoch [264/1000], Loss: 0.4716\n",
      "Epoch [265/1000], Loss: 0.4716\n",
      "Epoch [266/1000], Loss: 0.4713\n",
      "Epoch [267/1000], Loss: 0.4714\n",
      "Epoch [268/1000], Loss: 0.4713\n",
      "Epoch [269/1000], Loss: 0.4711\n",
      "Epoch [270/1000], Loss: 0.4711\n",
      "Epoch [271/1000], Loss: 0.4711\n",
      "Epoch [272/1000], Loss: 0.4710\n",
      "Epoch [273/1000], Loss: 0.4711\n",
      "Epoch [274/1000], Loss: 0.4710\n",
      "Epoch [275/1000], Loss: 0.4709\n",
      "Epoch [276/1000], Loss: 0.4708\n",
      "Epoch [277/1000], Loss: 0.4707\n",
      "Epoch [278/1000], Loss: 0.4706\n",
      "Epoch [279/1000], Loss: 0.4706\n",
      "Epoch [280/1000], Loss: 0.4705\n",
      "Epoch [281/1000], Loss: 0.4705\n",
      "Epoch [282/1000], Loss: 0.4705\n",
      "Epoch [283/1000], Loss: 0.4705\n",
      "Epoch [284/1000], Loss: 0.4704\n",
      "Epoch [285/1000], Loss: 0.4703\n",
      "Epoch [286/1000], Loss: 0.4704\n",
      "Epoch [287/1000], Loss: 0.4702\n",
      "Epoch [288/1000], Loss: 0.4701\n",
      "Epoch [289/1000], Loss: 0.4701\n",
      "Epoch [290/1000], Loss: 0.4701\n",
      "Epoch [291/1000], Loss: 0.4700\n",
      "Epoch [292/1000], Loss: 0.4700\n",
      "Epoch [293/1000], Loss: 0.4700\n",
      "Epoch [294/1000], Loss: 0.4699\n",
      "Epoch [295/1000], Loss: 0.4698\n",
      "Epoch [296/1000], Loss: 0.4698\n",
      "Epoch [297/1000], Loss: 0.4698\n",
      "Epoch [298/1000], Loss: 0.4697\n",
      "Epoch [299/1000], Loss: 0.4697\n",
      "Epoch [300/1000], Loss: 0.4696\n",
      "Epoch [301/1000], Loss: 0.4696\n",
      "Epoch [302/1000], Loss: 0.4696\n",
      "Epoch [303/1000], Loss: 0.4695\n",
      "Epoch [304/1000], Loss: 0.4695\n",
      "Epoch [305/1000], Loss: 0.4694\n",
      "Epoch [306/1000], Loss: 0.4695\n",
      "Epoch [307/1000], Loss: 0.4694\n",
      "Epoch [308/1000], Loss: 0.4694\n",
      "Epoch [309/1000], Loss: 0.4694\n",
      "Epoch [310/1000], Loss: 0.4693\n",
      "Epoch [311/1000], Loss: 0.4693\n",
      "Epoch [312/1000], Loss: 0.4693\n",
      "Epoch [313/1000], Loss: 0.4693\n",
      "Epoch [314/1000], Loss: 0.4693\n",
      "Epoch [315/1000], Loss: 0.4693\n",
      "Epoch [316/1000], Loss: 0.4693\n",
      "Epoch [317/1000], Loss: 0.4692\n",
      "Epoch [318/1000], Loss: 0.4692\n",
      "Epoch [319/1000], Loss: 0.4691\n",
      "Epoch [320/1000], Loss: 0.4692\n",
      "Epoch [321/1000], Loss: 0.4691\n",
      "Epoch [322/1000], Loss: 0.4691\n",
      "Epoch [323/1000], Loss: 0.4691\n",
      "Epoch [324/1000], Loss: 0.4690\n",
      "Epoch [325/1000], Loss: 0.4690\n",
      "Epoch [326/1000], Loss: 0.4691\n",
      "Epoch [327/1000], Loss: 0.4690\n",
      "Epoch [328/1000], Loss: 0.4690\n",
      "Epoch [329/1000], Loss: 0.4690\n",
      "Epoch [330/1000], Loss: 0.4690\n",
      "Epoch [331/1000], Loss: 0.4690\n",
      "Epoch [332/1000], Loss: 0.4690\n",
      "Epoch [333/1000], Loss: 0.4690\n",
      "Epoch [334/1000], Loss: 0.4689\n",
      "Epoch [335/1000], Loss: 0.4690\n",
      "Epoch [336/1000], Loss: 0.4690\n",
      "Epoch [337/1000], Loss: 0.4689\n",
      "Epoch [338/1000], Loss: 0.4689\n",
      "Epoch [339/1000], Loss: 0.4689\n",
      "Epoch [340/1000], Loss: 0.4689\n",
      "Epoch [341/1000], Loss: 0.4689\n",
      "Epoch [342/1000], Loss: 0.4689\n",
      "Epoch [343/1000], Loss: 0.4689\n",
      "Epoch [344/1000], Loss: 0.4689\n",
      "Epoch [345/1000], Loss: 0.4688\n",
      "Epoch [346/1000], Loss: 0.4688\n",
      "Epoch [347/1000], Loss: 0.4688\n",
      "Epoch [348/1000], Loss: 0.4688\n",
      "Epoch [349/1000], Loss: 0.4688\n",
      "Epoch [350/1000], Loss: 0.4688\n",
      "Epoch [351/1000], Loss: 0.4688\n",
      "Epoch [352/1000], Loss: 0.4688\n",
      "Epoch [353/1000], Loss: 0.4688\n",
      "Epoch [354/1000], Loss: 0.4688\n",
      "Epoch [355/1000], Loss: 0.4687\n",
      "Epoch [356/1000], Loss: 0.4687\n",
      "Epoch [357/1000], Loss: 0.4687\n",
      "Epoch [358/1000], Loss: 0.4687\n",
      "Epoch [359/1000], Loss: 0.4687\n",
      "Epoch [360/1000], Loss: 0.4687\n",
      "Epoch [361/1000], Loss: 0.4687\n",
      "Epoch [362/1000], Loss: 0.4688\n",
      "Epoch [363/1000], Loss: 0.4687\n",
      "Epoch [364/1000], Loss: 0.4687\n",
      "Epoch [365/1000], Loss: 0.4687\n",
      "Epoch [366/1000], Loss: 0.4686\n",
      "Epoch [367/1000], Loss: 0.4686\n",
      "Epoch [368/1000], Loss: 0.4686\n",
      "Epoch [369/1000], Loss: 0.4687\n",
      "Epoch [370/1000], Loss: 0.4687\n",
      "Epoch [371/1000], Loss: 0.4686\n",
      "Epoch [372/1000], Loss: 0.4686\n",
      "Epoch [373/1000], Loss: 0.4686\n",
      "Epoch [374/1000], Loss: 0.4686\n",
      "Epoch [375/1000], Loss: 0.4686\n",
      "Epoch [376/1000], Loss: 0.4686\n",
      "Epoch [377/1000], Loss: 0.4686\n",
      "Epoch [378/1000], Loss: 0.4686\n",
      "Epoch [379/1000], Loss: 0.4686\n",
      "Epoch [380/1000], Loss: 0.4686\n",
      "Epoch [381/1000], Loss: 0.4686\n",
      "Epoch [382/1000], Loss: 0.4686\n",
      "Epoch [383/1000], Loss: 0.4686\n",
      "Epoch [384/1000], Loss: 0.4686\n",
      "Epoch [385/1000], Loss: 0.4686\n",
      "Epoch [386/1000], Loss: 0.4686\n",
      "Epoch [387/1000], Loss: 0.4686\n",
      "Epoch [388/1000], Loss: 0.4685\n",
      "Epoch [389/1000], Loss: 0.4686\n",
      "Epoch [390/1000], Loss: 0.4686\n",
      "Epoch [391/1000], Loss: 0.4686\n",
      "Epoch [392/1000], Loss: 0.4686\n",
      "Epoch [393/1000], Loss: 0.4686\n",
      "Epoch [394/1000], Loss: 0.4685\n",
      "Epoch [395/1000], Loss: 0.4685\n",
      "Epoch [396/1000], Loss: 0.4685\n",
      "Epoch [397/1000], Loss: 0.4685\n",
      "Epoch [398/1000], Loss: 0.4685\n",
      "Epoch [399/1000], Loss: 0.4685\n",
      "Epoch [400/1000], Loss: 0.4685\n",
      "Epoch [401/1000], Loss: 0.4685\n",
      "Epoch [402/1000], Loss: 0.4685\n",
      "Epoch [403/1000], Loss: 0.4685\n",
      "Epoch [404/1000], Loss: 0.4685\n",
      "Epoch [405/1000], Loss: 0.4685\n",
      "Epoch [406/1000], Loss: 0.4685\n",
      "Epoch [407/1000], Loss: 0.4685\n",
      "Epoch [408/1000], Loss: 0.4685\n",
      "Epoch [409/1000], Loss: 0.4685\n",
      "Epoch [410/1000], Loss: 0.4685\n",
      "Epoch [411/1000], Loss: 0.4685\n",
      "Epoch [412/1000], Loss: 0.4685\n",
      "Epoch [413/1000], Loss: 0.4684\n",
      "Epoch [414/1000], Loss: 0.4684\n",
      "Epoch [415/1000], Loss: 0.4684\n",
      "Epoch [416/1000], Loss: 0.4684\n",
      "Epoch [417/1000], Loss: 0.4684\n",
      "Epoch [418/1000], Loss: 0.4684\n",
      "Epoch [419/1000], Loss: 0.4685\n",
      "Epoch [420/1000], Loss: 0.4684\n",
      "Epoch [421/1000], Loss: 0.4684\n",
      "Epoch [422/1000], Loss: 0.4684\n",
      "Epoch [423/1000], Loss: 0.4684\n",
      "Epoch [424/1000], Loss: 0.4684\n",
      "Epoch [425/1000], Loss: 0.4684\n",
      "Epoch [426/1000], Loss: 0.4684\n",
      "Epoch [427/1000], Loss: 0.4684\n",
      "Epoch [428/1000], Loss: 0.4684\n",
      "Epoch [429/1000], Loss: 0.4684\n",
      "Epoch [430/1000], Loss: 0.4684\n",
      "Epoch [431/1000], Loss: 0.4684\n",
      "Epoch [432/1000], Loss: 0.4684\n",
      "Epoch [433/1000], Loss: 0.4684\n",
      "Epoch [434/1000], Loss: 0.4684\n",
      "Epoch [435/1000], Loss: 0.4684\n",
      "Epoch [436/1000], Loss: 0.4684\n",
      "Epoch [437/1000], Loss: 0.4684\n",
      "Epoch [438/1000], Loss: 0.4684\n",
      "Epoch [439/1000], Loss: 0.4684\n",
      "Epoch [440/1000], Loss: 0.4684\n",
      "Epoch [441/1000], Loss: 0.4684\n",
      "Epoch [442/1000], Loss: 0.4684\n",
      "Epoch [443/1000], Loss: 0.4684\n",
      "Epoch [444/1000], Loss: 0.4684\n",
      "Epoch [445/1000], Loss: 0.4684\n",
      "Epoch [446/1000], Loss: 0.4684\n",
      "Epoch [447/1000], Loss: 0.4684\n",
      "Epoch [448/1000], Loss: 0.4684\n",
      "Epoch [449/1000], Loss: 0.4684\n",
      "Epoch [450/1000], Loss: 0.4684\n",
      "Epoch [451/1000], Loss: 0.4684\n",
      "Epoch [452/1000], Loss: 0.4684\n",
      "Epoch [453/1000], Loss: 0.4684\n",
      "Epoch [454/1000], Loss: 0.4684\n",
      "Epoch [455/1000], Loss: 0.4684\n",
      "Epoch [456/1000], Loss: 0.4684\n",
      "Epoch [457/1000], Loss: 0.4684\n",
      "Epoch [458/1000], Loss: 0.4684\n",
      "Epoch [459/1000], Loss: 0.4684\n",
      "Epoch [460/1000], Loss: 0.4684\n",
      "Epoch [461/1000], Loss: 0.4684\n",
      "Epoch [462/1000], Loss: 0.4684\n",
      "Epoch [463/1000], Loss: 0.4684\n",
      "Epoch [464/1000], Loss: 0.4684\n",
      "Epoch [465/1000], Loss: 0.4684\n",
      "Epoch [466/1000], Loss: 0.4684\n",
      "Epoch [467/1000], Loss: 0.4684\n",
      "Epoch [468/1000], Loss: 0.4684\n",
      "Epoch [469/1000], Loss: 0.4684\n",
      "Epoch [470/1000], Loss: 0.4684\n",
      "Epoch [471/1000], Loss: 0.4684\n",
      "Epoch [472/1000], Loss: 0.4684\n",
      "Epoch [473/1000], Loss: 0.4683\n",
      "Epoch [474/1000], Loss: 0.4684\n",
      "Epoch [475/1000], Loss: 0.4684\n",
      "Epoch [476/1000], Loss: 0.4684\n",
      "Epoch [477/1000], Loss: 0.4684\n",
      "Epoch [478/1000], Loss: 0.4684\n",
      "Epoch [479/1000], Loss: 0.4684\n",
      "Epoch [480/1000], Loss: 0.4683\n",
      "Epoch [481/1000], Loss: 0.4683\n",
      "Epoch [482/1000], Loss: 0.4684\n",
      "Epoch [483/1000], Loss: 0.4683\n",
      "Epoch [484/1000], Loss: 0.4684\n",
      "Epoch [485/1000], Loss: 0.4684\n",
      "Epoch [486/1000], Loss: 0.4683\n",
      "Epoch [487/1000], Loss: 0.4684\n",
      "Epoch [488/1000], Loss: 0.4684\n",
      "Epoch [489/1000], Loss: 0.4683\n",
      "Epoch [490/1000], Loss: 0.4683\n",
      "Epoch [491/1000], Loss: 0.4684\n",
      "Epoch [492/1000], Loss: 0.4684\n",
      "Epoch [493/1000], Loss: 0.4683\n",
      "Epoch [494/1000], Loss: 0.4683\n",
      "Epoch [495/1000], Loss: 0.4683\n",
      "Epoch [496/1000], Loss: 0.4683\n",
      "Epoch [497/1000], Loss: 0.4683\n",
      "Epoch [498/1000], Loss: 0.4683\n",
      "Epoch [499/1000], Loss: 0.4683\n",
      "Epoch [500/1000], Loss: 0.4683\n",
      "Epoch [501/1000], Loss: 0.4683\n",
      "Epoch [502/1000], Loss: 0.4682\n",
      "Epoch [503/1000], Loss: 0.4682\n",
      "Epoch [504/1000], Loss: 0.4681\n",
      "Epoch [505/1000], Loss: 0.4681\n",
      "Epoch [506/1000], Loss: 0.4680\n",
      "Epoch [507/1000], Loss: 0.4679\n",
      "Epoch [508/1000], Loss: 0.4678\n",
      "Epoch [509/1000], Loss: 0.4677\n",
      "Epoch [510/1000], Loss: 0.4677\n",
      "Epoch [511/1000], Loss: 0.4676\n",
      "Epoch [512/1000], Loss: 0.4674\n",
      "Epoch [513/1000], Loss: 0.4674\n",
      "Epoch [514/1000], Loss: 0.4672\n",
      "Epoch [515/1000], Loss: 0.4671\n",
      "Epoch [516/1000], Loss: 0.4669\n",
      "Epoch [517/1000], Loss: 0.4668\n",
      "Epoch [518/1000], Loss: 0.4666\n",
      "Epoch [519/1000], Loss: 0.4664\n",
      "Epoch [520/1000], Loss: 0.4663\n",
      "Epoch [521/1000], Loss: 0.4661\n",
      "Epoch [522/1000], Loss: 0.4660\n",
      "Epoch [523/1000], Loss: 0.4657\n",
      "Epoch [524/1000], Loss: 0.4657\n",
      "Epoch [525/1000], Loss: 0.4654\n",
      "Epoch [526/1000], Loss: 0.4652\n",
      "Epoch [527/1000], Loss: 0.4650\n",
      "Epoch [528/1000], Loss: 0.4649\n",
      "Epoch [529/1000], Loss: 0.4646\n",
      "Epoch [530/1000], Loss: 0.4645\n",
      "Epoch [531/1000], Loss: 0.4643\n",
      "Epoch [532/1000], Loss: 0.4641\n",
      "Epoch [533/1000], Loss: 0.4638\n",
      "Epoch [534/1000], Loss: 0.4637\n",
      "Epoch [535/1000], Loss: 0.4635\n",
      "Epoch [536/1000], Loss: 0.4633\n",
      "Epoch [537/1000], Loss: 0.4632\n",
      "Epoch [538/1000], Loss: 0.4630\n",
      "Epoch [539/1000], Loss: 0.4626\n",
      "Epoch [540/1000], Loss: 0.4623\n",
      "Epoch [541/1000], Loss: 0.4622\n",
      "Epoch [542/1000], Loss: 0.4620\n",
      "Epoch [543/1000], Loss: 0.4618\n",
      "Epoch [544/1000], Loss: 0.4615\n",
      "Epoch [545/1000], Loss: 0.4613\n",
      "Epoch [546/1000], Loss: 0.4610\n",
      "Epoch [547/1000], Loss: 0.4610\n",
      "Epoch [548/1000], Loss: 0.4607\n",
      "Epoch [549/1000], Loss: 0.4607\n",
      "Epoch [550/1000], Loss: 0.4605\n",
      "Epoch [551/1000], Loss: 0.4601\n",
      "Epoch [552/1000], Loss: 0.4600\n",
      "Epoch [553/1000], Loss: 0.4599\n",
      "Epoch [554/1000], Loss: 0.4597\n",
      "Epoch [555/1000], Loss: 0.4593\n",
      "Epoch [556/1000], Loss: 0.4594\n",
      "Epoch [557/1000], Loss: 0.4593\n",
      "Epoch [558/1000], Loss: 0.4588\n",
      "Epoch [559/1000], Loss: 0.4588\n",
      "Epoch [560/1000], Loss: 0.4588\n",
      "Epoch [561/1000], Loss: 0.4587\n",
      "Epoch [562/1000], Loss: 0.4583\n",
      "Epoch [563/1000], Loss: 0.4585\n",
      "Epoch [564/1000], Loss: 0.4582\n",
      "Epoch [565/1000], Loss: 0.4581\n",
      "Epoch [566/1000], Loss: 0.4580\n",
      "Epoch [567/1000], Loss: 0.4578\n",
      "Epoch [568/1000], Loss: 0.4578\n",
      "Epoch [569/1000], Loss: 0.4576\n",
      "Epoch [570/1000], Loss: 0.4575\n",
      "Epoch [571/1000], Loss: 0.4577\n",
      "Epoch [572/1000], Loss: 0.4574\n",
      "Epoch [573/1000], Loss: 0.4574\n",
      "Epoch [574/1000], Loss: 0.4575\n",
      "Epoch [575/1000], Loss: 0.4574\n",
      "Epoch [576/1000], Loss: 0.4574\n",
      "Epoch [577/1000], Loss: 0.4574\n",
      "Epoch [578/1000], Loss: 0.4572\n",
      "Epoch [579/1000], Loss: 0.4571\n",
      "Epoch [580/1000], Loss: 0.4571\n",
      "Epoch [581/1000], Loss: 0.4571\n",
      "Epoch [582/1000], Loss: 0.4568\n",
      "Epoch [583/1000], Loss: 0.4568\n",
      "Epoch [584/1000], Loss: 0.4568\n",
      "Epoch [585/1000], Loss: 0.4569\n",
      "Epoch [586/1000], Loss: 0.4568\n",
      "Epoch [587/1000], Loss: 0.4569\n",
      "Epoch [588/1000], Loss: 0.4568\n",
      "Epoch [589/1000], Loss: 0.4568\n",
      "Epoch [590/1000], Loss: 0.4567\n",
      "Epoch [591/1000], Loss: 0.4567\n",
      "Epoch [592/1000], Loss: 0.4566\n",
      "Epoch [593/1000], Loss: 0.4567\n",
      "Epoch [594/1000], Loss: 0.4567\n",
      "Epoch [595/1000], Loss: 0.4568\n",
      "Epoch [596/1000], Loss: 0.4565\n",
      "Epoch [597/1000], Loss: 0.4567\n",
      "Epoch [598/1000], Loss: 0.4567\n",
      "Epoch [599/1000], Loss: 0.4566\n",
      "Epoch [600/1000], Loss: 0.4565\n",
      "Epoch [601/1000], Loss: 0.4565\n",
      "Epoch [602/1000], Loss: 0.4564\n",
      "Epoch [603/1000], Loss: 0.4566\n",
      "Epoch [604/1000], Loss: 0.4565\n",
      "Epoch [605/1000], Loss: 0.4565\n",
      "Epoch [606/1000], Loss: 0.4564\n",
      "Epoch [607/1000], Loss: 0.4565\n",
      "Epoch [608/1000], Loss: 0.4566\n",
      "Epoch [609/1000], Loss: 0.4564\n",
      "Epoch [610/1000], Loss: 0.4565\n",
      "Epoch [611/1000], Loss: 0.4565\n",
      "Epoch [612/1000], Loss: 0.4565\n",
      "Epoch [613/1000], Loss: 0.4565\n",
      "Epoch [614/1000], Loss: 0.4564\n",
      "Epoch [615/1000], Loss: 0.4564\n",
      "Epoch [616/1000], Loss: 0.4564\n",
      "Epoch [617/1000], Loss: 0.4563\n",
      "Epoch [618/1000], Loss: 0.4563\n",
      "Epoch [619/1000], Loss: 0.4564\n",
      "Epoch [620/1000], Loss: 0.4564\n",
      "Epoch [621/1000], Loss: 0.4563\n",
      "Epoch [622/1000], Loss: 0.4563\n",
      "Epoch [623/1000], Loss: 0.4562\n",
      "Epoch [624/1000], Loss: 0.4563\n",
      "Epoch [625/1000], Loss: 0.4563\n",
      "Epoch [626/1000], Loss: 0.4563\n",
      "Epoch [627/1000], Loss: 0.4563\n",
      "Epoch [628/1000], Loss: 0.4563\n",
      "Epoch [629/1000], Loss: 0.4563\n",
      "Epoch [630/1000], Loss: 0.4562\n",
      "Epoch [631/1000], Loss: 0.4562\n",
      "Epoch [632/1000], Loss: 0.4561\n",
      "Epoch [633/1000], Loss: 0.4561\n",
      "Epoch [634/1000], Loss: 0.4563\n",
      "Epoch [635/1000], Loss: 0.4561\n",
      "Epoch [636/1000], Loss: 0.4562\n",
      "Epoch [637/1000], Loss: 0.4562\n",
      "Epoch [638/1000], Loss: 0.4561\n",
      "Epoch [639/1000], Loss: 0.4562\n",
      "Epoch [640/1000], Loss: 0.4563\n",
      "Epoch [641/1000], Loss: 0.4561\n",
      "Epoch [642/1000], Loss: 0.4563\n",
      "Epoch [643/1000], Loss: 0.4561\n",
      "Epoch [644/1000], Loss: 0.4561\n",
      "Epoch [645/1000], Loss: 0.4561\n",
      "Epoch [646/1000], Loss: 0.4561\n",
      "Epoch [647/1000], Loss: 0.4562\n",
      "Epoch [648/1000], Loss: 0.4561\n",
      "Epoch [649/1000], Loss: 0.4561\n",
      "Epoch [650/1000], Loss: 0.4562\n",
      "Epoch [651/1000], Loss: 0.4561\n",
      "Epoch [652/1000], Loss: 0.4562\n",
      "Epoch [653/1000], Loss: 0.4561\n",
      "Epoch [654/1000], Loss: 0.4562\n",
      "Epoch [655/1000], Loss: 0.4561\n",
      "Epoch [656/1000], Loss: 0.4561\n",
      "Epoch [657/1000], Loss: 0.4560\n",
      "Epoch [658/1000], Loss: 0.4561\n",
      "Epoch [659/1000], Loss: 0.4562\n",
      "Epoch [660/1000], Loss: 0.4560\n",
      "Epoch [661/1000], Loss: 0.4561\n",
      "Epoch [662/1000], Loss: 0.4561\n",
      "Epoch [663/1000], Loss: 0.4560\n",
      "Epoch [664/1000], Loss: 0.4560\n",
      "Epoch [665/1000], Loss: 0.4562\n",
      "Epoch [666/1000], Loss: 0.4561\n",
      "Epoch [667/1000], Loss: 0.4561\n",
      "Epoch [668/1000], Loss: 0.4561\n",
      "Epoch [669/1000], Loss: 0.4561\n",
      "Epoch [670/1000], Loss: 0.4560\n",
      "Epoch [671/1000], Loss: 0.4560\n",
      "Epoch [672/1000], Loss: 0.4561\n",
      "Epoch [673/1000], Loss: 0.4560\n",
      "Epoch [674/1000], Loss: 0.4562\n",
      "Epoch [675/1000], Loss: 0.4560\n",
      "Epoch [676/1000], Loss: 0.4560\n",
      "Epoch [677/1000], Loss: 0.4561\n",
      "Epoch [678/1000], Loss: 0.4560\n",
      "Epoch [679/1000], Loss: 0.4560\n",
      "Epoch [680/1000], Loss: 0.4561\n",
      "Epoch [681/1000], Loss: 0.4560\n",
      "Epoch [682/1000], Loss: 0.4560\n",
      "Epoch [683/1000], Loss: 0.4561\n",
      "Epoch [684/1000], Loss: 0.4559\n",
      "Epoch [685/1000], Loss: 0.4560\n",
      "Epoch [686/1000], Loss: 0.4560\n",
      "Epoch [687/1000], Loss: 0.4561\n",
      "Epoch [688/1000], Loss: 0.4562\n",
      "Epoch [689/1000], Loss: 0.4560\n",
      "Epoch [690/1000], Loss: 0.4560\n",
      "Epoch [691/1000], Loss: 0.4560\n",
      "Epoch [692/1000], Loss: 0.4560\n",
      "Epoch [693/1000], Loss: 0.4560\n",
      "Epoch [694/1000], Loss: 0.4560\n",
      "Epoch [695/1000], Loss: 0.4560\n",
      "Epoch [696/1000], Loss: 0.4561\n",
      "Epoch [697/1000], Loss: 0.4560\n",
      "Epoch [698/1000], Loss: 0.4559\n",
      "Epoch [699/1000], Loss: 0.4560\n",
      "Epoch [700/1000], Loss: 0.4560\n",
      "Epoch [701/1000], Loss: 0.4561\n",
      "Epoch [702/1000], Loss: 0.4560\n",
      "Epoch [703/1000], Loss: 0.4562\n",
      "Epoch [704/1000], Loss: 0.4560\n",
      "Epoch [705/1000], Loss: 0.4560\n",
      "Epoch [706/1000], Loss: 0.4560\n",
      "Epoch [707/1000], Loss: 0.4560\n",
      "Epoch [708/1000], Loss: 0.4560\n",
      "Epoch [709/1000], Loss: 0.4561\n",
      "Epoch [710/1000], Loss: 0.4561\n",
      "Epoch [711/1000], Loss: 0.4559\n",
      "Epoch [712/1000], Loss: 0.4560\n",
      "Epoch [713/1000], Loss: 0.4560\n",
      "Epoch [714/1000], Loss: 0.4560\n",
      "Epoch [715/1000], Loss: 0.4560\n",
      "Epoch [716/1000], Loss: 0.4560\n",
      "Epoch [717/1000], Loss: 0.4560\n",
      "Epoch [718/1000], Loss: 0.4560\n",
      "Epoch [719/1000], Loss: 0.4559\n",
      "Epoch [720/1000], Loss: 0.4560\n",
      "Epoch [721/1000], Loss: 0.4559\n",
      "Epoch [722/1000], Loss: 0.4559\n",
      "Epoch [723/1000], Loss: 0.4560\n",
      "Epoch [724/1000], Loss: 0.4561\n",
      "Epoch [725/1000], Loss: 0.4560\n",
      "Epoch [726/1000], Loss: 0.4559\n",
      "Epoch [727/1000], Loss: 0.4560\n",
      "Epoch [728/1000], Loss: 0.4560\n",
      "Epoch [729/1000], Loss: 0.4559\n",
      "Epoch [730/1000], Loss: 0.4559\n",
      "Epoch [731/1000], Loss: 0.4560\n",
      "Epoch [732/1000], Loss: 0.4559\n",
      "Epoch [733/1000], Loss: 0.4560\n",
      "Epoch [734/1000], Loss: 0.4560\n",
      "Epoch [735/1000], Loss: 0.4559\n",
      "Epoch [736/1000], Loss: 0.4559\n",
      "Epoch [737/1000], Loss: 0.4559\n",
      "Epoch [738/1000], Loss: 0.4559\n",
      "Epoch [739/1000], Loss: 0.4559\n",
      "Epoch [740/1000], Loss: 0.4559\n",
      "Epoch [741/1000], Loss: 0.4560\n",
      "Epoch [742/1000], Loss: 0.4559\n",
      "Epoch [743/1000], Loss: 0.4559\n",
      "Epoch [744/1000], Loss: 0.4559\n",
      "Epoch [745/1000], Loss: 0.4559\n",
      "Epoch [746/1000], Loss: 0.4559\n",
      "Epoch [747/1000], Loss: 0.4560\n",
      "Epoch [748/1000], Loss: 0.4559\n",
      "Epoch [749/1000], Loss: 0.4561\n",
      "Epoch [750/1000], Loss: 0.4559\n",
      "Epoch [751/1000], Loss: 0.4560\n",
      "Epoch [752/1000], Loss: 0.4559\n",
      "Epoch [753/1000], Loss: 0.4560\n",
      "Epoch [754/1000], Loss: 0.4559\n",
      "Epoch [755/1000], Loss: 0.4560\n",
      "Epoch [756/1000], Loss: 0.4559\n",
      "Epoch [757/1000], Loss: 0.4560\n",
      "Epoch [758/1000], Loss: 0.4560\n",
      "Epoch [759/1000], Loss: 0.4559\n",
      "Epoch [760/1000], Loss: 0.4560\n",
      "Epoch [761/1000], Loss: 0.4559\n",
      "Epoch [762/1000], Loss: 0.4560\n",
      "Epoch [763/1000], Loss: 0.4559\n",
      "Epoch [764/1000], Loss: 0.4560\n",
      "Epoch [765/1000], Loss: 0.4559\n",
      "Epoch [766/1000], Loss: 0.4559\n",
      "Epoch [767/1000], Loss: 0.4560\n",
      "Epoch [768/1000], Loss: 0.4559\n",
      "Epoch [769/1000], Loss: 0.4559\n",
      "Epoch [770/1000], Loss: 0.4559\n",
      "Epoch [771/1000], Loss: 0.4559\n",
      "Epoch [772/1000], Loss: 0.4559\n",
      "Epoch [773/1000], Loss: 0.4559\n",
      "Epoch [774/1000], Loss: 0.4559\n",
      "Epoch [775/1000], Loss: 0.4559\n",
      "Epoch [776/1000], Loss: 0.4559\n",
      "Epoch [777/1000], Loss: 0.4559\n",
      "Epoch [778/1000], Loss: 0.4559\n",
      "Epoch [779/1000], Loss: 0.4559\n",
      "Epoch [780/1000], Loss: 0.4559\n",
      "Epoch [781/1000], Loss: 0.4559\n",
      "Epoch [782/1000], Loss: 0.4559\n",
      "Epoch [783/1000], Loss: 0.4559\n",
      "Epoch [784/1000], Loss: 0.4559\n",
      "Epoch [785/1000], Loss: 0.4559\n",
      "Epoch [786/1000], Loss: 0.4559\n",
      "Epoch [787/1000], Loss: 0.4561\n",
      "Epoch [788/1000], Loss: 0.4559\n",
      "Epoch [789/1000], Loss: 0.4559\n",
      "Epoch [790/1000], Loss: 0.4559\n",
      "Epoch [791/1000], Loss: 0.4559\n",
      "Epoch [792/1000], Loss: 0.4560\n",
      "Epoch [793/1000], Loss: 0.4559\n",
      "Epoch [794/1000], Loss: 0.4559\n",
      "Epoch [795/1000], Loss: 0.4559\n",
      "Epoch [796/1000], Loss: 0.4559\n",
      "Epoch [797/1000], Loss: 0.4558\n",
      "Epoch [798/1000], Loss: 0.4559\n",
      "Epoch [799/1000], Loss: 0.4559\n",
      "Epoch [800/1000], Loss: 0.4559\n",
      "Epoch [801/1000], Loss: 0.4559\n",
      "Epoch [802/1000], Loss: 0.4559\n",
      "Epoch [803/1000], Loss: 0.4559\n",
      "Epoch [804/1000], Loss: 0.4559\n",
      "Epoch [805/1000], Loss: 0.4559\n",
      "Epoch [806/1000], Loss: 0.4559\n",
      "Epoch [807/1000], Loss: 0.4559\n",
      "Epoch [808/1000], Loss: 0.4559\n",
      "Epoch [809/1000], Loss: 0.4559\n",
      "Epoch [810/1000], Loss: 0.4559\n",
      "Epoch [811/1000], Loss: 0.4560\n",
      "Epoch [812/1000], Loss: 0.4559\n",
      "Epoch [813/1000], Loss: 0.4560\n",
      "Epoch [814/1000], Loss: 0.4559\n",
      "Epoch [815/1000], Loss: 0.4559\n",
      "Epoch [816/1000], Loss: 0.4559\n",
      "Epoch [817/1000], Loss: 0.4559\n",
      "Epoch [818/1000], Loss: 0.4559\n",
      "Epoch [819/1000], Loss: 0.4560\n",
      "Epoch [820/1000], Loss: 0.4559\n",
      "Epoch [821/1000], Loss: 0.4560\n",
      "Epoch [822/1000], Loss: 0.4559\n",
      "Epoch [823/1000], Loss: 0.4559\n",
      "Epoch [824/1000], Loss: 0.4559\n",
      "Epoch [825/1000], Loss: 0.4559\n",
      "Epoch [826/1000], Loss: 0.4559\n",
      "Epoch [827/1000], Loss: 0.4559\n",
      "Epoch [828/1000], Loss: 0.4559\n",
      "Epoch [829/1000], Loss: 0.4559\n",
      "Epoch [830/1000], Loss: 0.4559\n",
      "Epoch [831/1000], Loss: 0.4559\n",
      "Epoch [832/1000], Loss: 0.4559\n",
      "Epoch [833/1000], Loss: 0.4560\n",
      "Epoch [834/1000], Loss: 0.4559\n",
      "Epoch [835/1000], Loss: 0.4559\n",
      "Epoch [836/1000], Loss: 0.4559\n",
      "Epoch [837/1000], Loss: 0.4559\n",
      "Epoch [838/1000], Loss: 0.4559\n",
      "Epoch [839/1000], Loss: 0.4559\n",
      "Epoch [840/1000], Loss: 0.4559\n",
      "Epoch [841/1000], Loss: 0.4560\n",
      "Epoch [842/1000], Loss: 0.4559\n",
      "Epoch [843/1000], Loss: 0.4559\n",
      "Epoch [844/1000], Loss: 0.4559\n",
      "Epoch [845/1000], Loss: 0.4559\n",
      "Epoch [846/1000], Loss: 0.4559\n",
      "Epoch [847/1000], Loss: 0.4559\n",
      "Epoch [848/1000], Loss: 0.4560\n",
      "Epoch [849/1000], Loss: 0.4559\n",
      "Epoch [850/1000], Loss: 0.4559\n",
      "Epoch [851/1000], Loss: 0.4559\n",
      "Epoch [852/1000], Loss: 0.4559\n",
      "Epoch [853/1000], Loss: 0.4559\n",
      "Epoch [854/1000], Loss: 0.4559\n",
      "Epoch [855/1000], Loss: 0.4559\n",
      "Epoch [856/1000], Loss: 0.4559\n",
      "Epoch [857/1000], Loss: 0.4559\n",
      "Epoch [858/1000], Loss: 0.4559\n",
      "Epoch [859/1000], Loss: 0.4559\n",
      "Epoch [860/1000], Loss: 0.4559\n",
      "Epoch [861/1000], Loss: 0.4559\n",
      "Epoch [862/1000], Loss: 0.4558\n",
      "Epoch [863/1000], Loss: 0.4559\n",
      "Epoch [864/1000], Loss: 0.4559\n",
      "Epoch [865/1000], Loss: 0.4559\n",
      "Epoch [866/1000], Loss: 0.4559\n",
      "Epoch [867/1000], Loss: 0.4558\n",
      "Epoch [868/1000], Loss: 0.4559\n",
      "Epoch [869/1000], Loss: 0.4559\n",
      "Epoch [870/1000], Loss: 0.4558\n",
      "Epoch [871/1000], Loss: 0.4559\n",
      "Epoch [872/1000], Loss: 0.4558\n",
      "Epoch [873/1000], Loss: 0.4559\n",
      "Epoch [874/1000], Loss: 0.4558\n",
      "Epoch [875/1000], Loss: 0.4559\n",
      "Epoch [876/1000], Loss: 0.4559\n",
      "Epoch [877/1000], Loss: 0.4559\n",
      "Epoch [878/1000], Loss: 0.4559\n",
      "Epoch [879/1000], Loss: 0.4559\n",
      "Epoch [880/1000], Loss: 0.4558\n",
      "Epoch [881/1000], Loss: 0.4558\n",
      "Epoch [882/1000], Loss: 0.4559\n",
      "Epoch [883/1000], Loss: 0.4559\n",
      "Epoch [884/1000], Loss: 0.4559\n",
      "Epoch [885/1000], Loss: 0.4559\n",
      "Epoch [886/1000], Loss: 0.4559\n",
      "Epoch [887/1000], Loss: 0.4559\n",
      "Epoch [888/1000], Loss: 0.4559\n",
      "Epoch [889/1000], Loss: 0.4558\n",
      "Epoch [890/1000], Loss: 0.4560\n",
      "Epoch [891/1000], Loss: 0.4560\n",
      "Epoch [892/1000], Loss: 0.4559\n",
      "Epoch [893/1000], Loss: 0.4560\n",
      "Epoch [894/1000], Loss: 0.4559\n",
      "Epoch [895/1000], Loss: 0.4559\n",
      "Epoch [896/1000], Loss: 0.4558\n",
      "Epoch [897/1000], Loss: 0.4559\n",
      "Epoch [898/1000], Loss: 0.4559\n",
      "Epoch [899/1000], Loss: 0.4559\n",
      "Epoch [900/1000], Loss: 0.4559\n",
      "Epoch [901/1000], Loss: 0.4559\n",
      "Epoch [902/1000], Loss: 0.4559\n",
      "Epoch [903/1000], Loss: 0.4558\n",
      "Epoch [904/1000], Loss: 0.4559\n",
      "Epoch [905/1000], Loss: 0.4558\n",
      "Epoch [906/1000], Loss: 0.4559\n",
      "Epoch [907/1000], Loss: 0.4559\n",
      "Epoch [908/1000], Loss: 0.4559\n",
      "Epoch [909/1000], Loss: 0.4560\n",
      "Epoch [910/1000], Loss: 0.4559\n",
      "Epoch [911/1000], Loss: 0.4560\n",
      "Epoch [912/1000], Loss: 0.4559\n",
      "Epoch [913/1000], Loss: 0.4561\n",
      "Epoch [914/1000], Loss: 0.4558\n",
      "Epoch [915/1000], Loss: 0.4559\n",
      "Epoch [916/1000], Loss: 0.4558\n",
      "Epoch [917/1000], Loss: 0.4559\n",
      "Epoch [918/1000], Loss: 0.4559\n",
      "Epoch [919/1000], Loss: 0.4559\n",
      "Epoch [920/1000], Loss: 0.4559\n",
      "Epoch [921/1000], Loss: 0.4559\n",
      "Epoch [922/1000], Loss: 0.4559\n",
      "Epoch [923/1000], Loss: 0.4558\n",
      "Epoch [924/1000], Loss: 0.4558\n",
      "Epoch [925/1000], Loss: 0.4559\n",
      "Epoch [926/1000], Loss: 0.4559\n",
      "Epoch [927/1000], Loss: 0.4559\n",
      "Epoch [928/1000], Loss: 0.4558\n",
      "Epoch [929/1000], Loss: 0.4558\n",
      "Epoch [930/1000], Loss: 0.4559\n",
      "Epoch [931/1000], Loss: 0.4558\n",
      "Epoch [932/1000], Loss: 0.4558\n",
      "Epoch [933/1000], Loss: 0.4558\n",
      "Epoch [934/1000], Loss: 0.4559\n",
      "Epoch [935/1000], Loss: 0.4558\n",
      "Epoch [936/1000], Loss: 0.4558\n",
      "Epoch [937/1000], Loss: 0.4558\n",
      "Epoch [938/1000], Loss: 0.4559\n",
      "Epoch [939/1000], Loss: 0.4559\n",
      "Epoch [940/1000], Loss: 0.4558\n",
      "Epoch [941/1000], Loss: 0.4558\n",
      "Epoch [942/1000], Loss: 0.4558\n",
      "Epoch [943/1000], Loss: 0.4559\n",
      "Epoch [944/1000], Loss: 0.4558\n",
      "Epoch [945/1000], Loss: 0.4558\n",
      "Epoch [946/1000], Loss: 0.4558\n",
      "Epoch [947/1000], Loss: 0.4558\n",
      "Epoch [948/1000], Loss: 0.4558\n",
      "Epoch [949/1000], Loss: 0.4558\n",
      "Epoch [950/1000], Loss: 0.4558\n",
      "Epoch [951/1000], Loss: 0.4558\n",
      "Epoch [952/1000], Loss: 0.4558\n",
      "Epoch [953/1000], Loss: 0.4559\n",
      "Epoch [954/1000], Loss: 0.4559\n",
      "Epoch [955/1000], Loss: 0.4559\n",
      "Epoch [956/1000], Loss: 0.4559\n",
      "Epoch [957/1000], Loss: 0.4558\n",
      "Epoch [958/1000], Loss: 0.4558\n",
      "Epoch [959/1000], Loss: 0.4559\n",
      "Epoch [960/1000], Loss: 0.4558\n",
      "Epoch [961/1000], Loss: 0.4558\n",
      "Epoch [962/1000], Loss: 0.4558\n",
      "Epoch [963/1000], Loss: 0.4558\n",
      "Epoch [964/1000], Loss: 0.4558\n",
      "Epoch [965/1000], Loss: 0.4558\n",
      "Epoch [966/1000], Loss: 0.4559\n",
      "Epoch [967/1000], Loss: 0.4558\n",
      "Epoch [968/1000], Loss: 0.4558\n",
      "Epoch [969/1000], Loss: 0.4558\n",
      "Epoch [970/1000], Loss: 0.4558\n",
      "Epoch [971/1000], Loss: 0.4558\n",
      "Epoch [972/1000], Loss: 0.4558\n",
      "Epoch [973/1000], Loss: 0.4558\n",
      "Epoch [974/1000], Loss: 0.4559\n",
      "Epoch [975/1000], Loss: 0.4558\n",
      "Epoch [976/1000], Loss: 0.4558\n",
      "Epoch [977/1000], Loss: 0.4559\n",
      "Epoch [978/1000], Loss: 0.4558\n",
      "Epoch [979/1000], Loss: 0.4558\n",
      "Epoch [980/1000], Loss: 0.4559\n",
      "Epoch [981/1000], Loss: 0.4558\n",
      "Epoch [982/1000], Loss: 0.4558\n",
      "Epoch [983/1000], Loss: 0.4558\n",
      "Epoch [984/1000], Loss: 0.4558\n",
      "Epoch [985/1000], Loss: 0.4558\n",
      "Epoch [986/1000], Loss: 0.4558\n",
      "Epoch [987/1000], Loss: 0.4558\n",
      "Epoch [988/1000], Loss: 0.4558\n",
      "Epoch [989/1000], Loss: 0.4558\n",
      "Epoch [990/1000], Loss: 0.4558\n",
      "Epoch [991/1000], Loss: 0.4558\n",
      "Epoch [992/1000], Loss: 0.4558\n",
      "Epoch [993/1000], Loss: 0.4558\n",
      "Epoch [994/1000], Loss: 0.4558\n",
      "Epoch [995/1000], Loss: 0.4558\n",
      "Epoch [996/1000], Loss: 0.4558\n",
      "Epoch [997/1000], Loss: 0.4558\n",
      "Epoch [998/1000], Loss: 0.4559\n",
      "Epoch [999/1000], Loss: 0.4558\n",
      "Epoch [1000/1000], Loss: 0.4559\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes, dropout_rate=0.0):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool1d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool1d(self.conv2(x), 2))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output for fully connected layers\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the CNN-based classification model\n",
    "input_channels = 59  # Number of input channels/features\n",
    "num_classes = 2  # Number of output classes\n",
    "dropout_rate = 0.4  # Example dropout rate\n",
    "cnn_classification_model = CNNClassifier(input_channels, num_classes, dropout_rate)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn_classification_model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the CNN-based classification model\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = cnn_classification_model.forward(X_train.transpose(1, 2))  # Transpose input for CNN\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2eb0d66b-56e3-4016-beec-91fa7f48241c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89      3321\n",
      "           1       0.47      0.07      0.12       762\n",
      "\n",
      "    accuracy                           0.81      4083\n",
      "   macro avg       0.64      0.53      0.51      4083\n",
      "weighted avg       0.76      0.81      0.75      4083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the classification model\n",
    "cnn_classification_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = cnn_classification_model(X_test.transpose(1, 2))\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Convert predicted tensor to numpy array\n",
    "predicted = predicted.numpy()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test.numpy(), predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00f14512-a9b8-48f7-997f-09dffd59f2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.98      0.90      1684\n",
      "           1       0.46      0.07      0.13       358\n",
      "\n",
      "    accuracy                           0.82      2042\n",
      "   macro avg       0.65      0.53      0.51      2042\n",
      "weighted avg       0.77      0.82      0.77      2042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the classification model\n",
    "cnn_classification_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = cnn_classification_model(X_holdout.transpose(1, 2))\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Convert predicted tensor to numpy array\n",
    "predicted = predicted.numpy()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_holdout.numpy(), predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c9056a-fa4b-4eee-a2e9-f20e7007dd46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6035b-4aac-4869-9276-b265d1ac85c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f1b8a0e-53d6-4efb-ad67-30810f9d4064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 1.2754\n",
      "Epoch [2/50], Loss: 1.2713\n",
      "Epoch [3/50], Loss: 1.2676\n",
      "Epoch [4/50], Loss: 1.2642\n",
      "Epoch [5/50], Loss: 1.2611\n",
      "Epoch [6/50], Loss: 1.2582\n",
      "Epoch [7/50], Loss: 1.2556\n",
      "Epoch [8/50], Loss: 1.2532\n",
      "Epoch [9/50], Loss: 1.2510\n",
      "Epoch [10/50], Loss: 1.2489\n",
      "Epoch [11/50], Loss: 1.2470\n",
      "Epoch [12/50], Loss: 1.2452\n",
      "Epoch [13/50], Loss: 1.2433\n",
      "Epoch [14/50], Loss: 1.2415\n",
      "Epoch [15/50], Loss: 1.2396\n",
      "Epoch [16/50], Loss: 1.2375\n",
      "Epoch [17/50], Loss: 1.2354\n",
      "Epoch [18/50], Loss: 1.2332\n",
      "Epoch [19/50], Loss: 1.2309\n",
      "Epoch [20/50], Loss: 1.2284\n",
      "Epoch [21/50], Loss: 1.2259\n",
      "Epoch [22/50], Loss: 1.2234\n",
      "Epoch [23/50], Loss: 1.2207\n",
      "Epoch [24/50], Loss: 1.2180\n",
      "Epoch [25/50], Loss: 1.2152\n",
      "Epoch [26/50], Loss: 1.2123\n",
      "Epoch [27/50], Loss: 1.2093\n",
      "Epoch [28/50], Loss: 1.2063\n",
      "Epoch [29/50], Loss: 1.2031\n",
      "Epoch [30/50], Loss: 1.1998\n",
      "Epoch [31/50], Loss: 1.1964\n",
      "Epoch [32/50], Loss: 1.1929\n",
      "Epoch [33/50], Loss: 1.1893\n",
      "Epoch [34/50], Loss: 1.1858\n",
      "Epoch [35/50], Loss: 1.1822\n",
      "Epoch [36/50], Loss: 1.1787\n",
      "Epoch [37/50], Loss: 1.1752\n",
      "Epoch [38/50], Loss: 1.1718\n",
      "Epoch [39/50], Loss: 1.1685\n",
      "Epoch [40/50], Loss: 1.1651\n",
      "Epoch [41/50], Loss: 1.1618\n",
      "Epoch [42/50], Loss: 1.1585\n",
      "Epoch [43/50], Loss: 1.1552\n",
      "Epoch [44/50], Loss: 1.1517\n",
      "Epoch [45/50], Loss: 1.1481\n",
      "Epoch [46/50], Loss: 1.1442\n",
      "Epoch [47/50], Loss: 1.1402\n",
      "Epoch [48/50], Loss: 1.1362\n",
      "Epoch [49/50], Loss: 1.1321\n",
      "Epoch [50/50], Loss: 1.1280\n",
      "Mean Squared Error on Test Data: 1.1239392757415771\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Example sequential measurement data\n",
    "# Assuming each sequence has 10 time steps and 3 features\n",
    "X = np.random.randn(100, 10, 3)\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "# Example regression labels\n",
    "y = np.random.randn(100, 1)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Define LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        output = self.fc(lstm_out[:, -1, :])  # Using only the last time step's output\n",
    "        return output\n",
    "\n",
    "# Instantiate the model\n",
    "input_size = 3  # Number of features in each time step\n",
    "hidden_size = 50  # Number of LSTM units\n",
    "output_size = 1  # Output size (single regression value)\n",
    "model = LSTMModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    print(\"Mean Squared Error on Test Data:\", loss.item())\n",
    "\n",
    "# Make predictions\n",
    "predictions = outputs.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f291c55d-a01c-4a08-8a35-f0fa22d39e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.53983414],\n",
       "       [ 0.02595963],\n",
       "       [ 0.4001707 ],\n",
       "       [ 0.35539943],\n",
       "       [ 0.69263095],\n",
       "       [ 0.458923  ],\n",
       "       [ 0.45358214],\n",
       "       [ 0.6972333 ],\n",
       "       [ 0.01918528],\n",
       "       [-0.64251935],\n",
       "       [-0.04402913],\n",
       "       [-0.0785234 ],\n",
       "       [-0.08128691],\n",
       "       [ 0.5547164 ],\n",
       "       [ 0.09887768],\n",
       "       [ 0.4697313 ],\n",
       "       [ 0.26392022],\n",
       "       [ 0.0141659 ],\n",
       "       [-0.01234652],\n",
       "       [ 0.3830874 ],\n",
       "       [-0.3867787 ],\n",
       "       [ 0.52545273],\n",
       "       [ 0.43124145],\n",
       "       [ 0.0906188 ],\n",
       "       [-0.23529367],\n",
       "       [-0.1234112 ],\n",
       "       [-0.27464283],\n",
       "       [ 0.10087299],\n",
       "       [ 0.4842308 ],\n",
       "       [ 0.1294104 ],\n",
       "       [-0.07540329],\n",
       "       [ 0.20075747],\n",
       "       [-0.47554547],\n",
       "       [ 0.11421708],\n",
       "       [ 0.6245119 ],\n",
       "       [ 0.5454791 ],\n",
       "       [-0.3282947 ],\n",
       "       [ 0.05051087],\n",
       "       [ 0.39321065],\n",
       "       [-0.03295558],\n",
       "       [ 0.33816934],\n",
       "       [ 0.47598463],\n",
       "       [ 0.09506223],\n",
       "       [-0.00884948],\n",
       "       [ 0.41988903],\n",
       "       [-0.04274533],\n",
       "       [-0.06416123],\n",
       "       [ 0.24925269],\n",
       "       [-0.06592648],\n",
       "       [-0.09784995],\n",
       "       [ 0.13916703],\n",
       "       [-0.01446067],\n",
       "       [-0.3062598 ],\n",
       "       [-0.06122676],\n",
       "       [-0.05221102],\n",
       "       [-0.25737226],\n",
       "       [ 0.6151144 ],\n",
       "       [ 0.11623336],\n",
       "       [-0.35694999],\n",
       "       [ 0.08804549],\n",
       "       [ 0.20186214],\n",
       "       [ 0.02900726],\n",
       "       [-0.30973735],\n",
       "       [-0.27547792],\n",
       "       [ 0.76891214],\n",
       "       [-0.05324687],\n",
       "       [-0.18026069],\n",
       "       [ 0.33550993],\n",
       "       [ 0.22156158],\n",
       "       [ 0.1643571 ],\n",
       "       [ 0.4491331 ],\n",
       "       [ 0.29800576],\n",
       "       [ 0.5758192 ],\n",
       "       [ 0.30821404],\n",
       "       [-0.16636178],\n",
       "       [ 0.21758932],\n",
       "       [-0.25346422],\n",
       "       [ 0.31862968],\n",
       "       [ 0.92048335],\n",
       "       [ 0.10142978],\n",
       "       [ 0.40439895],\n",
       "       [ 0.24616249],\n",
       "       [ 0.07599353],\n",
       "       [ 0.6595602 ],\n",
       "       [-0.30560613],\n",
       "       [ 0.02939192],\n",
       "       [-0.3559599 ],\n",
       "       [ 0.12465762],\n",
       "       [-0.2394654 ],\n",
       "       [-0.35690302],\n",
       "       [ 0.00124365],\n",
       "       [ 0.263992  ],\n",
       "       [-0.12047873],\n",
       "       [ 0.07604867],\n",
       "       [-0.10386565],\n",
       "       [-0.29493976],\n",
       "       [ 0.4638098 ],\n",
       "       [ 0.44033763],\n",
       "       [-0.23341312],\n",
       "       [ 0.00368519]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25bdc9c6-b810-4262-ac26-ccdf52159a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5af84a-9930-4561-974f-bd0237da28a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
